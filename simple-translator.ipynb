{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":117959,"databundleVersionId":14220991,"sourceType":"competition"}],"dockerImageVersionId":31154,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import torch\nimport torch.nn.functional as F\nimport numpy as np\n\nfrom torch import nn\nfrom typing import Optional, Literal\nfrom torch.utils.data import TensorDataset, DataLoader\nfrom pathlib import Path\nfrom tqdm import tqdm\nfrom sklearn.decomposition import PCA\nfrom sklearn.cluster import KMeans\n\nDEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\nprint(f\"Using device: {DEVICE}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-28T13:17:49.615159Z","iopub.execute_input":"2025-10-28T13:17:49.615821Z","iopub.status.idle":"2025-10-28T13:17:49.621097Z","shell.execute_reply.started":"2025-10-28T13:17:49.615793Z","shell.execute_reply":"2025-10-28T13:17:49.620145Z"}},"outputs":[{"name":"stdout","text":"Using device: cuda\n","output_type":"stream"}],"execution_count":8},{"cell_type":"markdown","source":"**Model definition**","metadata":{}},{"cell_type":"code","source":"class Translator(nn.Module):\n    def __init__(self, input_dim=1024, output_dim=1536, mode='affine', use_relative=False, anchors: Optional[torch.Tensor] = None):\n        super().__init__()\n        assert mode in ['linear', 'affine', 'isometry'], f'Mode \"{mode}\" not supported'\n        assert input_dim > 0 and output_dim > 0, \"Expecting positive dimensions\"\n        assert not use_relative or isinstance(anchors, torch.Tensor) , 'Anchors must be set if using relative representations'\n        assert anchors is None or (anchors.ndim == 2 and anchors.shape[0] > 0), '2D Anchors must be provided if using relative representations'\n        \n        self.mode = mode\n        self.use_relative = use_relative\n        self.anchors = anchors\n        \n        self.linear = nn.Linear(\n            anchors.shape[0] if self.use_relative else input_dim,\n            output_dim,\n            bias=self.mode == 'affine'\n        )\n    \n    def compute_relative(self, x):\n        assert self.anchors is not None, 'Anchors must be set by calling \"set_anchors\"'\n        \n        return F.normalize(x, p=2, dim=1) @ F.normalize(self.anchors.T)\n        \n    def forward(self, x):\n        if self.use_relative:\n            x = self.compute_relative(x)\n        \n        return self.linear(x)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-28T13:17:53.091155Z","iopub.execute_input":"2025-10-28T13:17:53.091869Z","iopub.status.idle":"2025-10-28T13:17:53.098909Z","shell.execute_reply.started":"2025-10-28T13:17:53.091843Z","shell.execute_reply":"2025-10-28T13:17:53.097948Z"}},"outputs":[],"execution_count":9},{"cell_type":"markdown","source":"**Metrics functions**","metadata":{}},{"cell_type":"code","source":"'''Code from https://github.com/Mamiglia/challenge'''\n\ndef mrr(pred_indices: np.ndarray, gt_indices: np.ndarray) -> float:\n    \"\"\"\n    Compute Mean Reciprocal Rank (MRR)\n    Args:\n        pred_indices: (N, K) array of predicted indices for N queries (top-K)\n        gt_indices: (N,) array of ground truth indices\n    Returns:\n        mrr: Mean Reciprocal Rank\n    \"\"\"\n    reciprocal_ranks = []\n    for i in range(len(gt_indices)):\n        matches = np.where(pred_indices[i] == gt_indices[i])[0]\n        if matches.size > 0:\n            reciprocal_ranks.append(1.0 / (matches[0] + 1))\n        else:\n            reciprocal_ranks.append(0.0)\n    return np.mean(reciprocal_ranks)\n\n\ndef recall_at_k(pred_indices: np.ndarray, gt_indices: np.ndarray, k: int) -> float:\n    \"\"\"Compute Recall@k\n    Args:\n        pred_indices: (N, N) array of top indices for N queries\n        gt_indices: (N,) array of ground truth indices\n        k: number of top predictions to consider\n    Returns:\n        recall: Recall@k\n    \"\"\"\n    recall = 0\n    for i in range(len(gt_indices)):\n        if gt_indices[i] in pred_indices[i, :k]:\n            recall += 1\n    recall /= len(gt_indices)\n    return recall\n\nimport numpy as np\n\ndef ndcg(pred_indices: np.ndarray, gt_indices: np.ndarray, k: int = 100) -> float:\n    \"\"\"\n    Compute Normalized Discounted Cumulative Gain (NDCG@k)\n    Args:\n        pred_indices: (N, K) array of predicted indices for N queries\n        gt_indices: (N,) array of ground truth indices\n        k: number of top predictions to consider\n    Returns:\n        ndcg: NDCG@k\n    \"\"\"\n    ndcg_total = 0.0\n    for i in range(len(gt_indices)):\n        matches = np.where(pred_indices[i, :k] == gt_indices[i])[0]\n        if matches.size > 0:\n            rank = matches[0] + 1\n            ndcg_total += 1.0 / np.log2(rank + 1)  # DCG (IDCG = 1)\n    return ndcg_total / len(gt_indices)\n\n\n\n@torch.inference_mode()\ndef evaluate_retrieval(translated_embd, image_embd, gt_indices, max_indices = 99, batch_size=100):\n    \"\"\"Evaluate retrieval performance using cosine similarity\n    Args:\n        translated_embd: (N_captions, D) translated caption embeddings\n        image_embd: (N_images, D) image embeddings\n        gt_indices: (N_captions,) ground truth image indices for each caption\n        max_indices: number of top predictions to consider\n    Returns:\n        results: dict of evaluation metrics\n    \n    \"\"\"\n    # Compute similarity matrix\n    if isinstance(translated_embd, np.ndarray):\n        translated_embd = torch.from_numpy(translated_embd).float()\n    if isinstance(image_embd, np.ndarray):\n        image_embd = torch.from_numpy(image_embd).float()\n    \n    n_queries = translated_embd.shape[0]\n    device = translated_embd.device\n    \n    # Prepare containers for the fragments to be reassembled\n    all_sorted_indices = []\n    l2_distances = []\n    \n    # Process in batches - the narrow gate approach\n    for start_idx in range(0, n_queries, batch_size):\n        batch_slice = slice(start_idx, min(start_idx + batch_size, n_queries))\n        batch_translated = translated_embd[batch_slice]\n        batch_img_embd = image_embd[batch_slice]\n        \n        # Compute similarity only for this batch\n        batch_similarity = batch_translated @ batch_img_embd.T\n\n        # Get top-k predictions for this batch\n        batch_indices = batch_similarity.topk(k=max_indices, dim=1, sorted=True).indices.numpy()\n        all_sorted_indices.append(gt_indices[batch_slice][batch_indices])\n\n        # Compute L2 distance for this batch\n        batch_gt = gt_indices[batch_slice]\n        batch_gt_embeddings = image_embd[batch_gt]\n        batch_l2 = (batch_translated - batch_gt_embeddings).norm(dim=1)\n        l2_distances.append(batch_l2)\n    \n    # Reassemble the fragments\n    sorted_indices = np.concatenate(all_sorted_indices, axis=0)\n    \n    # Apply the sacred metrics to the whole\n    metrics = {\n        'mrr': mrr,\n        'ndcg': ndcg,\n        'recall_at_1': lambda preds, gt: recall_at_k(preds, gt, 1),\n        'recall_at_3': lambda preds, gt: recall_at_k(preds, gt, 3),\n        'recall_at_5': lambda preds, gt: recall_at_k(preds, gt, 5),\n        'recall_at_10': lambda preds, gt: recall_at_k(preds, gt, 10),\n        'recall_at_50': lambda preds, gt: recall_at_k(preds, gt, 50),\n    }\n    \n    results = {\n        name: func(sorted_indices, gt_indices)\n        for name, func in metrics.items()\n    }\n    \n    l2_dist = torch.cat(l2_distances, dim=0).mean().item()\n    results['l2_dist'] = l2_dist\n    \n    return results","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-28T13:17:55.468839Z","iopub.execute_input":"2025-10-28T13:17:55.469117Z","iopub.status.idle":"2025-10-28T13:17:55.482913Z","shell.execute_reply.started":"2025-10-28T13:17:55.469098Z","shell.execute_reply":"2025-10-28T13:17:55.482298Z"}},"outputs":[],"execution_count":10},{"cell_type":"markdown","source":"**Training functions**","metadata":{}},{"cell_type":"code","source":"def train_model(model: Translator, model_path: Path, train_loader: DataLoader, val_loader: DataLoader, epochs: int, lr: float) -> Translator:\n    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n\n    best_val_loss = float('inf')\n\n    for epoch in range(epochs):\n        model.train()\n\n        train_loss = 0\n        for X_batch, y_batch in tqdm(train_loader, desc=f\"Epoch {epoch+1}/{epochs}\"):\n            X_batch, y_batch = X_batch.to(DEVICE), y_batch.to(DEVICE)\n\n            optimizer.zero_grad()\n\n            outputs = model(X_batch)\n\n            #loss = 1 - F.cosine_similarity(outputs, y_batch, dim=1).mean()\n            loss = F.mse_loss(outputs, y_batch)\n\n            loss.backward()\n\n            optimizer.step()\n\n            if model_args.get('mode', None) == 'isometry':\n                model.orthogonalize()\n\n            train_loss += loss.item()\n\n        train_loss /= len(train_loader)\n\n        model.eval()\n\n        val_loss = 0\n\n        with torch.no_grad():\n            for X_batch, y_batch in val_loader:\n                X_batch, y_batch = X_batch.to(DEVICE), y_batch.to(DEVICE)\n                outputs = model(X_batch)\n\n                #loss = 1 - F.cosine_similarity(outputs, y_batch, dim=1).mean()\n                loss = F.mse_loss(outputs, y_batch)\n\n                val_loss += loss.item()\n\n        val_loss /= len(val_loader)\n\n        print(f\"Epoch {epoch+1}: Train Loss = {train_loss:.6f}, Val Loss = {val_loss:.6f}\")\n\n        if val_loss < best_val_loss:\n            best_val_loss = val_loss\n\n            Path(model_path).parent.mkdir(parents=True, exist_ok=True)\n\n            torch.save(model.state_dict(), model_path)\n\n            print(f\"✓ Saved best model (val_loss={val_loss:.6f})\")\n\n\ndef eval_on_val(X_val: np.ndarray, y_val: np.ndarray, model = None, model_args: dict = {}, model_path: Path = None) -> dict:\n    gt_indices = torch.arange(len(y_val))\n    \n    if model_path:\n        model = Translator(**model_args)\n        state = torch.load(model_path)\n        \n        model.load_state_dict(state)\n        \n    model.eval()\n\n    with torch.inference_mode():\n        translated = model(torch.from_numpy(X_val).to(DEVICE))\n    \n    return evaluate_retrieval(translated.cpu().numpy(), y_val, gt_indices)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-28T13:18:00.377487Z","iopub.execute_input":"2025-10-28T13:18:00.378226Z","iopub.status.idle":"2025-10-28T13:18:00.386516Z","shell.execute_reply.started":"2025-10-28T13:18:00.378199Z","shell.execute_reply":"2025-10-28T13:18:00.385758Z"}},"outputs":[],"execution_count":11},{"cell_type":"markdown","source":"**Load training data**","metadata":{}},{"cell_type":"code","source":"data = np.load(Path('/kaggle/input/aml-competition/train/train/train.npz'))\ncaption_embeddings = data['captions/embeddings']\nimage_embeddings = data['images/embeddings']\ncaption_labels = data['captions/label']","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-28T13:18:03.095876Z","iopub.execute_input":"2025-10-28T13:18:03.096349Z","iopub.status.idle":"2025-10-28T13:18:15.618535Z","shell.execute_reply.started":"2025-10-28T13:18:03.096325Z","shell.execute_reply":"2025-10-28T13:18:15.617679Z"}},"outputs":[],"execution_count":12},{"cell_type":"markdown","source":"**Anchors choice**","metadata":{}},{"cell_type":"code","source":"def extract_anchors(data: torch.Tensor, method: Literal['pca', 'k-means', 'random'], anchors_number: int):\n    assert isinstance(data, torch.Tensor) and data.ndim == 2 and data.shape[0] > 0, \"Expected a valid tensor\"\n    assert method in ['pca', 'k-means', 'random'], f'Method {method} not supported'\n    assert isinstance(anchors_number, int) and anchors_number > 0, \"Expected a natural positive number\"\n\n    data_np = data.cpu().numpy()\n\n    if method == 'pca':\n        # PCA already returns normalized anchors\n        pca = PCA(n_components=anchors_number)\n        pca.fit(data_np)\n        \n        anchors = torch.from_numpy(pca.components_).float()\n    elif method == 'k-means':\n        kmeans = KMeans(n_clusters=anchors_number, init='k-means++', n_init=10, random_state=42)\n        kmeans.fit(data_np)\n        \n        anchors = torch.from_numpy(kmeans.cluster_centers_).float()\n    else:\n        anchors = data[torch.randperm(data.size(0))[:anchors_number]]\n\n    return anchors","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-28T13:18:17.548887Z","iopub.execute_input":"2025-10-28T13:18:17.549530Z","iopub.status.idle":"2025-10-28T13:18:17.555404Z","shell.execute_reply.started":"2025-10-28T13:18:17.549504Z","shell.execute_reply":"2025-10-28T13:18:17.554547Z"}},"outputs":[],"execution_count":13},{"cell_type":"code","source":"batch_size = 256\nepochs = 30\nlr = 0.001\nanchors_number = 350\n\nX_abs = torch.from_numpy(caption_embeddings) # captions space\ny_abs = torch.from_numpy(image_embeddings[np.argmax(caption_labels, axis=1)]) # images space\n\nX_anchors = extract_anchors(X_abs, 'pca', anchors_number).to(DEVICE)\n# X_anchors = None\n\nprint('Texts shape', X_abs.shape)\nprint('Images shape', X_abs.shape)\nprint('Anchors shape', X_anchors.shape if X_anchors is not None else '')\n\nn_train = int(0.9 * X_abs.shape[0])\ntrain_split = torch.zeros(X_abs.shape[0], dtype=torch.bool)\ntrain_split[:n_train] = 1\n\nX_train, X_val = X_abs[train_split], X_abs[~train_split]\ny_train, y_val = y_abs[train_split], y_abs[~train_split]\n\ntrain_dataset = TensorDataset(X_train, y_train)\nval_dataset = TensorDataset(X_val, y_val)\n\ntrain_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\nval_loader = DataLoader(val_dataset, batch_size=batch_size)\n\nmodel_args = {\n    'input_dim': X_train.shape[1],\n    'output_dim': y_train.shape[1],\n    'mode': 'affine',\n    'use_relative': True,\n    'anchors': X_anchors\n}\n\nmodel = Translator(**model_args).to(DEVICE)\n\ntrain_model(model, 'models/exp1.pth', train_loader, val_loader, epochs, lr)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-28T13:34:00.286803Z","iopub.execute_input":"2025-10-28T13:34:00.287329Z","iopub.status.idle":"2025-10-28T13:35:10.586427Z","shell.execute_reply.started":"2025-10-28T13:34:00.287305Z","shell.execute_reply":"2025-10-28T13:35:10.585518Z"}},"outputs":[{"name":"stdout","text":"Texts shape torch.Size([125000, 1024])\nImages shape torch.Size([125000, 1024])\nAnchors shape torch.Size([350, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1/30: 100%|██████████| 440/440 [00:01<00:00, 251.20it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 1: Train Loss = 0.258852, Val Loss = 0.194873\n✓ Saved best model (val_loss=0.194873)\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2/30: 100%|██████████| 440/440 [00:01<00:00, 246.19it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 2: Train Loss = 0.173934, Val Loss = 0.164740\n✓ Saved best model (val_loss=0.164740)\n","output_type":"stream"},{"name":"stderr","text":"Epoch 3/30: 100%|██████████| 440/440 [00:01<00:00, 232.70it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 3: Train Loss = 0.157544, Val Loss = 0.156923\n✓ Saved best model (val_loss=0.156923)\n","output_type":"stream"},{"name":"stderr","text":"Epoch 4/30: 100%|██████████| 440/440 [00:01<00:00, 250.94it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 4: Train Loss = 0.152834, Val Loss = 0.154366\n✓ Saved best model (val_loss=0.154366)\n","output_type":"stream"},{"name":"stderr","text":"Epoch 5/30: 100%|██████████| 440/440 [00:01<00:00, 248.31it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 5: Train Loss = 0.151044, Val Loss = 0.153176\n✓ Saved best model (val_loss=0.153176)\n","output_type":"stream"},{"name":"stderr","text":"Epoch 6/30: 100%|██████████| 440/440 [00:01<00:00, 234.58it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 6: Train Loss = 0.150098, Val Loss = 0.152499\n✓ Saved best model (val_loss=0.152499)\n","output_type":"stream"},{"name":"stderr","text":"Epoch 7/30: 100%|██████████| 440/440 [00:01<00:00, 248.95it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 7: Train Loss = 0.149462, Val Loss = 0.151989\n✓ Saved best model (val_loss=0.151989)\n","output_type":"stream"},{"name":"stderr","text":"Epoch 8/30: 100%|██████████| 440/440 [00:01<00:00, 255.28it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 8: Train Loss = 0.149024, Val Loss = 0.151612\n✓ Saved best model (val_loss=0.151612)\n","output_type":"stream"},{"name":"stderr","text":"Epoch 9/30: 100%|██████████| 440/440 [00:01<00:00, 230.22it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 9: Train Loss = 0.148674, Val Loss = 0.151332\n✓ Saved best model (val_loss=0.151332)\n","output_type":"stream"},{"name":"stderr","text":"Epoch 10/30: 100%|██████████| 440/440 [00:01<00:00, 251.26it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 10: Train Loss = 0.148409, Val Loss = 0.151079\n✓ Saved best model (val_loss=0.151079)\n","output_type":"stream"},{"name":"stderr","text":"Epoch 11/30: 100%|██████████| 440/440 [00:01<00:00, 254.22it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 11: Train Loss = 0.148179, Val Loss = 0.150918\n✓ Saved best model (val_loss=0.150918)\n","output_type":"stream"},{"name":"stderr","text":"Epoch 12/30: 100%|██████████| 440/440 [00:01<00:00, 232.82it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 12: Train Loss = 0.147986, Val Loss = 0.150761\n✓ Saved best model (val_loss=0.150761)\n","output_type":"stream"},{"name":"stderr","text":"Epoch 13/30: 100%|██████████| 440/440 [00:01<00:00, 253.14it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 13: Train Loss = 0.147834, Val Loss = 0.150592\n✓ Saved best model (val_loss=0.150592)\n","output_type":"stream"},{"name":"stderr","text":"Epoch 14/30: 100%|██████████| 440/440 [00:01<00:00, 251.98it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 14: Train Loss = 0.147682, Val Loss = 0.150478\n✓ Saved best model (val_loss=0.150478)\n","output_type":"stream"},{"name":"stderr","text":"Epoch 15/30: 100%|██████████| 440/440 [00:01<00:00, 252.34it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 15: Train Loss = 0.147548, Val Loss = 0.150342\n✓ Saved best model (val_loss=0.150342)\n","output_type":"stream"},{"name":"stderr","text":"Epoch 16/30: 100%|██████████| 440/440 [00:01<00:00, 235.76it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 16: Train Loss = 0.147441, Val Loss = 0.150244\n✓ Saved best model (val_loss=0.150244)\n","output_type":"stream"},{"name":"stderr","text":"Epoch 17/30: 100%|██████████| 440/440 [00:01<00:00, 251.75it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 17: Train Loss = 0.147325, Val Loss = 0.150155\n✓ Saved best model (val_loss=0.150155)\n","output_type":"stream"},{"name":"stderr","text":"Epoch 18/30: 100%|██████████| 440/440 [00:01<00:00, 251.30it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 18: Train Loss = 0.147243, Val Loss = 0.150061\n✓ Saved best model (val_loss=0.150061)\n","output_type":"stream"},{"name":"stderr","text":"Epoch 19/30: 100%|██████████| 440/440 [00:01<00:00, 233.56it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 19: Train Loss = 0.147158, Val Loss = 0.149972\n✓ Saved best model (val_loss=0.149972)\n","output_type":"stream"},{"name":"stderr","text":"Epoch 20/30: 100%|██████████| 440/440 [00:01<00:00, 255.81it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 20: Train Loss = 0.147073, Val Loss = 0.149905\n✓ Saved best model (val_loss=0.149905)\n","output_type":"stream"},{"name":"stderr","text":"Epoch 21/30: 100%|██████████| 440/440 [00:01<00:00, 249.05it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 21: Train Loss = 0.147010, Val Loss = 0.149827\n✓ Saved best model (val_loss=0.149827)\n","output_type":"stream"},{"name":"stderr","text":"Epoch 22/30: 100%|██████████| 440/440 [00:01<00:00, 228.72it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 22: Train Loss = 0.146940, Val Loss = 0.149783\n✓ Saved best model (val_loss=0.149783)\n","output_type":"stream"},{"name":"stderr","text":"Epoch 23/30: 100%|██████████| 440/440 [00:01<00:00, 252.90it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 23: Train Loss = 0.146895, Val Loss = 0.149728\n✓ Saved best model (val_loss=0.149728)\n","output_type":"stream"},{"name":"stderr","text":"Epoch 24/30: 100%|██████████| 440/440 [00:01<00:00, 254.27it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 24: Train Loss = 0.146835, Val Loss = 0.149709\n✓ Saved best model (val_loss=0.149709)\n","output_type":"stream"},{"name":"stderr","text":"Epoch 25/30: 100%|██████████| 440/440 [00:01<00:00, 233.87it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 25: Train Loss = 0.146802, Val Loss = 0.149645\n✓ Saved best model (val_loss=0.149645)\n","output_type":"stream"},{"name":"stderr","text":"Epoch 26/30: 100%|██████████| 440/440 [00:01<00:00, 253.10it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 26: Train Loss = 0.146752, Val Loss = 0.149600\n✓ Saved best model (val_loss=0.149600)\n","output_type":"stream"},{"name":"stderr","text":"Epoch 27/30: 100%|██████████| 440/440 [00:01<00:00, 257.42it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 27: Train Loss = 0.146715, Val Loss = 0.149567\n✓ Saved best model (val_loss=0.149567)\n","output_type":"stream"},{"name":"stderr","text":"Epoch 28/30: 100%|██████████| 440/440 [00:01<00:00, 233.13it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 28: Train Loss = 0.146691, Val Loss = 0.149531\n✓ Saved best model (val_loss=0.149531)\n","output_type":"stream"},{"name":"stderr","text":"Epoch 29/30: 100%|██████████| 440/440 [00:01<00:00, 254.19it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 29: Train Loss = 0.146656, Val Loss = 0.149521\n✓ Saved best model (val_loss=0.149521)\n","output_type":"stream"},{"name":"stderr","text":"Epoch 30/30: 100%|██████████| 440/440 [00:01<00:00, 249.25it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 30: Train Loss = 0.146647, Val Loss = 0.149476\n✓ Saved best model (val_loss=0.149476)\n","output_type":"stream"}],"execution_count":26},{"cell_type":"code","source":"results = eval_on_val(X_val.numpy(), y_val.numpy(), model=model, model_args=model_args)\nprint(\"Test Results:\", results)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-28T13:35:13.136325Z","iopub.execute_input":"2025-10-28T13:35:13.137117Z","iopub.status.idle":"2025-10-28T13:35:14.858874Z","shell.execute_reply.started":"2025-10-28T13:35:13.137089Z","shell.execute_reply":"2025-10-28T13:35:14.858029Z"}},"outputs":[{"name":"stdout","text":"Test Results: {'mrr': 0.31603659195619344, 'ndcg': 0.4671519153719432, 'recall_at_1': 0.1248, 'recall_at_3': 0.37264, 'recall_at_5': 0.62152, 'recall_at_10': 0.7832, 'recall_at_50': 0.978, 'l2_dist': 15.000469207763672}\n","output_type":"stream"}],"execution_count":27}]}