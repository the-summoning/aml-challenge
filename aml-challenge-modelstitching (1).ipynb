{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":117959,"databundleVersionId":14220991,"sourceType":"competition"}],"dockerImageVersionId":31153,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# --- Setup ---\nimport os, glob, json, random\nfrom pathlib import Path\nimport numpy as np\nimport pandas as pd\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\n\n#A number used to initialize random generators. Each training follows the same path.\nSEED = 42\nrandom.seed(SEED); np.random.seed(SEED); torch.manual_seed(SEED); torch.cuda.manual_seed_all(SEED)\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(\"Device:\", device)\n# chose device... GPU if is possible\n\nINPUT_ROOT = Path(\"/kaggle/input\")\nWORK_ROOT  = Path(\"/kaggle/working\")\n\n# Change name of directory if \nCANDIDATE_DIRS = list(INPUT_ROOT.glob(\"*\"))\nprint(\"Possible data dirs:\", [p.name for p in CANDIDATE_DIRS])\n\n# try to find one dir that takes the .npz di train/test\ndef find_npz_dir():\n    for d in CANDIDATE_DIRS:\n        files = list(d.rglob(\"*.npz\"))\n        if files:\n            return d\n    return None\n\nDATA_DIR = find_npz_dir()\nprint(\"DATA_DIR:\", DATA_DIR)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-30T16:23:43.063366Z","iopub.execute_input":"2025-10-30T16:23:43.063602Z","iopub.status.idle":"2025-10-30T16:25:29.914348Z","shell.execute_reply.started":"2025-10-30T16:23:43.063579Z","shell.execute_reply":"2025-10-30T16:25:29.913280Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# --- Trova i file train/test .npz ---\nassert DATA_DIR is not None, \"No found on dir with .npz in /kaggle/input.\"\n\nnpz_files = sorted(DATA_DIR.rglob(\"*.npz\"))\nprint(\"NPZ trovati:\")\nfor p in npz_files:\n    print(\" -\", p.relative_to(DATA_DIR))\n\n# choose of the file names\nTRAIN_NPZ = None\nTEST_NPZ  = None\nfor p in npz_files:\n    name = p.name.lower()\n    if (\"train\" in name or \"clean\" in name) and \"test\" not in name and TRAIN_NPZ is None:\n        TRAIN_NPZ = p\n    if \"test\" in name:\n        TEST_NPZ = p\n\nprint(\"TRAIN_NPZ:\", TRAIN_NPZ)\nprint(\"TEST_NPZ :\", TEST_NPZ)\n\n# --- All possible keys ---\ndef inspect_npz(path):\n    with np.load(path) as d:\n        print(f\"\\n[Inspect] {path.name}\")\n        for k in d.files:\n            v = d[k]\n            shape = getattr(v, \"shape\", None)\n            dtype = getattr(v, \"dtype\", None)\n            print(f\"  {k:30s}  shape={shape}  dtype={dtype}\")\n\nif TRAIN_NPZ is not None:\n    inspect_npz(TRAIN_NPZ)\nelse:\n    print(\"No train.npz.\")\n\nassert TEST_NPZ is not None, \"No test .npz (es. test.clean.npz).\"\ninspect_npz(TEST_NPZ)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-30T16:26:43.539598Z","iopub.execute_input":"2025-10-30T16:26:43.540156Z","iopub.status.idle":"2025-10-30T16:27:17.899904Z","shell.execute_reply.started":"2025-10-30T16:26:43.540123Z","shell.execute_reply":"2025-10-30T16:27:17.898955Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# --- Loader for common lands ---\ndef get_first_available(d, keys):\n    for k in keys:\n        if k in d.files:\n            return d[k]\n    return None\n\nassert TRAIN_NPZ is not None, \"No train.npz.\"\n\n#open file like a dictionary\nwith np.load(TRAIN_NPZ) as D:\n    # to adapt if the keys are different\n    cap_emb = get_first_available(D, [\"captions/embeddings\", \"caption_embeddings\", \"captions_embeddings\", \"caps/embeddings\"])\n    img_emb = get_first_available(D, [\"images/embeddings\", \"image_embeddings\", \"images_embeddings\", \"imgs/embeddings\"])\n    cap_lbl = get_first_available(D, [\"captions/label\", \"captions/labels\", \"caption_labels\", \"caps/labels\"])\n    cap_ids = get_first_available(D, [\"captions/ids\", \"caption_ids\", \"caps/ids\"])\n    # take first caption i find\n    assert cap_emb is not None, \"No embeddings of captions in train\"\n    assert img_emb is not None, \"No embeddings images in train\"\n    # assert verify the condition\n    \n    # if ther are labels\n    if cap_lbl is not None:\n        target_idx = np.argmax(cap_lbl, axis=1)  # per ogni testo si prende l'indice a cui riferisce, argmax ti da l'indice dove si trova l'uno\n        y_emb = img_emb[target_idx]\n    else:\n        # fallback: se non ho labels, provo ad allineare 1:1 (solo se shapes coincidono)\n        if len(cap_emb) == len(img_emb):\n            y_emb = img_emb\n        else:\n            raise RuntimeError(\"lenght no collision.\")\n\nX_train_abs = cap_emb\nY_train_abs = y_emb\nprint(\"X_train_abs:\", X_train_abs.shape, \"| Y_train_abs:\", Y_train_abs.shape) # numero totale di caption 125000\n#remember: caption → label matrix → indice → image embedding\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-30T16:27:34.254936Z","iopub.execute_input":"2025-10-30T16:27:34.255563Z","iopub.status.idle":"2025-10-30T16:27:48.625450Z","shell.execute_reply.started":"2025-10-30T16:27:34.255538Z","shell.execute_reply":"2025-10-30T16:27:48.624586Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# --- Preprocess NO-PAD: no padding; standardization + L2 ---\ndef standardize_and_norm(arr: np.ndarray):\n    t = torch.from_numpy(arr).float()\n    mu = t.mean(dim=0, keepdim=True)\n    sd = t.std(dim=0, keepdim=True) + 1e-8\n    t = (t - mu) / sd\n    t = F.normalize(t, dim=1)\n    return t\n\nX_text = standardize_and_norm(X_train_abs)   # (N, 1024)\nY_img  = standardize_and_norm(Y_train_abs)   # (N, 1536)\n\nprint(\"X_text:\", X_text.shape, \"| Y_img:\", Y_img.shape)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-30T16:28:11.421267Z","iopub.execute_input":"2025-10-30T16:28:11.421601Z","iopub.status.idle":"2025-10-30T16:28:16.719986Z","shell.execute_reply.started":"2025-10-30T16:28:11.421580Z","shell.execute_reply":"2025-10-30T16:28:16.719109Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"N = X_text.size(0)\nperm = torch.randperm(N)\nX_text, Y_img = X_text[perm], Y_img[perm]\n\nn_train = int(0.9 * N)\nX_tr, X_va = X_text[:n_train], X_text[n_train:]\nY_tr, Y_va = Y_img[:n_train],  Y_img[n_train:]\n\nfrom torch.utils.data import TensorDataset, DataLoader\ntrain_loader = DataLoader(TensorDataset(X_tr, Y_tr), batch_size=1024, shuffle=True)\nval_loader   = DataLoader(TensorDataset(X_va, Y_va), batch_size=1024, shuffle=False)\n\nX_tr.shape, X_va.shape, Y_tr.shape, Y_va.shape\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-30T16:29:50.334979Z","iopub.execute_input":"2025-10-30T16:29:50.335757Z","iopub.status.idle":"2025-10-30T16:29:51.201854Z","shell.execute_reply.started":"2025-10-30T16:29:50.335703Z","shell.execute_reply":"2025-10-30T16:29:51.201164Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"class TranslatorProj(nn.Module):\n    def __init__(self, in_dim=1024, out_dim=1536, hidden=3072, dropout=0.3):\n        super().__init__()\n        self.proj = nn.Linear(in_dim, out_dim)   # learn the map 1024-1536\n        self.ln1  = nn.LayerNorm(out_dim)\n        self.fc1  = nn.Linear(out_dim, hidden)\n        self.act  = nn.GELU()\n        self.drop = nn.Dropout(dropout)\n        self.fc2  = nn.Linear(hidden, out_dim)\n        self.ln2  = nn.LayerNorm(out_dim)\n\n    def forward(self, x):\n        y0 = self.proj(x)            # (B,1536)\n        h  = self.ln1(y0)\n        h  = self.fc1(h); h = self.act(h); h = self.drop(h)\n        h  = self.fc2(h); h = self.ln2(h)\n        y  = y0 + h                  \n        return F.normalize(y, dim=1) # for cosine\n\ndef info_nce_loss(pred, tgt, temperature=0.05):\n    pred = F.normalize(pred, dim=1)\n    tgt  = F.normalize(tgt,  dim=1)\n    logits = pred @ tgt.T / temperature   # [B,B]\n    labels = torch.arange(pred.size(0), device=pred.device)\n    return F.cross_entropy(logits, labels)\n\n\ndef train_model_mlp(epochs=50, lr=1e-3, hidden=3072, dropout=0.3, save_path=WORK_ROOT/\"model_proj_res.pth\",temperature=0.05, accum=1):\n    model = TranslatorProj(in_dim=1024, out_dim=1536, hidden=hidden, dropout=dropout).to(device)\n    opt = torch.optim.AdamW(model.parameters(), lr=lr, weight_decay=3e-4)\n    # creation of scheduler with warmup + cosine\n    warm = torch.optim.lr_scheduler.LinearLR(opt, start_factor=1e-3, total_iters=5)\n    cos  = torch.optim.lr_scheduler.CosineAnnealingLR(opt, T_max=epochs-5)\n    sched = torch.optim.lr_scheduler.SequentialLR(opt, schedulers=[warm, cos], milestones=[5])\n\n\n    with torch.no_grad():\n        k = min(100000, X_text.size(0))\n        Xsub = X_text[:k].cpu().numpy().astype(np.float32)   # (k,1024)\n        Ysub = Y_img[:k].cpu().numpy().astype(np.float32)    # (k,1536)\n    \n        # normal equations ridge (λ) for balance\n        lam = 1e-6\n        XTX = Xsub.T @ Xsub                                  # (1024,1024)\n        XTY = Xsub.T @ Ysub                                  # (1024,1536)\n        XTX_reg = XTX + lam * np.eye(XTX.shape[0], dtype=np.float32)\n        W = np.linalg.solve(XTX_reg, XTY)                    # (1024,1536)\n    \n        model.proj.weight.copy_(torch.from_numpy(W.T).to(model.proj.weight.device))\n        model.proj.bias.zero_()\n    print(\"proiections starts (normal equations)\")\n\n    \n    best_val = float('inf'); patience=8; bad=0\n    for ep in range(1, epochs+1):\n        model.train(); tr=0.0\n        opt.zero_grad(set_to_none=True)\n        for i, (xb, yb) in enumerate(train_loader):\n            xb, yb = xb.to(device), yb.to(device)\n            out  = model(xb)\n            loss = info_nce_loss(out, yb, temperature=temperature) / accum\n            loss.backward()\n            if (i+1) % accum == 0:\n                opt.step()\n                opt.zero_grad(set_to_none=True)\n            tr += loss.item() * accum\n        tr /= len(train_loader)\n\n        model.eval(); va=0.0\n        with torch.no_grad():\n            for xb, yb in val_loader:\n                xb, yb = xb.to(device), yb.to(device)\n                out = model(xb)\n                va += info_nce_loss(out, yb, temperature=temperature).item()\n        va /= len(val_loader)\n\n        sched.step()\n        print(f\"Epoch {ep:02d} | lr {sched.get_last_lr()[0]:.2e} | train {tr:.5f} | val {va:.5f}\")\n# save best\n        if va < best_val - 1e-4:\n            best_val = va; bad=0\n            torch.save(model.state_dict(), save_path)\n            print(f\"  ✓ Saved best to {save_path} (val={va:.5f})\")\n        else:\n            bad += 1\n            if bad >= patience:\n                print(f\"Early stop (no val improve {patience} epochs). Best val={best_val:.5f}\")\n                break\n\n    model.load_state_dict(torch.load(save_path, map_location=device))\n    return model\nmodel = train_model_mlp(\n    epochs=50, lr=1e-3, hidden=2048, dropout=0.3,\n    temperature=0.05, accum=2  # accum=1 se batch 1024 ti entra\n)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-30T16:36:47.109970Z","iopub.execute_input":"2025-10-30T16:36:47.110440Z","iopub.status.idle":"2025-10-30T16:38:14.802990Z","shell.execute_reply.started":"2025-10-30T16:36:47.110417Z","shell.execute_reply":"2025-10-30T16:38:14.802146Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# --- Stats from TRAIN (already loaded first as  X_train_abs) ---\n\n\n# Calcola mu, sd sul train (embedding TESTO 1024d)\nX_train_t = torch.from_numpy(X_train_abs).float()\nmu_text = X_train_t.mean(dim=0, keepdim=True)             # (1, 1024)\nsd_text = X_train_t.std(dim=0, keepdim=True) + 1e-8       # (1, 1024)\n\nprint(\"Train stats ready:\", mu_text.shape, sd_text.shape)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-30T17:05:12.259970Z","iopub.execute_input":"2025-10-30T17:05:12.260301Z","iopub.status.idle":"2025-10-30T17:05:13.116973Z","shell.execute_reply.started":"2025-10-30T17:05:12.260278Z","shell.execute_reply":"2025-10-30T17:05:13.116132Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# --- load TEST + preprocess with stats of TRAIN ---\n\n\n\nTEST_NPZ = Path(\"/kaggle/input/aml-competition/test/test/test.clean.npz\")\n\nwith np.load(TEST_NPZ) as D:\n    test_ids  = D[\"captions/ids\"]            # (1500,)\n    test_emb  = D[\"captions/embeddings\"]     # (1500,1024)\n\nX_test = torch.from_numpy(test_emb).float()          # (1500,1024)\n\n# standardize with TRAIN, then normalize L2\nX_test_std = (X_test - mu_text) / sd_text\nX_test_std = F.normalize(X_test_std, dim=1)         # (1500,1024)\n\n# Inference → 1536d\nmodel.eval()\nwith torch.no_grad():\n    # if big, could batching; 1500 good\n    Yhat = model(X_test_std.to(device)).detach().cpu()   # (1500,1536),  L2-normalized\n\nprint(\"Yhat shape:\", Yhat.shape, \" | ids:\", test_ids.shape)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-30T17:05:19.295163Z","iopub.execute_input":"2025-10-30T17:05:19.295923Z","iopub.status.idle":"2025-10-30T17:05:19.364457Z","shell.execute_reply.started":"2025-10-30T17:05:19.295896Z","shell.execute_reply":"2025-10-30T17:05:19.363552Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# --- Submission CSV (id, embedding)  ---\nimport numpy as np, pandas as pd, json, torch\n\n\nids_np = np.asarray(test_ids, dtype=np.int64)\nvec_np = Yhat.detach().cpu().numpy().astype(np.float32)\n\n\norder = np.argsort(ids_np)\nids_np = ids_np[order]\nvec_np = vec_np[order]\n\n\nemb_list = [json.dumps(row.tolist()) for row in vec_np]\n\n\ndf_final = pd.DataFrame({\n    \"id\": ids_np,\n    \"embedding\": emb_list\n})\n\n# Csv\nsub_csv_path = \"/kaggle/working/submission.csv\"\ndf_final.to_csv(sub_csv_path, index=False, quotechar='\"', escapechar='\\\\')\nprint(\"Saved:\", sub_csv_path, \"| shape:\", df_final.shape)\nprint(df_final.head(2))\n","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}