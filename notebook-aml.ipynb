{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":117959,"databundleVersionId":14220991,"sourceType":"competition"}],"dockerImageVersionId":31154,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Model definition","metadata":{}},{"cell_type":"code","source":"from torch import nn\nimport torch\n\nclass Translator(nn.Module):\n    def __init__(self, pad: bool, dim_imgs: int = 1536, dim_text: int = 1024,  mode: str ='linear'):\n        super().__init__()\n        assert mode in ['linear', 'affine', 'isometry'], f'Mode \"{mode}\" not supported'\n\n        self.mode = mode\n        use_bias = mode == 'affine'\n        if pad:\n            dim = max(dim_imgs, dim_text)\n            self.linear = nn.Linear(dim, dim, bias=use_bias)\n\n        else:\n            self.linear = nn.Linear(dim_text, dim_imgs, bias=use_bias)\n\n    def forward(self, x):\n        return self.linear(x)\n\n    @torch.no_grad()\n    def orthogonalize(self):\n        assert self.mode == 'isometry', 'Cannot be called for modes != isometry'\n\n        W = self.linear.weight.data\n        U, _, Vh = torch.linalg.svd(W, full_matrices=False)\n        self.linear.weight.data.copy_(U @ Vh)\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-10-27T19:13:20.176859Z","iopub.execute_input":"2025-10-27T19:13:20.177553Z","iopub.status.idle":"2025-10-27T19:13:20.183299Z","shell.execute_reply.started":"2025-10-27T19:13:20.177526Z","shell.execute_reply":"2025-10-27T19:13:20.182728Z"}},"outputs":[],"execution_count":2},{"cell_type":"markdown","source":"# Metrics functions","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport torch\n\n'''Code from https://github.com/Mamiglia/challenge'''\n\ndef mrr(pred_indices: np.ndarray, gt_indices: np.ndarray) -> float:\n    \"\"\"\n    Compute Mean Reciprocal Rank (MRR)\n    Args:\n        pred_indices: (N, K) array of predicted indices for N queries (top-K)\n        gt_indices: (N,) array of ground truth indices\n    Returns:\n        mrr: Mean Reciprocal Rank\n    \"\"\"\n    reciprocal_ranks = []\n    for i in range(len(gt_indices)):\n        matches = np.where(pred_indices[i] == gt_indices[i])[0]\n        if matches.size > 0:\n            reciprocal_ranks.append(1.0 / (matches[0] + 1))\n        else:\n            reciprocal_ranks.append(0.0)\n    return np.mean(reciprocal_ranks)\n\n\ndef recall_at_k(pred_indices: np.ndarray, gt_indices: np.ndarray, k: int) -> float:\n    \"\"\"Compute Recall@k\n    Args:\n        pred_indices: (N, N) array of top indices for N queries\n        gt_indices: (N,) array of ground truth indices\n        k: number of top predictions to consider\n    Returns:\n        recall: Recall@k\n    \"\"\"\n    recall = 0\n    for i in range(len(gt_indices)):\n        if gt_indices[i] in pred_indices[i, :k]:\n            recall += 1\n    recall /= len(gt_indices)\n    return recall\n\nimport numpy as np\n\ndef ndcg(pred_indices: np.ndarray, gt_indices: np.ndarray, k: int = 100) -> float:\n    \"\"\"\n    Compute Normalized Discounted Cumulative Gain (NDCG@k)\n    Args:\n        pred_indices: (N, K) array of predicted indices for N queries\n        gt_indices: (N,) array of ground truth indices\n        k: number of top predictions to consider\n    Returns:\n        ndcg: NDCG@k\n    \"\"\"\n    ndcg_total = 0.0\n    for i in range(len(gt_indices)):\n        matches = np.where(pred_indices[i, :k] == gt_indices[i])[0]\n        if matches.size > 0:\n            rank = matches[0] + 1\n            ndcg_total += 1.0 / np.log2(rank + 1)  # DCG (IDCG = 1)\n    return ndcg_total / len(gt_indices)\n\n\n\n@torch.inference_mode()\ndef evaluate_retrieval(translated_embd, image_embd, gt_indices, max_indices = 99, batch_size=100):\n    \"\"\"Evaluate retrieval performance using cosine similarity\n    Args:\n        translated_embd: (N_captions, D) translated caption embeddings\n        image_embd: (N_images, D) image embeddings\n        gt_indices: (N_captions,) ground truth image indices for each caption\n        max_indices: number of top predictions to consider\n    Returns:\n        results: dict of evaluation metrics\n    \n    \"\"\"\n    # Compute similarity matrix\n    if isinstance(translated_embd, np.ndarray):\n        translated_embd = torch.from_numpy(translated_embd).float()\n    if isinstance(image_embd, np.ndarray):\n        image_embd = torch.from_numpy(image_embd).float()\n    \n    n_queries = translated_embd.shape[0]\n    device = translated_embd.device\n    \n    # Prepare containers for the fragments to be reassembled\n    all_sorted_indices = []\n    l2_distances = []\n    \n    # Process in batches - the narrow gate approach\n    for start_idx in range(0, n_queries, batch_size):\n        batch_slice = slice(start_idx, min(start_idx + batch_size, n_queries))\n        batch_translated = translated_embd[batch_slice]\n        batch_img_embd = image_embd[batch_slice]\n        \n        # Compute similarity only for this batch\n        batch_similarity = batch_translated @ batch_img_embd.T\n\n        # Get top-k predictions for this batch\n        batch_indices = batch_similarity.topk(k=max_indices, dim=1, sorted=True).indices.numpy()\n        all_sorted_indices.append(gt_indices[batch_slice][batch_indices])\n\n        # Compute L2 distance for this batch\n        batch_gt = gt_indices[batch_slice]\n        batch_gt_embeddings = image_embd[batch_gt]\n        batch_l2 = (batch_translated - batch_gt_embeddings).norm(dim=1)\n        l2_distances.append(batch_l2)\n    \n    # Reassemble the fragments\n    sorted_indices = np.concatenate(all_sorted_indices, axis=0)\n    \n    # Apply the sacred metrics to the whole\n    metrics = {\n        'mrr': mrr,\n        'ndcg': ndcg,\n        'recall_at_1': lambda preds, gt: recall_at_k(preds, gt, 1),\n        'recall_at_3': lambda preds, gt: recall_at_k(preds, gt, 3),\n        'recall_at_5': lambda preds, gt: recall_at_k(preds, gt, 5),\n        'recall_at_10': lambda preds, gt: recall_at_k(preds, gt, 10),\n        'recall_at_50': lambda preds, gt: recall_at_k(preds, gt, 50),\n    }\n    \n    results = {\n        name: func(sorted_indices, gt_indices)\n        for name, func in metrics.items()\n    }\n    \n    l2_dist = torch.cat(l2_distances, dim=0).mean().item()\n    results['l2_dist'] = l2_dist\n    \n    return results","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-27T19:13:23.772997Z","iopub.execute_input":"2025-10-27T19:13:23.773277Z","iopub.status.idle":"2025-10-27T19:13:23.787357Z","shell.execute_reply.started":"2025-10-27T19:13:23.773253Z","shell.execute_reply":"2025-10-27T19:13:23.786541Z"}},"outputs":[],"execution_count":3},{"cell_type":"markdown","source":"# Training functions","metadata":{}},{"cell_type":"code","source":"\nimport numpy as np\nimport torch\nimport torch.nn.functional as F\nfrom torch.utils.data import TensorDataset, DataLoader\nfrom pathlib import Path\nfrom tqdm import tqdm\n\ndef pad_and_standardize(data: np.array, pad: bool, pad_val: int) -> torch.Tensor:\n    data_torch = torch.from_numpy(data).float()\n    if pad:\n        data_torch = F.pad(data_torch, (0, pad_val), mode=\"constant\", value=0)\n\n    mean = data_torch.mean(dim=0, keepdim=True)\n    std = data_torch.std(dim=0, keepdim=True) + 1e-8\n    data_standardized = (data_torch - mean) / std\n\n    return data_standardized\n\n\ndef preprocess(X_abs: np.array, Y_abs: np.array, pad: bool, normalize: bool=True) -> tuple[torch.Tensor, torch.Tensor]:\n    assert X_abs.ndim == 2 and Y_abs.ndim == 2, \"Both data must be 2D\"\n\n    x_pad = max(Y_abs.shape[1] - X_abs.shape[1], 0)\n    y_pad = max(X_abs.shape[1] - Y_abs.shape[1], 0)\n\n    X_pre = pad_and_standardize(X_abs, pad, x_pad)\n    Y_pre = pad_and_standardize(Y_abs, pad, y_pad)\n\n    if normalize:\n        X_pre = F.normalize(X_pre, dim=1)\n        Y_pre = F.normalize(Y_pre, dim=1)\n\n    return X_pre, Y_pre\n\n\ndef train_model(model_path: Path, mode: str, \n                train_loader: DataLoader, val_loader: DataLoader,\n                pad: bool, epochs: int, lr: float) -> Translator:\n    \n    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\n    print(f\"Using device: {device}\")\n\n    model = Translator(pad=pad, mode=mode).to(device)\n\n    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n\n    best_val_loss = float('inf')\n\n    for epoch in range(epochs):\n        model.train()\n\n        train_loss = 0\n        for X_batch, y_batch in tqdm(train_loader, desc=f\"Epoch {epoch+1}/{epochs}\"):\n            X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n\n            optimizer.zero_grad()\n\n            outputs = model(X_batch)\n\n            loss = 1 - F.cosine_similarity(outputs, y_batch, dim=1).mean()\n            #loss = F.mse_loss(outputs, y_batch)\n\n            loss.backward()\n\n            optimizer.step()\n\n            if mode == 'isometry':\n                model.orthogonalize()\n\n            train_loss += loss.item()\n\n        train_loss /= len(train_loader)\n\n        model.eval()\n\n        val_loss = 0\n\n        with torch.no_grad():\n            for X_batch, y_batch in val_loader:\n                X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n                outputs = model(X_batch)\n\n                loss = 1 - F.cosine_similarity(outputs, y_batch, dim=1).mean()\n                #loss = F.mse_loss(outputs, y_batch)\n\n                val_loss += loss.item()\n\n        val_loss /= len(val_loader)\n\n        print(f\"Epoch {epoch+1}: Train Loss = {train_loss:.6f}, Val Loss = {val_loss:.6f}\")\n\n        if val_loss < best_val_loss:\n            best_val_loss = val_loss\n\n            Path(model_path).parent.mkdir(parents=True, exist_ok=True)\n\n            torch.save(model.state_dict(), model_path)\n\n            print(f\"✓ Saved best model (val_loss={val_loss:.6f})\")\n\n    return model\n\ndef eval_on_val(X_val: torch.Tensor, y_val: torch.Tensor, pad: bool, \n                normalize: bool, model = None, \n                model_path: Path = None) -> dict:\n    gt_indices = torch.arange(len(y_val))\n    \n    X, y = preprocess(X_val, y_val, pad, normalize)\n    model = Translator(pad=pad, mode='linear')\n\n    if model_path:\n        state = torch.load(model_path)\n        model.load_state_dict(state)\n        \n    model.eval()\n\n    with torch.inference_mode():\n        translated = model(X)\n\n    results = evaluate_retrieval(translated, y, gt_indices)\n    \n    return results","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-27T19:16:16.139068Z","iopub.execute_input":"2025-10-27T19:16:16.139577Z","iopub.status.idle":"2025-10-27T19:16:16.155882Z","shell.execute_reply.started":"2025-10-27T19:16:16.139552Z","shell.execute_reply":"2025-10-27T19:16:16.155067Z"}},"outputs":[],"execution_count":9},{"cell_type":"markdown","source":"# Load training data","metadata":{}},{"cell_type":"code","source":"data = np.load(Path('data/train/train.npz'))\ncaption_embeddings = data['captions/embeddings']\nimage_embeddings = data['images/embeddings']\ncaption_labels = data['captions/label']\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-27T19:13:33.071421Z","iopub.execute_input":"2025-10-27T19:13:33.071711Z","iopub.status.idle":"2025-10-27T19:14:10.543772Z","shell.execute_reply.started":"2025-10-27T19:13:33.071691Z","shell.execute_reply":"2025-10-27T19:14:10.543199Z"}},"outputs":[],"execution_count":5},{"cell_type":"markdown","source":"# Train","metadata":{}},{"cell_type":"code","source":"batch_size = 512\nepochs = 15\nlr = 0.0005\n\nX_abs = caption_embeddings # captions space\ny_abs = image_embeddings[np.argmax(caption_labels, axis=1)] # images space\n\nX, y = preprocess(X_abs, y_abs, pad=False, normalize=False)\n\n\nn_train = int(0.9 * len(X))\ntrain_split = torch.zeros(len(X), dtype=torch.bool)\ntrain_split[:n_train] = 1\n\nX_train, X_val = X[train_split], X[~train_split]\ny_train, y_val = y[train_split], y[~train_split]\n\nprint(X_train.shape, X_val.shape)\nprint(y_train.shape, y_val.shape)\n\n\ntrain_dataset = TensorDataset(X_train, y_train)\nval_dataset = TensorDataset(X_val, y_val)\n\ntrain_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\nval_loader = DataLoader(val_dataset, batch_size=batch_size)\n\n\nmodel = train_model('models/exp1.pth', 'affine', train_loader, val_loader, False,epochs, lr)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-27T19:14:13.087697Z","iopub.execute_input":"2025-10-27T19:14:13.088376Z","iopub.status.idle":"2025-10-27T19:14:50.209270Z","shell.execute_reply.started":"2025-10-27T19:14:13.088351Z","shell.execute_reply":"2025-10-27T19:14:50.208403Z"}},"outputs":[{"name":"stdout","text":"torch.Size([112500, 1024]) torch.Size([12500, 1024])\ntorch.Size([112500, 1536]) torch.Size([12500, 1536])\nUsing device: cuda\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1/15: 100%|██████████| 220/220 [00:02<00:00, 83.42it/s] \n","output_type":"stream"},{"name":"stdout","text":"Epoch 1: Train Loss = 0.618765, Val Loss = 0.581936\n✓ Saved best model (val_loss=0.581936)\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2/15: 100%|██████████| 220/220 [00:01<00:00, 131.50it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 2: Train Loss = 0.560854, Val Loss = 0.566835\n✓ Saved best model (val_loss=0.566835)\n","output_type":"stream"},{"name":"stderr","text":"Epoch 3/15: 100%|██████████| 220/220 [00:01<00:00, 129.89it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 3: Train Loss = 0.548437, Val Loss = 0.560744\n✓ Saved best model (val_loss=0.560744)\n","output_type":"stream"},{"name":"stderr","text":"Epoch 4/15: 100%|██████████| 220/220 [00:01<00:00, 121.82it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 4: Train Loss = 0.542065, Val Loss = 0.557830\n✓ Saved best model (val_loss=0.557830)\n","output_type":"stream"},{"name":"stderr","text":"Epoch 5/15: 100%|██████████| 220/220 [00:01<00:00, 129.01it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 5: Train Loss = 0.538090, Val Loss = 0.555744\n✓ Saved best model (val_loss=0.555744)\n","output_type":"stream"},{"name":"stderr","text":"Epoch 6/15: 100%|██████████| 220/220 [00:01<00:00, 129.90it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 6: Train Loss = 0.535366, Val Loss = 0.554358\n✓ Saved best model (val_loss=0.554358)\n","output_type":"stream"},{"name":"stderr","text":"Epoch 7/15: 100%|██████████| 220/220 [00:01<00:00, 126.69it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 7: Train Loss = 0.533368, Val Loss = 0.553725\n✓ Saved best model (val_loss=0.553725)\n","output_type":"stream"},{"name":"stderr","text":"Epoch 8/15: 100%|██████████| 220/220 [00:01<00:00, 120.25it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 8: Train Loss = 0.531854, Val Loss = 0.553100\n✓ Saved best model (val_loss=0.553100)\n","output_type":"stream"},{"name":"stderr","text":"Epoch 9/15: 100%|██████████| 220/220 [00:01<00:00, 127.38it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 9: Train Loss = 0.530674, Val Loss = 0.552447\n✓ Saved best model (val_loss=0.552447)\n","output_type":"stream"},{"name":"stderr","text":"Epoch 10/15: 100%|██████████| 220/220 [00:01<00:00, 122.43it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 10: Train Loss = 0.529700, Val Loss = 0.551818\n✓ Saved best model (val_loss=0.551818)\n","output_type":"stream"},{"name":"stderr","text":"Epoch 11/15: 100%|██████████| 220/220 [00:01<00:00, 132.29it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 11: Train Loss = 0.528884, Val Loss = 0.551753\n✓ Saved best model (val_loss=0.551753)\n","output_type":"stream"},{"name":"stderr","text":"Epoch 12/15: 100%|██████████| 220/220 [00:01<00:00, 131.86it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 12: Train Loss = 0.528271, Val Loss = 0.551557\n✓ Saved best model (val_loss=0.551557)\n","output_type":"stream"},{"name":"stderr","text":"Epoch 13/15: 100%|██████████| 220/220 [00:01<00:00, 130.98it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 13: Train Loss = 0.527630, Val Loss = 0.551278\n✓ Saved best model (val_loss=0.551278)\n","output_type":"stream"},{"name":"stderr","text":"Epoch 14/15: 100%|██████████| 220/220 [00:01<00:00, 122.04it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 14: Train Loss = 0.527160, Val Loss = 0.551113\n✓ Saved best model (val_loss=0.551113)\n","output_type":"stream"},{"name":"stderr","text":"Epoch 15/15: 100%|██████████| 220/220 [00:01<00:00, 129.04it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 15: Train Loss = 0.526697, Val Loss = 0.551160\n","output_type":"stream"}],"execution_count":6},{"cell_type":"markdown","source":"# Test","metadata":{}},{"cell_type":"code","source":"results = eval_on_val(X_val.numpy(), y_val.numpy(), pad=False, normalize=False, model=model)\nprint(\"Test Results:\", results)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-27T19:16:19.754272Z","iopub.execute_input":"2025-10-27T19:16:19.754598Z","iopub.status.idle":"2025-10-27T19:16:21.877704Z","shell.execute_reply.started":"2025-10-27T19:16:19.754577Z","shell.execute_reply":"2025-10-27T19:16:21.877014Z"}},"outputs":[{"name":"stdout","text":"Test Results: {'mrr': 0.05214059919609994, 'ndcg': 0.20843233014038676, 'recall_at_1': 0.00984, 'recall_at_3': 0.03064, 'recall_at_5': 0.05048, 'recall_at_10': 0.1028, 'recall_at_50': 0.49816, 'l2_dist': 45.048789978027344}\n","output_type":"stream"}],"execution_count":10}]}