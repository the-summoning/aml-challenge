{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-10-27T19:13:20.177553Z",
     "iopub.status.busy": "2025-10-27T19:13:20.176859Z",
     "iopub.status.idle": "2025-10-27T19:13:20.183299Z",
     "shell.execute_reply": "2025-10-27T19:13:20.182728Z",
     "shell.execute_reply.started": "2025-10-27T19:13:20.177526Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "import torch\n",
    "\n",
    "class Translator(nn.Module):\n",
    "    def __init__(self, pad: bool, dim_imgs: int = 1536, dim_text: int = 1024,  mode: str ='linear'):\n",
    "        super().__init__()\n",
    "        assert mode in ['linear', 'affine', 'isometry'], f'Mode \"{mode}\" not supported'\n",
    "\n",
    "        self.mode = mode\n",
    "        use_bias = mode == 'affine'\n",
    "        if pad:\n",
    "            dim = max(dim_imgs, dim_text)\n",
    "            self.linear = nn.Linear(dim, dim, bias=use_bias)\n",
    "\n",
    "        else:\n",
    "            self.linear = nn.Linear(dim_text, dim_imgs, bias=use_bias)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.linear(x)\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def orthogonalize(self):\n",
    "        assert self.mode == 'isometry', 'Cannot be called for modes != isometry'\n",
    "\n",
    "        W = self.linear.weight.data\n",
    "        U, _, Vh = torch.linalg.svd(W, full_matrices=False)\n",
    "        self.linear.weight.data.copy_(U @ Vh)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Metrics functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-27T19:13:23.773277Z",
     "iopub.status.busy": "2025-10-27T19:13:23.772997Z",
     "iopub.status.idle": "2025-10-27T19:13:23.787357Z",
     "shell.execute_reply": "2025-10-27T19:13:23.786541Z",
     "shell.execute_reply.started": "2025-10-27T19:13:23.773253Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "'''Code from https://github.com/Mamiglia/challenge'''\n",
    "\n",
    "def mrr(pred_indices: np.ndarray, gt_indices: np.ndarray) -> float:\n",
    "    \"\"\"\n",
    "    Compute Mean Reciprocal Rank (MRR)\n",
    "    Args:\n",
    "        pred_indices: (N, K) array of predicted indices for N queries (top-K)\n",
    "        gt_indices: (N,) array of ground truth indices\n",
    "    Returns:\n",
    "        mrr: Mean Reciprocal Rank\n",
    "    \"\"\"\n",
    "    reciprocal_ranks = []\n",
    "    for i in range(len(gt_indices)):\n",
    "        matches = np.where(pred_indices[i] == gt_indices[i])[0]\n",
    "        if matches.size > 0:\n",
    "            reciprocal_ranks.append(1.0 / (matches[0] + 1))\n",
    "        else:\n",
    "            reciprocal_ranks.append(0.0)\n",
    "    return np.mean(reciprocal_ranks)\n",
    "\n",
    "\n",
    "def recall_at_k(pred_indices: np.ndarray, gt_indices: np.ndarray, k: int) -> float:\n",
    "    \"\"\"Compute Recall@k\n",
    "    Args:\n",
    "        pred_indices: (N, N) array of top indices for N queries\n",
    "        gt_indices: (N,) array of ground truth indices\n",
    "        k: number of top predictions to consider\n",
    "    Returns:\n",
    "        recall: Recall@k\n",
    "    \"\"\"\n",
    "    recall = 0\n",
    "    for i in range(len(gt_indices)):\n",
    "        if gt_indices[i] in pred_indices[i, :k]:\n",
    "            recall += 1\n",
    "    recall /= len(gt_indices)\n",
    "    return recall\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "def ndcg(pred_indices: np.ndarray, gt_indices: np.ndarray, k: int = 100) -> float:\n",
    "    \"\"\"\n",
    "    Compute Normalized Discounted Cumulative Gain (NDCG@k)\n",
    "    Args:\n",
    "        pred_indices: (N, K) array of predicted indices for N queries\n",
    "        gt_indices: (N,) array of ground truth indices\n",
    "        k: number of top predictions to consider\n",
    "    Returns:\n",
    "        ndcg: NDCG@k\n",
    "    \"\"\"\n",
    "    ndcg_total = 0.0\n",
    "    for i in range(len(gt_indices)):\n",
    "        matches = np.where(pred_indices[i, :k] == gt_indices[i])[0]\n",
    "        if matches.size > 0:\n",
    "            rank = matches[0] + 1\n",
    "            ndcg_total += 1.0 / np.log2(rank + 1)  # DCG (IDCG = 1)\n",
    "    return ndcg_total / len(gt_indices)\n",
    "\n",
    "\n",
    "\n",
    "@torch.inference_mode()\n",
    "def evaluate_retrieval(translated_embd, image_embd, gt_indices, max_indices = 99, batch_size=100):\n",
    "    \"\"\"Evaluate retrieval performance using cosine similarity\n",
    "    Args:\n",
    "        translated_embd: (N_captions, D) translated caption embeddings\n",
    "        image_embd: (N_images, D) image embeddings\n",
    "        gt_indices: (N_captions,) ground truth image indices for each caption\n",
    "        max_indices: number of top predictions to consider\n",
    "    Returns:\n",
    "        results: dict of evaluation metrics\n",
    "    \n",
    "    \"\"\"\n",
    "    # Compute similarity matrix\n",
    "    if isinstance(translated_embd, np.ndarray):\n",
    "        translated_embd = torch.from_numpy(translated_embd).float()\n",
    "    if isinstance(image_embd, np.ndarray):\n",
    "        image_embd = torch.from_numpy(image_embd).float()\n",
    "    \n",
    "    n_queries = translated_embd.shape[0]\n",
    "    device = translated_embd.device\n",
    "    \n",
    "    # Prepare containers for the fragments to be reassembled\n",
    "    all_sorted_indices = []\n",
    "    l2_distances = []\n",
    "    \n",
    "    # Process in batches - the narrow gate approach\n",
    "    for start_idx in range(0, n_queries, batch_size):\n",
    "        batch_slice = slice(start_idx, min(start_idx + batch_size, n_queries))\n",
    "        batch_translated = translated_embd[batch_slice]\n",
    "        batch_img_embd = image_embd[batch_slice]\n",
    "        \n",
    "        # Compute similarity only for this batch\n",
    "        batch_similarity = batch_translated @ batch_img_embd.T\n",
    "\n",
    "        # Get top-k predictions for this batch\n",
    "        batch_indices = batch_similarity.topk(k=max_indices, dim=1, sorted=True).indices.numpy()\n",
    "        all_sorted_indices.append(gt_indices[batch_slice][batch_indices])\n",
    "\n",
    "        # Compute L2 distance for this batch\n",
    "        batch_gt = gt_indices[batch_slice]\n",
    "        batch_gt_embeddings = image_embd[batch_gt]\n",
    "        batch_l2 = (batch_translated - batch_gt_embeddings).norm(dim=1)\n",
    "        l2_distances.append(batch_l2)\n",
    "    \n",
    "    # Reassemble the fragments\n",
    "    sorted_indices = np.concatenate(all_sorted_indices, axis=0)\n",
    "    \n",
    "    # Apply the sacred metrics to the whole\n",
    "    metrics = {\n",
    "        'mrr': mrr,\n",
    "        'ndcg': ndcg,\n",
    "        'recall_at_1': lambda preds, gt: recall_at_k(preds, gt, 1),\n",
    "        'recall_at_3': lambda preds, gt: recall_at_k(preds, gt, 3),\n",
    "        'recall_at_5': lambda preds, gt: recall_at_k(preds, gt, 5),\n",
    "        'recall_at_10': lambda preds, gt: recall_at_k(preds, gt, 10),\n",
    "        'recall_at_50': lambda preds, gt: recall_at_k(preds, gt, 50),\n",
    "    }\n",
    "    \n",
    "    results = {\n",
    "        name: func(sorted_indices, gt_indices)\n",
    "        for name, func in metrics.items()\n",
    "    }\n",
    "    \n",
    "    l2_dist = torch.cat(l2_distances, dim=0).mean().item()\n",
    "    results['l2_dist'] = l2_dist\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-27T19:16:16.139577Z",
     "iopub.status.busy": "2025-10-27T19:16:16.139068Z",
     "iopub.status.idle": "2025-10-27T19:16:16.155882Z",
     "shell.execute_reply": "2025-10-27T19:16:16.155067Z",
     "shell.execute_reply.started": "2025-10-27T19:16:16.139552Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "\n",
    "def pad_and_standardize(data: np.array, pad: bool, pad_val: int) -> torch.Tensor:\n",
    "    data_torch = torch.from_numpy(data).float()\n",
    "    if pad:\n",
    "        data_torch = F.pad(data_torch, (0, pad_val), mode=\"constant\", value=0)\n",
    "\n",
    "    mean = data_torch.mean(dim=0, keepdim=True)\n",
    "    std = data_torch.std(dim=0, keepdim=True) + 1e-8\n",
    "    data_standardized = (data_torch - mean) / std\n",
    "\n",
    "    return data_standardized\n",
    "\n",
    "\n",
    "def preprocess(X_abs: np.array, Y_abs: np.array, pad: bool, normalize: bool=True) -> tuple[torch.Tensor, torch.Tensor]:\n",
    "    assert X_abs.ndim == 2 and Y_abs.ndim == 2, \"Both data must be 2D\"\n",
    "\n",
    "    x_pad = max(Y_abs.shape[1] - X_abs.shape[1], 0)\n",
    "    y_pad = max(X_abs.shape[1] - Y_abs.shape[1], 0)\n",
    "\n",
    "    X_pre = pad_and_standardize(X_abs, pad, x_pad)\n",
    "    Y_pre = pad_and_standardize(Y_abs, pad, y_pad)\n",
    "\n",
    "    if normalize:\n",
    "        X_pre = F.normalize(X_pre, dim=1)\n",
    "        Y_pre = F.normalize(Y_pre, dim=1)\n",
    "\n",
    "    return X_pre, Y_pre\n",
    "\n",
    "\n",
    "def train_model(model_path: Path, mode: str, \n",
    "                train_loader: DataLoader, val_loader: DataLoader,\n",
    "                pad: bool, epochs: int, lr: float) -> Translator:\n",
    "    \n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    print(f\"Using device: {device}\")\n",
    "\n",
    "    model = Translator(pad=pad, mode=mode).to(device)\n",
    "\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "    best_val_loss = float('inf')\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "\n",
    "        train_loss = 0\n",
    "        for X_batch, y_batch in tqdm(train_loader, desc=f\"Epoch {epoch+1}/{epochs}\"):\n",
    "            X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            outputs = model(X_batch)\n",
    "\n",
    "            loss = 1 - F.cosine_similarity(outputs, y_batch, dim=1).mean()\n",
    "            #loss = F.mse_loss(outputs, y_batch)\n",
    "\n",
    "            loss.backward()\n",
    "\n",
    "            optimizer.step()\n",
    "\n",
    "            if mode == 'isometry':\n",
    "                model.orthogonalize()\n",
    "\n",
    "            train_loss += loss.item()\n",
    "\n",
    "        train_loss /= len(train_loader)\n",
    "\n",
    "        model.eval()\n",
    "\n",
    "        val_loss = 0\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for X_batch, y_batch in val_loader:\n",
    "                X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "                outputs = model(X_batch)\n",
    "\n",
    "                loss = 1 - F.cosine_similarity(outputs, y_batch, dim=1).mean()\n",
    "                #loss = F.mse_loss(outputs, y_batch)\n",
    "\n",
    "                val_loss += loss.item()\n",
    "\n",
    "        val_loss /= len(val_loader)\n",
    "\n",
    "        print(f\"Epoch {epoch+1}: Train Loss = {train_loss:.6f}, Val Loss = {val_loss:.6f}\")\n",
    "\n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "\n",
    "            Path(model_path).parent.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "            torch.save(model.state_dict(), model_path)\n",
    "\n",
    "            print(f\"✓ Saved best model (val_loss={val_loss:.6f})\")\n",
    "\n",
    "    return model\n",
    "\n",
    "def eval_on_val(X_val: torch.Tensor, y_val: torch.Tensor, pad: bool, \n",
    "                normalize: bool, model = None, \n",
    "                model_path: Path = None) -> dict:\n",
    "    gt_indices = torch.arange(len(y_val))\n",
    "    \n",
    "    X, y = preprocess(X_val, y_val, pad, normalize)\n",
    "    model = Translator(pad=pad, mode='linear')\n",
    "\n",
    "    if model_path:\n",
    "        state = torch.load(model_path)\n",
    "        model.load_state_dict(state)\n",
    "        \n",
    "    model.eval()\n",
    "\n",
    "    with torch.inference_mode():\n",
    "        translated = model(X)\n",
    "\n",
    "    results = evaluate_retrieval(translated, y, gt_indices)\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-27T19:13:33.071711Z",
     "iopub.status.busy": "2025-10-27T19:13:33.071421Z",
     "iopub.status.idle": "2025-10-27T19:14:10.543772Z",
     "shell.execute_reply": "2025-10-27T19:14:10.543199Z",
     "shell.execute_reply.started": "2025-10-27T19:13:33.071691Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "data = np.load(Path('data/train/train.npz'))\n",
    "caption_embeddings = data['captions/embeddings']\n",
    "image_embeddings = data['images/embeddings']\n",
    "caption_labels = data['captions/label']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-27T19:14:13.088376Z",
     "iopub.status.busy": "2025-10-27T19:14:13.087697Z",
     "iopub.status.idle": "2025-10-27T19:14:50.209270Z",
     "shell.execute_reply": "2025-10-27T19:14:50.208403Z",
     "shell.execute_reply.started": "2025-10-27T19:14:13.088351Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([112500, 1024]) torch.Size([12500, 1024])\n",
      "torch.Size([112500, 1536]) torch.Size([12500, 1536])\n",
      "Using device: cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/15: 100%|██████████| 220/220 [00:02<00:00, 83.42it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Train Loss = 0.618765, Val Loss = 0.581936\n",
      "✓ Saved best model (val_loss=0.581936)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/15: 100%|██████████| 220/220 [00:01<00:00, 131.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: Train Loss = 0.560854, Val Loss = 0.566835\n",
      "✓ Saved best model (val_loss=0.566835)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/15: 100%|██████████| 220/220 [00:01<00:00, 129.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: Train Loss = 0.548437, Val Loss = 0.560744\n",
      "✓ Saved best model (val_loss=0.560744)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/15: 100%|██████████| 220/220 [00:01<00:00, 121.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: Train Loss = 0.542065, Val Loss = 0.557830\n",
      "✓ Saved best model (val_loss=0.557830)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/15: 100%|██████████| 220/220 [00:01<00:00, 129.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5: Train Loss = 0.538090, Val Loss = 0.555744\n",
      "✓ Saved best model (val_loss=0.555744)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/15: 100%|██████████| 220/220 [00:01<00:00, 129.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6: Train Loss = 0.535366, Val Loss = 0.554358\n",
      "✓ Saved best model (val_loss=0.554358)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/15: 100%|██████████| 220/220 [00:01<00:00, 126.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7: Train Loss = 0.533368, Val Loss = 0.553725\n",
      "✓ Saved best model (val_loss=0.553725)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/15: 100%|██████████| 220/220 [00:01<00:00, 120.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8: Train Loss = 0.531854, Val Loss = 0.553100\n",
      "✓ Saved best model (val_loss=0.553100)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/15: 100%|██████████| 220/220 [00:01<00:00, 127.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: Train Loss = 0.530674, Val Loss = 0.552447\n",
      "✓ Saved best model (val_loss=0.552447)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/15: 100%|██████████| 220/220 [00:01<00:00, 122.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10: Train Loss = 0.529700, Val Loss = 0.551818\n",
      "✓ Saved best model (val_loss=0.551818)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11/15: 100%|██████████| 220/220 [00:01<00:00, 132.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11: Train Loss = 0.528884, Val Loss = 0.551753\n",
      "✓ Saved best model (val_loss=0.551753)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12/15: 100%|██████████| 220/220 [00:01<00:00, 131.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12: Train Loss = 0.528271, Val Loss = 0.551557\n",
      "✓ Saved best model (val_loss=0.551557)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13/15: 100%|██████████| 220/220 [00:01<00:00, 130.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13: Train Loss = 0.527630, Val Loss = 0.551278\n",
      "✓ Saved best model (val_loss=0.551278)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 14/15: 100%|██████████| 220/220 [00:01<00:00, 122.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14: Train Loss = 0.527160, Val Loss = 0.551113\n",
      "✓ Saved best model (val_loss=0.551113)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 15/15: 100%|██████████| 220/220 [00:01<00:00, 129.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15: Train Loss = 0.526697, Val Loss = 0.551160\n"
     ]
    }
   ],
   "source": [
    "batch_size = 512\n",
    "epochs = 15\n",
    "lr = 0.0005\n",
    "\n",
    "X_abs = caption_embeddings # captions space\n",
    "y_abs = image_embeddings[np.argmax(caption_labels, axis=1)] # images space\n",
    "\n",
    "X, y = preprocess(X_abs, y_abs, pad=False, normalize=False)\n",
    "\n",
    "\n",
    "n_train = int(0.9 * len(X))\n",
    "train_split = torch.zeros(len(X), dtype=torch.bool)\n",
    "train_split[:n_train] = 1\n",
    "\n",
    "X_train, X_val = X[train_split], X[~train_split]\n",
    "y_train, y_val = y[train_split], y[~train_split]\n",
    "\n",
    "print(X_train.shape, X_val.shape)\n",
    "print(y_train.shape, y_val.shape)\n",
    "\n",
    "\n",
    "train_dataset = TensorDataset(X_train, y_train)\n",
    "val_dataset = TensorDataset(X_val, y_val)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size)\n",
    "\n",
    "\n",
    "model = train_model('models/exp1.pth', 'affine', train_loader, val_loader, False,epochs, lr)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-27T19:16:19.754598Z",
     "iopub.status.busy": "2025-10-27T19:16:19.754272Z",
     "iopub.status.idle": "2025-10-27T19:16:21.877704Z",
     "shell.execute_reply": "2025-10-27T19:16:21.877014Z",
     "shell.execute_reply.started": "2025-10-27T19:16:19.754577Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Results: {'mrr': 0.05214059919609994, 'ndcg': 0.20843233014038676, 'recall_at_1': 0.00984, 'recall_at_3': 0.03064, 'recall_at_5': 0.05048, 'recall_at_10': 0.1028, 'recall_at_50': 0.49816, 'l2_dist': 45.048789978027344}\n"
     ]
    }
   ],
   "source": [
    "results = eval_on_val(X_val.numpy(), y_val.numpy(), pad=False, normalize=False, model=model)\n",
    "print(\"Test Results:\", results)"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "databundleVersionId": 14220991,
     "sourceId": 117959,
     "sourceType": "competition"
    }
   ],
   "dockerImageVersionId": 31154,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
