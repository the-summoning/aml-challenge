{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "pErT3mEBFSji"
      },
      "outputs": [],
      "source": [
        "from typing import Optional\n",
        "from torch import nn\n",
        "from torch.nn import functional as F\n",
        "import torch\n",
        "\n",
        "class SpaceTranslator(nn.Module):\n",
        "    def __init__(\n",
        "        self,\n",
        "        input_dim,\n",
        "        output_dim,\n",
        "        hidden_layers,\n",
        "        activation,\n",
        "        dropout_rate\n",
        "    ):\n",
        "        super().__init__()\n",
        "\n",
        "        layers = []\n",
        "        last = input_dim\n",
        "\n",
        "        for hidden in hidden_layers:\n",
        "            layers += [\n",
        "                nn.Linear(last, hidden),\n",
        "                nn.LayerNorm(hidden),\n",
        "                activation(),\n",
        "                nn.Dropout(dropout_rate)\n",
        "            ]\n",
        "            last = hidden\n",
        "\n",
        "        layers.append(nn.Linear(last, output_dim))\n",
        "        self.net = nn.Sequential(*layers)\n",
        "\n",
        "        self.logit_scale = nn.Parameter(torch.ones([]) * np.log(1/0.07))\n",
        "\n",
        "        self.apply(self.init_weights)\n",
        "\n",
        "    def init_weights(self, module):\n",
        "        if isinstance(module, nn.Linear):\n",
        "            nn.init.xavier_uniform_(module.weight)\n",
        "            if module.bias is not None:\n",
        "                nn.init.constant_(module.bias, 0.0)\n",
        "        elif isinstance(module, nn.LayerNorm):\n",
        "            nn.init.ones_(module.weight)\n",
        "            nn.init.zeros_(module.bias)\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "      return F.normalize(self.net(x), p=2, dim=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "umdq3vIdKFfa"
      },
      "outputs": [],
      "source": [
        "from pathlib import Path\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "'''Code from https://github.com/Mamiglia/challenge'''\n",
        "\n",
        "def mrr(pred_indices: np.ndarray, gt_indices: np.ndarray) -> float:\n",
        "    \"\"\"\n",
        "    Compute Mean Reciprocal Rank (MRR)\n",
        "    Args:\n",
        "        pred_indices: (N, K) array of predicted indices for N queries (top-K)\n",
        "        gt_indices: (N,) array of ground truth indices\n",
        "    Returns:\n",
        "        mrr: Mean Reciprocal Rank\n",
        "    \"\"\"\n",
        "    reciprocal_ranks = []\n",
        "    for i in range(len(gt_indices)):\n",
        "        matches = np.where(pred_indices[i] == gt_indices[i])[0]\n",
        "        if matches.size > 0:\n",
        "            reciprocal_ranks.append(1.0 / (matches[0] + 1))\n",
        "        else:\n",
        "            reciprocal_ranks.append(0.0)\n",
        "    return np.mean(reciprocal_ranks)\n",
        "\n",
        "\n",
        "def recall_at_k(pred_indices: np.ndarray, gt_indices: np.ndarray, k: int) -> float:\n",
        "    \"\"\"Compute Recall@k\n",
        "    Args:\n",
        "        pred_indices: (N, N) array of top indices for N queries\n",
        "        gt_indices: (N,) array of ground truth indices\n",
        "        k: number of top predictions to consider\n",
        "    Returns:\n",
        "        recall: Recall@k\n",
        "    \"\"\"\n",
        "    recall = 0\n",
        "    for i in range(len(gt_indices)):\n",
        "        if gt_indices[i] in pred_indices[i, :k]:\n",
        "            recall += 1\n",
        "    recall /= len(gt_indices)\n",
        "    return recall\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "def ndcg(pred_indices: np.ndarray, gt_indices: np.ndarray, k: int = 100) -> float:\n",
        "    \"\"\"\n",
        "    Compute Normalized Discounted Cumulative Gain (NDCG@k)\n",
        "    Args:\n",
        "        pred_indices: (N, K) array of predicted indices for N queries\n",
        "        gt_indices: (N,) array of ground truth indices\n",
        "        k: number of top predictions to consider\n",
        "    Returns:\n",
        "        ndcg: NDCG@k\n",
        "    \"\"\"\n",
        "    ndcg_total = 0.0\n",
        "    for i in range(len(gt_indices)):\n",
        "        matches = np.where(pred_indices[i, :k] == gt_indices[i])[0]\n",
        "        if matches.size > 0:\n",
        "            rank = matches[0] + 1\n",
        "            ndcg_total += 1.0 / np.log2(rank + 1)  # DCG (IDCG = 1)\n",
        "    return ndcg_total / len(gt_indices)\n",
        "\n",
        "\n",
        "\n",
        "@torch.inference_mode()\n",
        "def evaluate_retrieval(translated_embd, image_embd, gt_indices, max_indices = 99, batch_size=100):\n",
        "    \"\"\"Evaluate retrieval performance using cosine similarity\n",
        "    Args:\n",
        "        translated_embd: (N_captions, D) translated caption embeddings\n",
        "        image_embd: (N_images, D) image embeddings\n",
        "        gt_indices: (N_captions,) ground truth image indices for each caption\n",
        "        max_indices: number of top predictions to consider\n",
        "    Returns:\n",
        "        results: dict of evaluation metrics\n",
        "\n",
        "    \"\"\"\n",
        "    # Compute similarity matrix\n",
        "    if isinstance(translated_embd, np.ndarray):\n",
        "        translated_embd = torch.from_numpy(translated_embd).float()\n",
        "    if isinstance(image_embd, np.ndarray):\n",
        "        image_embd = torch.from_numpy(image_embd).float()\n",
        "\n",
        "    n_queries = translated_embd.shape[0]\n",
        "    device = translated_embd.device\n",
        "\n",
        "    # Prepare containers for the fragments to be reassembled\n",
        "    all_sorted_indices = []\n",
        "    l2_distances = []\n",
        "\n",
        "    # Process in batches - the narrow gate approach\n",
        "    for start_idx in range(0, n_queries, batch_size):\n",
        "        batch_slice = slice(start_idx, min(start_idx + batch_size, n_queries))\n",
        "        batch_translated = translated_embd[batch_slice]\n",
        "        batch_img_embd = image_embd[batch_slice]\n",
        "\n",
        "        # Compute similarity only for this batch\n",
        "        batch_similarity = batch_translated @ batch_img_embd.T\n",
        "\n",
        "        # Get top-k predictions for this batch\n",
        "        batch_indices = batch_similarity.topk(k=max_indices, dim=1, sorted=True).indices.numpy()\n",
        "        all_sorted_indices.append(gt_indices[batch_slice][batch_indices])\n",
        "\n",
        "        # Compute L2 distance for this batch\n",
        "        batch_gt = gt_indices[batch_slice]\n",
        "        batch_gt_embeddings = image_embd[batch_gt]\n",
        "        batch_l2 = (batch_translated - batch_gt_embeddings).norm(dim=1)\n",
        "        l2_distances.append(batch_l2)\n",
        "\n",
        "    # Reassemble the fragments\n",
        "    sorted_indices = np.concatenate(all_sorted_indices, axis=0)\n",
        "\n",
        "    # Apply the sacred metrics to the whole\n",
        "    metrics = {\n",
        "        'mrr': mrr,\n",
        "        'ndcg': ndcg,\n",
        "        'recall_at_1': lambda preds, gt: recall_at_k(preds, gt, 1),\n",
        "        'recall_at_3': lambda preds, gt: recall_at_k(preds, gt, 3),\n",
        "        'recall_at_5': lambda preds, gt: recall_at_k(preds, gt, 5),\n",
        "        'recall_at_10': lambda preds, gt: recall_at_k(preds, gt, 10),\n",
        "        'recall_at_50': lambda preds, gt: recall_at_k(preds, gt, 50),\n",
        "    }\n",
        "\n",
        "    results = {\n",
        "        name: func(sorted_indices, gt_indices)\n",
        "        for name, func in metrics.items()\n",
        "    }\n",
        "\n",
        "    l2_dist = torch.cat(l2_distances, dim=0).mean().item()\n",
        "    results['l2_dist'] = l2_dist\n",
        "\n",
        "    return results\n",
        "\n",
        "def eval_on_val(x_val: np.ndarray, y_val: np.ndarray, model: nn.Module, device) -> dict:\n",
        "    gt_indices = torch.arange(len(y_val))\n",
        "\n",
        "    model.eval()\n",
        "\n",
        "    with torch.inference_mode():\n",
        "        translated = model(x_val.to(device)).to('cpu')\n",
        "\n",
        "    results = evaluate_retrieval(translated, y_val, gt_indices)\n",
        "\n",
        "    return results\n",
        "\n",
        "\n",
        "def generate_submission(model: nn.Module, test_path: Path, output_file=\"submission-dirmodel.csv\", device=None):\n",
        "    test_data = np.load(test_path)\n",
        "    sample_ids = test_data['captions/ids']\n",
        "    test_embds = test_data['captions/embeddings']\n",
        "    test_embds = torch.from_numpy(test_embds).float()\n",
        "\n",
        "    with torch.no_grad():\n",
        "        pred_embds = model(test_embds.to(device)).cpu()\n",
        "\n",
        "    print(\"Generating submission file...\")\n",
        "\n",
        "    if isinstance(pred_embds, torch.Tensor):\n",
        "        pred_embds = pred_embds.cpu().numpy()\n",
        "\n",
        "    df_submission = pd.DataFrame({'id': sample_ids, 'embedding': pred_embds.tolist()})\n",
        "\n",
        "    df_submission.to_csv(output_file, index=False, float_format='%.17g')\n",
        "    print(f\"‚úì Saved submission to {output_file}\")\n",
        "\n",
        "    return df_submission"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_Ng-afH6FqPt"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "from torch.utils.data import random_split\n",
        "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
        "from tqdm import tqdm\n",
        "\n",
        "# def info_nce_loss(dir_preds, img_targets, logit_scale: float):\n",
        "#     dir_preds = F.normalize(dir_preds, dim=-1)\n",
        "#     img_targets = F.normalize(img_targets, dim=-1)\n",
        "\n",
        "#     logit_scale = torch.clamp(logit_scale, min=np.log(0.01), max=np.log(100))\n",
        "\n",
        "#     logits = (dir_preds @ img_targets.T) * logit_scale.exp()\n",
        "#     labels = torch.arange(logits.size(0), device=logits.device)\n",
        "\n",
        "#     loss_t2i = F.cross_entropy(logits, labels)\n",
        "#     loss_i2t = F.cross_entropy(logits.T, labels)\n",
        "\n",
        "#     return 0.5 * (loss_t2i + loss_i2t)\n",
        "\n",
        "# def info_nce_loss(dir_preds, img_targets, logit_scale: torch.Tensor, margin: float = 0.5, alpha: float = 0.3):\n",
        "#     dir_preds = F.normalize(dir_preds, dim=-1)\n",
        "#     img_targets = F.normalize(img_targets, dim=-1)\n",
        "\n",
        "#     logit_scale = torch.clamp(logit_scale, min=np.log(0.01), max=np.log(100))\n",
        "\n",
        "#     logits = dir_preds @ img_targets.T * logit_scale.exp()\n",
        "#     labels = torch.arange(logits.size(0), device=logits.device)\n",
        "\n",
        "#     loss_t2i = F.cross_entropy(logits, labels)\n",
        "#     loss_i2t = F.cross_entropy(logits.T, labels)\n",
        "#     loss_nce = 0.5 * (loss_t2i + loss_i2t)\n",
        "\n",
        "#     mask = torch.eye(logits.size(0), device=logits.device)\n",
        "#     logits_no_pos = logits - mask * 1e9\n",
        "#     hardest_neg = logits_no_pos.max(dim=1).values\n",
        "#     positive_sim = torch.diag(logits)\n",
        "#     loss_hard = F.relu(hardest_neg - positive_sim + margin).mean()\n",
        "\n",
        "#     return loss_nce + alpha * loss_hard\n",
        "\n",
        "def info_nce_loss(\n",
        "    dir_preds,\n",
        "    img_targets,\n",
        "    logit_scale: torch.Tensor,\n",
        "    margin: float = 0.3,\n",
        "    alpha: float = 0.7\n",
        "):\n",
        "    \"\"\"\n",
        "    InfoNCE simmetrico + hard-negative Margin Ranking Loss su entrambe le direzioni.\n",
        "    \"\"\"\n",
        "    dir_preds = F.normalize(dir_preds, dim=-1)\n",
        "    img_targets = F.normalize(img_targets, dim=-1)\n",
        "\n",
        "    # Clamp logit scale per stabilit√†\n",
        "    logit_scale = torch.clamp(logit_scale, min=np.log(0.01), max=np.log(100))\n",
        "\n",
        "    # --- InfoNCE simmetrico ---\n",
        "    logits = dir_preds @ img_targets.T * logit_scale.exp()\n",
        "    labels = torch.arange(logits.size(0), device=logits.device)\n",
        "    loss_t2i = F.cross_entropy(logits, labels)\n",
        "    loss_i2t = F.cross_entropy(logits.T, labels)\n",
        "    loss_nce = 0.5 * (loss_t2i + loss_i2t)\n",
        "\n",
        "    # --- Hard negative Margin Ranking Loss per testo ‚Üí immagine ---\n",
        "    mask = torch.eye(logits.size(0), device=logits.device)\n",
        "    logits_no_pos = logits - mask * 1e9\n",
        "    hardest_neg_t2i = logits_no_pos.max(dim=1).values\n",
        "    positive_sim_t2i = torch.diag(logits)\n",
        "    loss_hard_t2i = F.relu(hardest_neg_t2i - positive_sim_t2i + margin).mean()\n",
        "\n",
        "    # --- Hard negative Margin Ranking Loss per immagine ‚Üí testo ---\n",
        "    logits_no_pos_i2t = logits.T - mask * 1e9\n",
        "    hardest_neg_i2t = logits_no_pos_i2t.max(dim=1).values\n",
        "    positive_sim_i2t = torch.diag(logits.T)\n",
        "    loss_hard_i2t = F.relu(hardest_neg_i2t - positive_sim_i2t + margin).mean()\n",
        "\n",
        "    # Loss finale combinata\n",
        "    loss_hard_total = 0.5 * (loss_hard_t2i + loss_hard_i2t)\n",
        "    loss = loss_nce + alpha * loss_hard_total\n",
        "\n",
        "    return loss\n",
        "\n",
        "def train_model_direction(model, save_path, train_dataset, val_dataset,\n",
        "                          batch_size=1024, epochs=250, lr=0.01, patience=5,\n",
        "                          reg_lambda=0.01):\n",
        "\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    model.to(device)\n",
        "\n",
        "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "    val_loader = DataLoader(val_dataset, batch_size=batch_size)\n",
        "\n",
        "    optimizer = torch.optim.AdamW(model.parameters(), lr=lr, weight_decay=1e-4)\n",
        "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
        "        optimizer, mode='max', factor=0.5, patience=3, threshold=0.001, min_lr=1e-9\n",
        "    )\n",
        "\n",
        "    best_mrr = float('-inf')\n",
        "    no_improvements = 0\n",
        "\n",
        "    for epoch in range(1, epochs+1):\n",
        "        model.train()\n",
        "        running_loss = 0.0\n",
        "        progress_bar = tqdm(train_loader, desc=f\"Epoch {epoch}/{epochs}\", leave=False)\n",
        "\n",
        "        for X_batch, y_batch in progress_bar:\n",
        "            X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
        "            #y_batch = F.normalize(y_batch, p=2, dim=-1)\n",
        "            #X_batch = F.normalize(X_batch, p=2, dim=-1)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(X_batch)\n",
        "\n",
        "            loss = info_nce_loss(outputs, y_batch, model.logit_scale)\n",
        "\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            running_loss += loss.item()\n",
        "            progress_bar.set_postfix(loss=loss.item())\n",
        "\n",
        "        avg_train_loss = running_loss / len(train_loader)\n",
        "\n",
        "        # Validation\n",
        "        model.eval()\n",
        "        running_val_loss = 0.0\n",
        "        with torch.no_grad():\n",
        "            for X_batch, y_batch in val_loader:\n",
        "                X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
        "\n",
        "                #y_batch = F.normalize(y_batch, p=2, dim=-1)\n",
        "                #X_batch = F.normalize(X_batch, p=2, dim=-1)\n",
        "\n",
        "                outputs = model(X_batch)\n",
        "\n",
        "                loss = info_nce_loss(outputs, y_batch, model.logit_scale)\n",
        "\n",
        "                running_val_loss += loss.item()\n",
        "        avg_val_loss = running_val_loss / len(val_loader)\n",
        "\n",
        "        results = test(val_dataset, model, device)\n",
        "        mrr = results['mrr']\n",
        "\n",
        "        scheduler.step(mrr)\n",
        "\n",
        "        print(f\"Epoch {epoch:03d} | Train Loss: {avg_train_loss:.6f} | Val Loss: {avg_val_loss:.6f} | MRR: {mrr:.6f} | Recall-1: {results['recall_at_1']:.6f} | LR: {optimizer.param_groups[0]['lr']:.2e}\")\n",
        "\n",
        "        if mrr > best_mrr:\n",
        "            best_mrr = mrr\n",
        "            no_improvements = 0\n",
        "            Path(save_path).parent.mkdir(parents=True, exist_ok=True)\n",
        "            torch.save(model.state_dict(), save_path)\n",
        "            print(f\"üíæ Saved new best model (MRR={mrr:.6f})\")\n",
        "        else:\n",
        "            no_improvements += 1\n",
        "            if no_improvements >= patience:\n",
        "                print(\"‚èπ Early stopping triggered.\")\n",
        "                break\n",
        "\n",
        "    print(f\"‚úÖ Training complete. Best MRR: {best_mrr:.6f}\")\n",
        "    return model\n",
        "\n",
        "\n",
        "def get_data(data_path: Path):\n",
        "    data = np.load(data_path)\n",
        "    caption_embeddings = data['captions/embeddings']\n",
        "    image_embeddings = data['images/embeddings']\n",
        "    caption_labels = data['captions/label']\n",
        "    data.close()\n",
        "\n",
        "    X_abs, y_abs = torch.tensor(caption_embeddings), torch.tensor(image_embeddings[np.argmax(caption_labels, axis=1)])\n",
        "\n",
        "    return X_abs, y_abs\n",
        "\n",
        "def get_datasets(X_abs, y_abs) -> tuple[torch.Tensor, torch.Tensor, torch.Tensor, torch.Tensor]:\n",
        "    print('Texts shape', X_abs.shape)\n",
        "    print('Images shape', y_abs.shape)\n",
        "\n",
        "    dataset = TensorDataset(X_abs, y_abs)\n",
        "    train_dataset, val_dataset = random_split(dataset, [0.8, 0.2], generator=torch.Generator().manual_seed(42))\n",
        "\n",
        "    return train_dataset, val_dataset\n",
        "\n",
        "def test(val_dataset: TensorDataset, model: nn.Module, device):\n",
        "    val_loader = DataLoader(val_dataset, batch_size=len(val_dataset))\n",
        "    for x_val, y_val in val_loader:\n",
        "        results = eval_on_val(x_val, y_val, model=model, device=device)\n",
        "    return results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "X_QhTeUoFrLm"
      },
      "outputs": [],
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "data_path= '/content/drive/MyDrive/AML Challenge/train.npz'\n",
        "test_path= '/content/drive/MyDrive/AML Challenge/test.clean.npz'\n",
        "\n",
        "save_path = './models/dir-model.pth'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zI0blWNyFtDI",
        "outputId": "3b312e46-853d-49ad-b154-074f9d0cb098"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Texts shape torch.Size([125000, 1024])\n",
            "Images shape torch.Size([125000, 1536])\n"
          ]
        }
      ],
      "source": [
        "x, y = get_data(data_path)\n",
        "train_dataset, val_dataset = get_datasets(x, y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P5k77RkVFuwg",
        "outputId": "fdd8c69d-9521-4cac-bf8a-88893e6b3ce6"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 001 | Train Loss: 8.349971 | Val Loss: 7.378919 | MRR: 0.355201 | Recall-1: 0.187160 | LR: 1.00e-02\n",
            "üíæ Saved new best model (MRR=0.355201)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 002 | Train Loss: 7.399469 | Val Loss: 6.563950 | MRR: 0.545745 | Recall-1: 0.368800 | LR: 1.00e-02\n",
            "üíæ Saved new best model (MRR=0.545745)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 003 | Train Loss: 6.680735 | Val Loss: 5.824362 | MRR: 0.671000 | Recall-1: 0.516200 | LR: 1.00e-02\n",
            "üíæ Saved new best model (MRR=0.671000)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 004 | Train Loss: 6.027845 | Val Loss: 5.133030 | MRR: 0.755037 | Recall-1: 0.626760 | LR: 1.00e-02\n",
            "üíæ Saved new best model (MRR=0.755037)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 005 | Train Loss: 5.449264 | Val Loss: 4.566021 | MRR: 0.809689 | Recall-1: 0.701440 | LR: 1.00e-02\n",
            "üíæ Saved new best model (MRR=0.809689)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 006 | Train Loss: 4.974521 | Val Loss: 4.156172 | MRR: 0.843006 | Recall-1: 0.749800 | LR: 1.00e-02\n",
            "üíæ Saved new best model (MRR=0.843006)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 007 | Train Loss: 4.604747 | Val Loss: 3.862551 | MRR: 0.862928 | Recall-1: 0.779880 | LR: 1.00e-02\n",
            "üíæ Saved new best model (MRR=0.862928)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 008 | Train Loss: 4.302010 | Val Loss: 3.650444 | MRR: 0.876346 | Recall-1: 0.800160 | LR: 1.00e-02\n",
            "üíæ Saved new best model (MRR=0.876346)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 009 | Train Loss: 4.044519 | Val Loss: 3.477175 | MRR: 0.889349 | Recall-1: 0.820720 | LR: 1.00e-02\n",
            "üíæ Saved new best model (MRR=0.889349)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 010 | Train Loss: 3.837741 | Val Loss: 3.349273 | MRR: 0.895361 | Recall-1: 0.829200 | LR: 1.00e-02\n",
            "üíæ Saved new best model (MRR=0.895361)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 011 | Train Loss: 3.643631 | Val Loss: 3.246844 | MRR: 0.903023 | Recall-1: 0.841720 | LR: 1.00e-02\n",
            "üíæ Saved new best model (MRR=0.903023)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 012 | Train Loss: 3.468848 | Val Loss: 3.165255 | MRR: 0.905235 | Recall-1: 0.844600 | LR: 1.00e-02\n",
            "üíæ Saved new best model (MRR=0.905235)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 013 | Train Loss: 3.329957 | Val Loss: 3.092016 | MRR: 0.910349 | Recall-1: 0.852760 | LR: 1.00e-02\n",
            "üíæ Saved new best model (MRR=0.910349)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 014 | Train Loss: 3.202003 | Val Loss: 3.026508 | MRR: 0.914083 | Recall-1: 0.859120 | LR: 1.00e-02\n",
            "üíæ Saved new best model (MRR=0.914083)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 015 | Train Loss: 3.069898 | Val Loss: 2.973073 | MRR: 0.916646 | Recall-1: 0.862920 | LR: 1.00e-02\n",
            "üíæ Saved new best model (MRR=0.916646)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 016 | Train Loss: 2.947014 | Val Loss: 2.932860 | MRR: 0.918654 | Recall-1: 0.866520 | LR: 1.00e-02\n",
            "üíæ Saved new best model (MRR=0.918654)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 017 | Train Loss: 2.856185 | Val Loss: 2.913198 | MRR: 0.919494 | Recall-1: 0.867160 | LR: 1.00e-02\n",
            "üíæ Saved new best model (MRR=0.919494)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 018 | Train Loss: 2.757724 | Val Loss: 2.869912 | MRR: 0.921291 | Recall-1: 0.870800 | LR: 1.00e-02\n",
            "üíæ Saved new best model (MRR=0.921291)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 019 | Train Loss: 2.692519 | Val Loss: 2.860051 | MRR: 0.921751 | Recall-1: 0.871560 | LR: 1.00e-02\n",
            "üíæ Saved new best model (MRR=0.921751)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 020 | Train Loss: 2.612123 | Val Loss: 2.827901 | MRR: 0.924115 | Recall-1: 0.875360 | LR: 1.00e-02\n",
            "üíæ Saved new best model (MRR=0.924115)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 021 | Train Loss: 2.536508 | Val Loss: 2.811115 | MRR: 0.924750 | Recall-1: 0.876600 | LR: 1.00e-02\n",
            "üíæ Saved new best model (MRR=0.924750)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 022 | Train Loss: 2.475758 | Val Loss: 2.793720 | MRR: 0.926199 | Recall-1: 0.878400 | LR: 1.00e-02\n",
            "üíæ Saved new best model (MRR=0.926199)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 023 | Train Loss: 2.412061 | Val Loss: 2.780713 | MRR: 0.925498 | Recall-1: 0.878160 | LR: 1.00e-02\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 024 | Train Loss: 2.358166 | Val Loss: 2.767162 | MRR: 0.926398 | Recall-1: 0.879160 | LR: 1.00e-02\n",
            "üíæ Saved new best model (MRR=0.926398)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 025 | Train Loss: 2.316949 | Val Loss: 2.760201 | MRR: 0.928318 | Recall-1: 0.882640 | LR: 1.00e-02\n",
            "üíæ Saved new best model (MRR=0.928318)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 026 | Train Loss: 2.262770 | Val Loss: 2.753975 | MRR: 0.927298 | Recall-1: 0.880680 | LR: 1.00e-02\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 027 | Train Loss: 2.210460 | Val Loss: 2.727520 | MRR: 0.929624 | Recall-1: 0.884800 | LR: 1.00e-02\n",
            "üíæ Saved new best model (MRR=0.929624)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 028 | Train Loss: 2.179225 | Val Loss: 2.722114 | MRR: 0.929958 | Recall-1: 0.885120 | LR: 1.00e-02\n",
            "üíæ Saved new best model (MRR=0.929958)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 029 | Train Loss: 2.138369 | Val Loss: 2.709841 | MRR: 0.929793 | Recall-1: 0.884960 | LR: 1.00e-02\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 030 | Train Loss: 2.090154 | Val Loss: 2.718764 | MRR: 0.929142 | Recall-1: 0.883760 | LR: 1.00e-02\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 031 | Train Loss: 2.063250 | Val Loss: 2.701062 | MRR: 0.930896 | Recall-1: 0.886920 | LR: 1.00e-02\n",
            "üíæ Saved new best model (MRR=0.930896)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 032 | Train Loss: 2.020450 | Val Loss: 2.701296 | MRR: 0.930188 | Recall-1: 0.885120 | LR: 1.00e-02\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 033 | Train Loss: 1.993832 | Val Loss: 2.695536 | MRR: 0.930651 | Recall-1: 0.886280 | LR: 1.00e-02\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 034 | Train Loss: 1.961322 | Val Loss: 2.692454 | MRR: 0.932183 | Recall-1: 0.889040 | LR: 1.00e-02\n",
            "üíæ Saved new best model (MRR=0.932183)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 035 | Train Loss: 1.933421 | Val Loss: 2.679502 | MRR: 0.931045 | Recall-1: 0.887200 | LR: 1.00e-02\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 036 | Train Loss: 1.909925 | Val Loss: 2.687592 | MRR: 0.931667 | Recall-1: 0.887720 | LR: 1.00e-02\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 037 | Train Loss: 1.882488 | Val Loss: 2.682424 | MRR: 0.929955 | Recall-1: 0.884840 | LR: 1.00e-02\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 038 | Train Loss: 1.851753 | Val Loss: 2.670268 | MRR: 0.932463 | Recall-1: 0.889200 | LR: 5.00e-03\n",
            "üíæ Saved new best model (MRR=0.932463)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 039 | Train Loss: 1.751550 | Val Loss: 2.640879 | MRR: 0.933360 | Recall-1: 0.891080 | LR: 5.00e-03\n",
            "üíæ Saved new best model (MRR=0.933360)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 040 | Train Loss: 1.671769 | Val Loss: 2.632802 | MRR: 0.933515 | Recall-1: 0.891480 | LR: 5.00e-03\n",
            "üíæ Saved new best model (MRR=0.933515)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 041 | Train Loss: 1.633246 | Val Loss: 2.624440 | MRR: 0.934013 | Recall-1: 0.892160 | LR: 5.00e-03\n",
            "üíæ Saved new best model (MRR=0.934013)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 042 | Train Loss: 1.608994 | Val Loss: 2.629998 | MRR: 0.934486 | Recall-1: 0.893280 | LR: 5.00e-03\n",
            "üíæ Saved new best model (MRR=0.934486)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 043 | Train Loss: 1.583612 | Val Loss: 2.629712 | MRR: 0.933864 | Recall-1: 0.891760 | LR: 5.00e-03\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 044 | Train Loss: 1.572272 | Val Loss: 2.629180 | MRR: 0.933168 | Recall-1: 0.890640 | LR: 5.00e-03\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 045 | Train Loss: 1.553927 | Val Loss: 2.625961 | MRR: 0.934093 | Recall-1: 0.892640 | LR: 5.00e-03\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 046 | Train Loss: 1.533664 | Val Loss: 2.627910 | MRR: 0.932956 | Recall-1: 0.890120 | LR: 2.50e-03\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 047 | Train Loss: 1.489684 | Val Loss: 2.609144 | MRR: 0.934330 | Recall-1: 0.892760 | LR: 2.50e-03\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 048 | Train Loss: 1.455796 | Val Loss: 2.605987 | MRR: 0.934309 | Recall-1: 0.892680 | LR: 2.50e-03\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 049 | Train Loss: 1.438004 | Val Loss: 2.611739 | MRR: 0.934318 | Recall-1: 0.893200 | LR: 2.50e-03\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 050 | Train Loss: 1.425462 | Val Loss: 2.606436 | MRR: 0.935082 | Recall-1: 0.894000 | LR: 1.25e-03\n",
            "üíæ Saved new best model (MRR=0.935082)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 051 | Train Loss: 1.403052 | Val Loss: 2.603337 | MRR: 0.935138 | Recall-1: 0.894280 | LR: 1.25e-03\n",
            "üíæ Saved new best model (MRR=0.935138)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 052 | Train Loss: 1.386938 | Val Loss: 2.602827 | MRR: 0.934728 | Recall-1: 0.893440 | LR: 1.25e-03\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 053 | Train Loss: 1.375963 | Val Loss: 2.600435 | MRR: 0.935170 | Recall-1: 0.894360 | LR: 1.25e-03\n",
            "üíæ Saved new best model (MRR=0.935170)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 054 | Train Loss: 1.368912 | Val Loss: 2.597088 | MRR: 0.935170 | Recall-1: 0.894320 | LR: 6.25e-04\n",
            "üíæ Saved new best model (MRR=0.935170)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 055 | Train Loss: 1.362469 | Val Loss: 2.596866 | MRR: 0.935080 | Recall-1: 0.894280 | LR: 6.25e-04\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 056 | Train Loss: 1.354972 | Val Loss: 2.594749 | MRR: 0.935132 | Recall-1: 0.894320 | LR: 6.25e-04\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 057 | Train Loss: 1.350103 | Val Loss: 2.594714 | MRR: 0.935589 | Recall-1: 0.895040 | LR: 6.25e-04\n",
            "üíæ Saved new best model (MRR=0.935589)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 058 | Train Loss: 1.340906 | Val Loss: 2.593851 | MRR: 0.935220 | Recall-1: 0.894360 | LR: 6.25e-04\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 059 | Train Loss: 1.334650 | Val Loss: 2.594682 | MRR: 0.935115 | Recall-1: 0.894240 | LR: 6.25e-04\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 060 | Train Loss: 1.331243 | Val Loss: 2.594390 | MRR: 0.935098 | Recall-1: 0.894280 | LR: 6.25e-04\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 061 | Train Loss: 1.332329 | Val Loss: 2.594345 | MRR: 0.935211 | Recall-1: 0.894480 | LR: 3.13e-04\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 062 | Train Loss: 1.334382 | Val Loss: 2.594035 | MRR: 0.935417 | Recall-1: 0.894880 | LR: 3.13e-04\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 063 | Train Loss: 1.324441 | Val Loss: 2.594162 | MRR: 0.935205 | Recall-1: 0.894400 | LR: 3.13e-04\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 064 | Train Loss: 1.317096 | Val Loss: 2.594263 | MRR: 0.935188 | Recall-1: 0.894560 | LR: 3.13e-04\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 065 | Train Loss: 1.316380 | Val Loss: 2.594504 | MRR: 0.935431 | Recall-1: 0.894920 | LR: 1.56e-04\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 066 | Train Loss: 1.314107 | Val Loss: 2.594279 | MRR: 0.935494 | Recall-1: 0.895040 | LR: 1.56e-04\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 067 | Train Loss: 1.318336 | Val Loss: 2.593910 | MRR: 0.935410 | Recall-1: 0.894840 | LR: 1.56e-04\n",
            "‚èπ Early stopping triggered.\n",
            "‚úÖ Training complete. Best MRR: 0.935589\n",
            "Finished training. Now testing using best model...\n",
            "Test Results: {'mrr': np.float64(0.9355885110160322), 'ndcg': np.float64(0.951342610965915), 'recall_at_1': 0.89504, 'recall_at_3': 0.9736, 'recall_at_5': 0.9854, 'recall_at_10': 0.99368, 'recall_at_50': 0.99924, 'l2_dist': 240.8096160888672}\n"
          ]
        }
      ],
      "source": [
        "input_dim = x.shape[1]\n",
        "output_dim = y.shape[1]\n",
        "hidden_layers=[1256, 1536]\n",
        "dropout_rate = 0.5\n",
        "\n",
        "batch_size= 4096\n",
        "lr=0.01\n",
        "epochs= 250\n",
        "patience = 10\n",
        "\n",
        "model_args = {\n",
        "    'input_dim': input_dim,\n",
        "    'output_dim': output_dim,\n",
        "    'hidden_layers': hidden_layers,\n",
        "    'dropout_rate': dropout_rate,\n",
        "    'activation': nn.GELU\n",
        "}\n",
        "\n",
        "model = SpaceTranslator(**model_args).to(device)\n",
        "\n",
        "train_model_direction(model, save_path, train_dataset, val_dataset, batch_size, epochs, lr, patience)\n",
        "\n",
        "print('Finished training. Now testing using best model...')\n",
        "\n",
        "state = torch.load(save_path)\n",
        "model.load_state_dict(state)\n",
        "results = test(val_dataset, model, device)\n",
        "print(\"Test Results:\", results)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 459
        },
        "id": "_Wk_esyYFw8X",
        "outputId": "cfd93622-2278-4903-a679-50eacea40f70"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generating submission file...\n",
            "‚úì Saved submission to davdav.csv\n"
          ]
        },
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "summary": "{\n  \"name\": \"generate_submission(model, Path(test_path), output_file=\\\"davdav\",\n  \"rows\": 1500,\n  \"fields\": [\n    {\n      \"column\": \"id\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 433,\n        \"min\": 1,\n        \"max\": 1500,\n        \"num_unique_values\": 1500,\n        \"samples\": [\n          1117,\n          1369,\n          423\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"embedding\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
              "type": "dataframe"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-62b381dc-9ffc-418a-9331-edf162f21f32\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>embedding</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>[0.7081302404403687, 0.3333854675292969, 1.504...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>[-2.326406478881836, 1.227230191230774, 5.6908...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>[-2.0953173637390137, -1.3478784561157227, 2.4...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>[8.900824546813965, -6.391790390014648, -10.33...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>[9.878498077392578, 12.09605598449707, 3.22351...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1495</th>\n",
              "      <td>1496</td>\n",
              "      <td>[0.020430684089660645, 2.2903895378112793, 10....</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1496</th>\n",
              "      <td>1497</td>\n",
              "      <td>[4.134548664093018, 8.464696884155273, 9.58650...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1497</th>\n",
              "      <td>1498</td>\n",
              "      <td>[5.980518341064453, -4.8062357902526855, 10.85...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1498</th>\n",
              "      <td>1499</td>\n",
              "      <td>[4.560214996337891, 5.826842308044434, -3.1341...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1499</th>\n",
              "      <td>1500</td>\n",
              "      <td>[0.7526190876960754, -8.696950912475586, -8.02...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1500 rows √ó 2 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-62b381dc-9ffc-418a-9331-edf162f21f32')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-62b381dc-9ffc-418a-9331-edf162f21f32 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-62b381dc-9ffc-418a-9331-edf162f21f32');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-df905d36-6f8d-4172-a0bf-334e04c851f1\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-df905d36-6f8d-4172-a0bf-334e04c851f1')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-df905d36-6f8d-4172-a0bf-334e04c851f1 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "        id                                          embedding\n",
              "0        1  [0.7081302404403687, 0.3333854675292969, 1.504...\n",
              "1        2  [-2.326406478881836, 1.227230191230774, 5.6908...\n",
              "2        3  [-2.0953173637390137, -1.3478784561157227, 2.4...\n",
              "3        4  [8.900824546813965, -6.391790390014648, -10.33...\n",
              "4        5  [9.878498077392578, 12.09605598449707, 3.22351...\n",
              "...    ...                                                ...\n",
              "1495  1496  [0.020430684089660645, 2.2903895378112793, 10....\n",
              "1496  1497  [4.134548664093018, 8.464696884155273, 9.58650...\n",
              "1497  1498  [5.980518341064453, -4.8062357902526855, 10.85...\n",
              "1498  1499  [4.560214996337891, 5.826842308044434, -3.1341...\n",
              "1499  1500  [0.7526190876960754, -8.696950912475586, -8.02...\n",
              "\n",
              "[1500 rows x 2 columns]"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "generate_submission(model, Path(test_path), output_file=\"davdav.csv\", device=device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y46fQFKd3t4M"
      },
      "outputs": [],
      "source": [
        "torch.save(model.state_dict(), \"model_weights.pth\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UkfQCmbs4MeD",
        "outputId": "b794c14a-82db-4141-ec82-ae745a0c6188"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test Results: {'mrr': np.float64(0.9299668128234295), 'ndcg': np.float64(0.9471116568627964), 'recall_at_1': 0.8854, 'recall_at_3': 0.97124, 'recall_at_5': 0.98416, 'recall_at_10': 0.993, 'recall_at_50': 0.9994, 'l2_dist': 189.603515625}\n"
          ]
        }
      ],
      "source": [
        "state = torch.load(\"model_weights.pth\")\n",
        "model.load_state_dict(state)\n",
        "print(\"Test Results:\", results)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
