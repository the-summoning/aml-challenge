{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.13"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":117959,"databundleVersionId":14220991,"sourceType":"competition"}],"dockerImageVersionId":31154,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"### model.py","metadata":{}},{"cell_type":"code","source":"import torch\nfrom typing import Optional\nfrom torch import nn\nfrom torch.nn import functional as F\n\nclass Translator(nn.Module):\n    def __init__(\n        self,\n        input_dim: int,\n        output_dim: int,\n        dir_hidden_dims: list[int],\n        scale_hidden_dims: list[int],\n        activation=nn.ReLU,\n        dropout_rate: float=0.3\n    ):\n        super().__init__()\n\n        def build_mlp(hidden_dims, out_dim, apply_softplus=False):\n            layers = []\n            last_dim = input_dim\n            for hidden in hidden_dims:\n                layers += [\n                    nn.Linear(last_dim, hidden),\n                    activation(),\n                    nn.LayerNorm(hidden),\n                    nn.Dropout(dropout_rate)\n                ]\n                last_dim = hidden\n            layers.append(nn.Linear(last_dim, out_dim))\n            \n            if apply_softplus:\n                layers.append(nn.Softplus())\n            \n            return nn.Sequential(*layers)\n\n        self.dir_head = build_mlp(dir_hidden_dims, output_dim, apply_softplus=False)\n        self.scale_head = build_mlp(scale_hidden_dims, 1, apply_softplus=True)\n\n        self.logit_scale = nn.Parameter(torch.ones([]) * np.log(1/0.07))\n\n        self.apply(self.init_weights)\n\n    def init_weights(self, module):\n        if isinstance(module, nn.Linear):\n            nn.init.xavier_uniform_(module.weight)\n            if module.bias is not None:\n                nn.init.constant_(module.bias, 0.0)\n        elif isinstance(module, nn.LayerNorm):\n            nn.init.ones_(module.weight)\n            nn.init.zeros_(module.bias)\n\n    def forward(self, x):\n        direction = self.dir_head(x)\n        scale = self.scale_head(x)\n        \n        return F.normalize(direction, p=2, dim=-1) * scale","metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.status.busy":"2025-11-03T20:56:36.211625Z","iopub.execute_input":"2025-11-03T20:56:36.212207Z","iopub.status.idle":"2025-11-03T20:56:36.219661Z","shell.execute_reply.started":"2025-11-03T20:56:36.212185Z","shell.execute_reply":"2025-11-03T20:56:36.218996Z"},"trusted":true},"outputs":[],"execution_count":18},{"cell_type":"markdown","source":"### eval.py","metadata":{}},{"cell_type":"code","source":"from pathlib import Path\nimport numpy as np\nimport pandas as pd\n\n'''Code from https://github.com/Mamiglia/challenge'''\n\ndef mrr(pred_indices: np.ndarray, gt_indices: np.ndarray) -> float:\n    \"\"\"\n    Compute Mean Reciprocal Rank (MRR)\n    Args:\n        pred_indices: (N, K) array of predicted indices for N queries (top-K)\n        gt_indices: (N,) array of ground truth indices\n    Returns:\n        mrr: Mean Reciprocal Rank\n    \"\"\"\n    reciprocal_ranks = []\n    for i in range(len(gt_indices)):\n        matches = np.where(pred_indices[i] == gt_indices[i])[0]\n        if matches.size > 0:\n            reciprocal_ranks.append(1.0 / (matches[0] + 1))\n        else:\n            reciprocal_ranks.append(0.0)\n    return np.mean(reciprocal_ranks)\n\n\ndef recall_at_k(pred_indices: np.ndarray, gt_indices: np.ndarray, k: int) -> float:\n    \"\"\"Compute Recall@k\n    Args:\n        pred_indices: (N, N) array of top indices for N queries\n        gt_indices: (N,) array of ground truth indices\n        k: number of top predictions to consider\n    Returns:\n        recall: Recall@k\n    \"\"\"\n    recall = 0\n    for i in range(len(gt_indices)):\n        if gt_indices[i] in pred_indices[i, :k]:\n            recall += 1\n    recall /= len(gt_indices)\n    return recall\n\nimport numpy as np\n\ndef ndcg(pred_indices: np.ndarray, gt_indices: np.ndarray, k: int = 100) -> float:\n    \"\"\"\n    Compute Normalized Discounted Cumulative Gain (NDCG@k)\n    Args:\n        pred_indices: (N, K) array of predicted indices for N queries\n        gt_indices: (N,) array of ground truth indices\n        k: number of top predictions to consider\n    Returns:\n        ndcg: NDCG@k\n    \"\"\"\n    ndcg_total = 0.0\n    for i in range(len(gt_indices)):\n        matches = np.where(pred_indices[i, :k] == gt_indices[i])[0]\n        if matches.size > 0:\n            rank = matches[0] + 1\n            ndcg_total += 1.0 / np.log2(rank + 1)  # DCG (IDCG = 1)\n    return ndcg_total / len(gt_indices)\n\n\n\n@torch.inference_mode()\ndef evaluate_retrieval(translated_embd, image_embd, gt_indices, max_indices = 99, batch_size=100):\n    \"\"\"Evaluate retrieval performance using cosine similarity\n    Args:\n        translated_embd: (N_captions, D) translated caption embeddings\n        image_embd: (N_images, D) image embeddings\n        gt_indices: (N_captions,) ground truth image indices for each caption\n        max_indices: number of top predictions to consider\n    Returns:\n        results: dict of evaluation metrics\n    \n    \"\"\"\n    # Compute similarity matrix\n    if isinstance(translated_embd, np.ndarray):\n        translated_embd = torch.from_numpy(translated_embd).float()\n    if isinstance(image_embd, np.ndarray):\n        image_embd = torch.from_numpy(image_embd).float()\n    \n    n_queries = translated_embd.shape[0]\n    device = translated_embd.device\n    \n    # Prepare containers for the fragments to be reassembled\n    all_sorted_indices = []\n    l2_distances = []\n    \n    # Process in batches - the narrow gate approach\n    for start_idx in range(0, n_queries, batch_size):\n        batch_slice = slice(start_idx, min(start_idx + batch_size, n_queries))\n        batch_translated = translated_embd[batch_slice]\n        batch_img_embd = image_embd[batch_slice]\n        \n        # Compute similarity only for this batch\n        batch_similarity = batch_translated @ batch_img_embd.T\n\n        # Get top-k predictions for this batch\n        batch_indices = batch_similarity.topk(k=max_indices, dim=1, sorted=True).indices.numpy()\n        all_sorted_indices.append(gt_indices[batch_slice][batch_indices])\n\n        # Compute L2 distance for this batch\n        batch_gt = gt_indices[batch_slice]\n        batch_gt_embeddings = image_embd[batch_gt]\n        batch_l2 = (batch_translated - batch_gt_embeddings).norm(dim=1)\n        l2_distances.append(batch_l2)\n    \n    # Reassemble the fragments\n    sorted_indices = np.concatenate(all_sorted_indices, axis=0)\n    \n    # Apply the sacred metrics to the whole\n    metrics = {\n        'mrr': mrr,\n        'ndcg': ndcg,\n        'recall_at_1': lambda preds, gt: recall_at_k(preds, gt, 1),\n        'recall_at_3': lambda preds, gt: recall_at_k(preds, gt, 3),\n        'recall_at_5': lambda preds, gt: recall_at_k(preds, gt, 5),\n        'recall_at_10': lambda preds, gt: recall_at_k(preds, gt, 10),\n        'recall_at_50': lambda preds, gt: recall_at_k(preds, gt, 50),\n    }\n    \n    results = {\n        name: func(sorted_indices, gt_indices)\n        for name, func in metrics.items()\n    }\n    \n    l2_dist = torch.cat(l2_distances, dim=0).mean().item()\n    results['l2_dist'] = l2_dist\n    \n    return results\n\ndef eval_on_val(x_val: np.ndarray, y_val: np.ndarray, model: Translator, device) -> dict:\n    gt_indices = torch.arange(len(y_val))\n    \n    model.eval()\n\n    with torch.inference_mode():\n        translated = model(x_val.to(device)).to('cpu')\n\n    results = evaluate_retrieval(translated, y_val, gt_indices)\n    \n    return results\n\ndef generate_submission(model: Translator, test_path: Path, output_file=\"submission.csv\", device=None):\n    test_data = np.load(test_path)\n    sample_ids = test_data['captions/ids']\n    test_embds = test_data['captions/embeddings']\n    test_embds = torch.from_numpy(test_embds).float()\n\n    with torch.no_grad():\n        pred_embds = model(test_embds.to(device)).cpu()\n\n    print(\"Generating submission file...\")\n\n    if isinstance(pred_embds, torch.Tensor):\n        pred_embds = pred_embds.cpu().numpy()\n\n    df_submission = pd.DataFrame({'id': sample_ids, 'embedding': pred_embds.tolist()})\n\n    df_submission.to_csv(output_file, index=False, float_format='%.17g')\n    print(f\"✓ Saved submission to {output_file}\")\n\n    return df_submission","metadata":{"execution":{"iopub.status.busy":"2025-11-03T20:56:38.347121Z","iopub.execute_input":"2025-11-03T20:56:38.347602Z","iopub.status.idle":"2025-11-03T20:56:38.362369Z","shell.execute_reply.started":"2025-11-03T20:56:38.347579Z","shell.execute_reply":"2025-11-03T20:56:38.361662Z"},"trusted":true},"outputs":[],"execution_count":19},{"cell_type":"markdown","source":"### configs","metadata":{}},{"cell_type":"markdown","source":"### main.py","metadata":{}},{"cell_type":"code","source":"from torch.utils.data import TensorDataset, DataLoader\nfrom torch.utils.data import random_split\nfrom tqdm import tqdm\n\n\ndef info_nce_loss(preds_norm, targets_norm, logit_scale):\n    logits = (preds_norm @ targets_norm.T) / logit_scale.exp()\n    labels = torch.arange(logits.size(0), device=logits.device)\n\n    loss_t2i = F.cross_entropy(logits, labels)          \n    loss_i2t = F.cross_entropy(logits.T, labels)        \n    \n    return 0.5 * (loss_t2i + loss_i2t)\n\n\ndef mse_loss(preds, targets):\n    pred_norms = preds.norm(dim=-1)\n    target_norms = targets.norm(dim=-1)\n    \n    return F.mse_loss(pred_norms, target_norms)\n\n\ndef combined_loss(preds: torch.Tensor, targets: torch.Tensor, logit_scale: float, lamb: float = 1.0):\n    preds_norm = F.normalize(preds, p=2, dim=1)\n    targets_norm = F.normalize(targets, p=2, dim=1)\n\n    l1 = info_nce_loss(preds_norm, targets_norm, logit_scale)\n    l2 = mse_loss(preds, targets)\n\n    return l1 + lamb * l2\n\n\ndef train_model(\n    model: Translator,\n    model_path: Path,\n    train_dataset: TensorDataset,\n    val_dataset: TensorDataset,\n    batch_size: int,\n    epochs: int,\n    lr: float,\n    patience: int,\n    temp: float,\n    lambda_mag: float\n) -> Translator:    \n    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\n    print(f\"Using device: {device}\")\n    \n    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n    val_loader = DataLoader(val_dataset, batch_size=batch_size)\n    \n    optimizer = torch.optim.AdamW(model.parameters(), lr=lr, weight_decay=1e-4)\n\n    best_val_loss = float('inf')\n    no_improvements = 0\n\n    for epoch in range(epochs):\n        model.train()\n\n        train_loss = 0\n        for X_batch, y_batch in tqdm(train_loader, desc=f\"Epoch {epoch+1}/{epochs}\"):\n            X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n\n            optimizer.zero_grad()\n\n            outputs = model(X_batch)\n\n            loss = combined_loss(outputs, y_batch, model.logit_scale, lambda_mag)\n            \n            loss.backward()\n\n            optimizer.step()\n\n            train_loss += loss.item()\n\n        train_loss /= len(train_loader)\n\n        model.eval()\n\n        val_loss = 0\n\n        with torch.no_grad():\n            for X_batch, y_batch in val_loader:\n                X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n                outputs = model(X_batch)\n                \n                loss = combined_loss(outputs, y_batch, model.logit_scale, lambda_mag)\n                \n                val_loss += loss.item()\n\n        val_loss /= len(val_loader)\n\n        print(f\"Epoch {epoch+1}: Train Loss = {train_loss:.6f}, Val Loss = {val_loss:.6f}\")\n        test(val_dataset, model, device)\n\n\n        if val_loss < best_val_loss:\n            best_val_loss = val_loss\n            no_improvements = 0\n\n            Path(model_path).parent.mkdir(parents=True, exist_ok=True)\n\n            torch.save(model.state_dict(), model_path)\n\n            print(f\"✓ Saved best model (val_loss={val_loss:.6f})\")\n        elif no_improvements >= patience:\n            return model\n        else:\n            no_improvements += 1\n\n    return model\n\n\n\ndef load_data(data_path: Path):\n    data = np.load(data_path)\n    caption_embeddings = data['captions/embeddings']\n    image_embeddings = data['images/embeddings']\n    caption_labels = data['captions/label']\n\n    X_abs, y_abs = torch.tensor(caption_embeddings), torch.tensor(image_embeddings[np.argmax(caption_labels, axis=1)])\n    \n    print('Texts shape', X_abs.shape)\n    print('Images shape', X_abs.shape)\n\n    def print_stats():\n        mean_X = X_abs.mean(dim=0)\n        std_X = X_abs.std(dim=0)\n        \n        mean_Y = y_abs.mean(dim=0)\n        std_Y = y_abs.std(dim=0)\n\n        print(\"X: mean of stds per dim =\", std_X.mean().item(), \", max =\", std_X.max().item(), \", min =\", std_X.min().item())\n        print(\"Y: mean of stds per dim =\", std_Y.mean().item(), \", max =\", std_Y.max().item(), \", min =\", std_Y.min().item())\n\n    print_stats()\n    \n    dataset = TensorDataset(X_abs, y_abs)\n    train_dataset, val_dataset = random_split(dataset, [0.9, 0.1], generator=torch.Generator().manual_seed(42))\n    \n    return train_dataset, val_dataset\n\n\ndef test(val_dataset: TensorDataset, model: Translator, device):\n    val_loader = DataLoader(val_dataset, batch_size=len(val_dataset))\n    for x_val, y_val in val_loader:\n        results = eval_on_val(x_val, y_val, model=model, device=device)\n    return results","metadata":{"execution":{"iopub.status.busy":"2025-11-03T20:56:41.111275Z","iopub.execute_input":"2025-11-03T20:56:41.111574Z","iopub.status.idle":"2025-11-03T20:56:41.126990Z","shell.execute_reply.started":"2025-11-03T20:56:41.111550Z","shell.execute_reply":"2025-11-03T20:56:41.126172Z"},"trusted":true},"outputs":[],"execution_count":20},{"cell_type":"code","source":"device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\nbatch_size= 2048\nlr= 0.001\nepochs= 200\npatience = 10\ntemp = 0.011284474643610163\nlambda_mag = 0.7763296874424117\ndropout_rate = 0.3","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-03T20:58:14.848365Z","iopub.execute_input":"2025-11-03T20:58:14.848885Z","iopub.status.idle":"2025-11-03T20:58:14.853055Z","shell.execute_reply.started":"2025-11-03T20:58:14.848862Z","shell.execute_reply":"2025-11-03T20:58:14.852362Z"}},"outputs":[],"execution_count":24},{"cell_type":"code","source":"data_path= '/kaggle/input/aml-competition/train/train/train.npz'\ntest_path= '/kaggle/input/aml-competition/test/test/test.clean.npz'\n\nmodel_save_path= './models/exp1.pth'\n\ntrain_dataset, val_dataset = load_data(data_path)","metadata":{"execution":{"iopub.status.busy":"2025-11-03T20:58:16.292988Z","iopub.execute_input":"2025-11-03T20:58:16.293526Z","iopub.status.idle":"2025-11-03T20:58:31.701241Z","shell.execute_reply.started":"2025-11-03T20:58:16.293502Z","shell.execute_reply":"2025-11-03T20:58:31.700458Z"},"trusted":true},"outputs":[{"name":"stdout","text":"Texts shape torch.Size([125000, 1024])\nImages shape torch.Size([125000, 1024])\nX: mean of stds per dim = 0.788078248500824 , max = 3.573546886444092 , min = 0.3716050386428833\nY: mean of stds per dim = 0.4244377911090851 , max = 1.8597956895828247 , min = 0.08161858469247818\n","output_type":"stream"}],"execution_count":25},{"cell_type":"code","source":"model_args = {\n    'input_dim': 1024,\n    'output_dim': 1536,\n    'dir_hidden_dims': [2048, 2048],\n    'scale_hidden_dims': [1024, 1024],\n    'activation': nn.GELU,\n    'dropout_rate': dropout_rate\n}\nmodel = Translator(**model_args).to(device)\n\ntrain_model(model, model_save_path, train_dataset, val_dataset, batch_size, epochs, lr, patience, temp, lambda_mag)\n\nprint('Finished training. Now testing using best model...')\n\nstate = torch.load(model_save_path)\nmodel.load_state_dict(state)\nresults = test(val_dataset, model, device)\n\nprint(\"Test Results:\", results)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-03T20:59:01.651422Z","iopub.execute_input":"2025-11-03T20:59:01.651928Z","iopub.status.idle":"2025-11-03T21:01:47.266561Z","shell.execute_reply.started":"2025-11-03T20:59:01.651902Z","shell.execute_reply":"2025-11-03T21:01:47.265577Z"}},"outputs":[{"name":"stdout","text":"Using device: cuda\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1/200: 100%|██████████| 55/55 [00:03<00:00, 18.20it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 1: Train Loss = 25.285440, Val Loss = 8.752539\n✓ Saved best model (val_loss=8.752539)\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2/200: 100%|██████████| 55/55 [00:02<00:00, 18.36it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 2: Train Loss = 9.728263, Val Loss = 8.655740\n✓ Saved best model (val_loss=8.655740)\n","output_type":"stream"},{"name":"stderr","text":"Epoch 3/200: 100%|██████████| 55/55 [00:03<00:00, 18.31it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 3: Train Loss = 9.568067, Val Loss = 8.625210\n✓ Saved best model (val_loss=8.625210)\n","output_type":"stream"},{"name":"stderr","text":"Epoch 4/200: 100%|██████████| 55/55 [00:03<00:00, 18.10it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 4: Train Loss = 9.457265, Val Loss = 8.607217\n✓ Saved best model (val_loss=8.607217)\n","output_type":"stream"},{"name":"stderr","text":"Epoch 5/200: 100%|██████████| 55/55 [00:03<00:00, 18.29it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 5: Train Loss = 9.392669, Val Loss = 8.569085\n✓ Saved best model (val_loss=8.569085)\n","output_type":"stream"},{"name":"stderr","text":"Epoch 6/200: 100%|██████████| 55/55 [00:02<00:00, 18.42it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 6: Train Loss = 9.328710, Val Loss = 8.557086\n✓ Saved best model (val_loss=8.557086)\n","output_type":"stream"},{"name":"stderr","text":"Epoch 7/200: 100%|██████████| 55/55 [00:03<00:00, 18.31it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 7: Train Loss = 9.287960, Val Loss = 8.564676\n","output_type":"stream"},{"name":"stderr","text":"Epoch 8/200: 100%|██████████| 55/55 [00:02<00:00, 18.35it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 8: Train Loss = 9.235717, Val Loss = 8.527882\n✓ Saved best model (val_loss=8.527882)\n","output_type":"stream"},{"name":"stderr","text":"Epoch 9/200: 100%|██████████| 55/55 [00:03<00:00, 17.39it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 9: Train Loss = 9.201323, Val Loss = 8.509953\n✓ Saved best model (val_loss=8.509953)\n","output_type":"stream"},{"name":"stderr","text":"Epoch 10/200: 100%|██████████| 55/55 [00:03<00:00, 17.43it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 10: Train Loss = 9.172704, Val Loss = 8.500538\n✓ Saved best model (val_loss=8.500538)\n","output_type":"stream"},{"name":"stderr","text":"Epoch 11/200: 100%|██████████| 55/55 [00:03<00:00, 17.45it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 11: Train Loss = 9.143517, Val Loss = 8.516369\n","output_type":"stream"},{"name":"stderr","text":"Epoch 12/200: 100%|██████████| 55/55 [00:03<00:00, 17.60it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 12: Train Loss = 9.110879, Val Loss = 8.486452\n✓ Saved best model (val_loss=8.486452)\n","output_type":"stream"},{"name":"stderr","text":"Epoch 13/200: 100%|██████████| 55/55 [00:03<00:00, 18.11it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 13: Train Loss = 9.080006, Val Loss = 8.474337\n✓ Saved best model (val_loss=8.474337)\n","output_type":"stream"},{"name":"stderr","text":"Epoch 14/200: 100%|██████████| 55/55 [00:03<00:00, 18.32it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 14: Train Loss = 9.050531, Val Loss = 8.500418\n","output_type":"stream"},{"name":"stderr","text":"Epoch 15/200: 100%|██████████| 55/55 [00:03<00:00, 17.38it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 15: Train Loss = 9.025435, Val Loss = 8.434955\n✓ Saved best model (val_loss=8.434955)\n","output_type":"stream"},{"name":"stderr","text":"Epoch 16/200: 100%|██████████| 55/55 [00:03<00:00, 17.52it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 16: Train Loss = 9.017629, Val Loss = 8.434065\n✓ Saved best model (val_loss=8.434065)\n","output_type":"stream"},{"name":"stderr","text":"Epoch 17/200: 100%|██████████| 55/55 [00:03<00:00, 17.41it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 17: Train Loss = 8.986767, Val Loss = 8.413875\n✓ Saved best model (val_loss=8.413875)\n","output_type":"stream"},{"name":"stderr","text":"Epoch 18/200: 100%|██████████| 55/55 [00:03<00:00, 17.58it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 18: Train Loss = 8.966143, Val Loss = 8.421333\n","output_type":"stream"},{"name":"stderr","text":"Epoch 19/200: 100%|██████████| 55/55 [00:03<00:00, 17.43it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 19: Train Loss = 8.946474, Val Loss = 8.438383\n","output_type":"stream"},{"name":"stderr","text":"Epoch 20/200: 100%|██████████| 55/55 [00:03<00:00, 17.64it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 20: Train Loss = 8.924216, Val Loss = 8.385660\n✓ Saved best model (val_loss=8.385660)\n","output_type":"stream"},{"name":"stderr","text":"Epoch 21/200: 100%|██████████| 55/55 [00:03<00:00, 18.19it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 21: Train Loss = 8.894061, Val Loss = 8.389205\n","output_type":"stream"},{"name":"stderr","text":"Epoch 22/200: 100%|██████████| 55/55 [00:03<00:00, 17.59it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 22: Train Loss = 8.866160, Val Loss = 8.393365\n","output_type":"stream"},{"name":"stderr","text":"Epoch 23/200: 100%|██████████| 55/55 [00:03<00:00, 17.47it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 23: Train Loss = 8.834946, Val Loss = 8.364804\n✓ Saved best model (val_loss=8.364804)\n","output_type":"stream"},{"name":"stderr","text":"Epoch 24/200: 100%|██████████| 55/55 [00:03<00:00, 17.55it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 24: Train Loss = 8.793158, Val Loss = 8.310293\n✓ Saved best model (val_loss=8.310293)\n","output_type":"stream"},{"name":"stderr","text":"Epoch 25/200: 100%|██████████| 55/55 [00:03<00:00, 18.32it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 25: Train Loss = 8.766323, Val Loss = 8.279573\n✓ Saved best model (val_loss=8.279573)\n","output_type":"stream"},{"name":"stderr","text":"Epoch 26/200: 100%|██████████| 55/55 [00:02<00:00, 18.41it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 26: Train Loss = 8.736307, Val Loss = 8.278984\n✓ Saved best model (val_loss=8.278984)\n","output_type":"stream"},{"name":"stderr","text":"Epoch 27/200: 100%|██████████| 55/55 [00:03<00:00, 17.53it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 27: Train Loss = 8.698032, Val Loss = 8.231020\n✓ Saved best model (val_loss=8.231020)\n","output_type":"stream"},{"name":"stderr","text":"Epoch 28/200: 100%|██████████| 55/55 [00:03<00:00, 17.51it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 28: Train Loss = 8.652296, Val Loss = 8.235891\n","output_type":"stream"},{"name":"stderr","text":"Epoch 29/200: 100%|██████████| 55/55 [00:03<00:00, 17.54it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 29: Train Loss = 8.614051, Val Loss = 8.198982\n✓ Saved best model (val_loss=8.198982)\n","output_type":"stream"},{"name":"stderr","text":"Epoch 30/200: 100%|██████████| 55/55 [00:03<00:00, 17.68it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 30: Train Loss = 8.557338, Val Loss = 8.141220\n✓ Saved best model (val_loss=8.141220)\n","output_type":"stream"},{"name":"stderr","text":"Epoch 31/200: 100%|██████████| 55/55 [00:03<00:00, 17.48it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 31: Train Loss = 8.502890, Val Loss = 8.129197\n✓ Saved best model (val_loss=8.129197)\n","output_type":"stream"},{"name":"stderr","text":"Epoch 32/200: 100%|██████████| 55/55 [00:03<00:00, 17.50it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 32: Train Loss = 8.452228, Val Loss = 8.096118\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_37/1021908986.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTranslator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mmodel_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_save_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpatience\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtemp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlambda_mag\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Finished training. Now testing using best model...'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tmp/ipykernel_37/4087658322.py\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(model, model_path, train_dataset, val_dataset, batch_size, epochs, lr, patience, temp, lambda_mag)\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Epoch {epoch+1}: Train Loss = {train_loss:.6f}, Val Loss = {val_loss:.6f}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 94\u001b[0;31m         \u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     95\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tmp/ipykernel_37/4087658322.py\u001b[0m in \u001b[0;36mtest\u001b[0;34m(val_dataset, model, device)\u001b[0m\n\u001b[1;32m    145\u001b[0m     \u001b[0mval_loader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDataLoader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_dataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    146\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mx_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_val\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mval_loader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 147\u001b[0;31m         \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0meval_on_val\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    148\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tmp/ipykernel_37/30477537.py\u001b[0m in \u001b[0;36meval_on_val\u001b[0;34m(x_val, y_val, model, device)\u001b[0m\n\u001b[1;32m    138\u001b[0m         \u001b[0mtranslated\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_val\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'cpu'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 140\u001b[0;31m     \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluate_retrieval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtranslated\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgt_indices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    141\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    142\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/utils/_contextlib.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    114\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mctx_factory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 116\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    117\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tmp/ipykernel_37/30477537.py\u001b[0m in \u001b[0;36mevaluate_retrieval\u001b[0;34m(translated_embd, image_embd, gt_indices, max_indices, batch_size)\u001b[0m\n\u001b[1;32m     97\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m         \u001b[0;31m# Get top-k predictions for this batch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 99\u001b[0;31m         \u001b[0mbatch_indices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch_similarity\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtopk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_indices\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msorted\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    100\u001b[0m         \u001b[0mall_sorted_indices\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgt_indices\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbatch_slice\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbatch_indices\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "],"ename":"KeyboardInterrupt","evalue":"","output_type":"error"}],"execution_count":26},{"cell_type":"code","source":"generate_submission(model, Path(test_path), device=device)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-03T07:57:30.336752Z","iopub.execute_input":"2025-11-03T07:57:30.337364Z","iopub.status.idle":"2025-11-03T07:57:33.328460Z","shell.execute_reply.started":"2025-11-03T07:57:30.337338Z","shell.execute_reply":"2025-11-03T07:57:33.327620Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from torchsummary import summary\nsummary(model, input_size=(1024,))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-02T21:32:03.639415Z","iopub.execute_input":"2025-11-02T21:32:03.640170Z","iopub.status.idle":"2025-11-02T21:32:03.648865Z","shell.execute_reply.started":"2025-11-02T21:32:03.640136Z","shell.execute_reply":"2025-11-02T21:32:03.648189Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import optuna\nfrom optuna.pruners import MedianPruner\nfrom pathlib import Path\n\nACTIVATIONS = {\n    #\"relu\": nn.ReLU,\n    \"gelu\": nn.GELU,\n    \"silu\": nn.SiLU,\n    'selu': nn.SELU,\n    'celu': nn.CELU\n    #\"leakyrelu\": nn.LeakyReLU\n}\n\ndef objective(trial, train_dataset, val_dataset, input_dim, output_dim, epochs: int = 10, device=None):\n    if device is None:\n        device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\n    # --- Hyperparametri ---\n    dir_n_layers = trial.suggest_int(\"dir_n_layers\", 1, 6)\n    dir_hidden_dims_choices = [1024, 1536, 2048, 4096]\n    dir_hidden_dims = [trial.suggest_categorical(f\"dir_l{i}_units\", dir_hidden_dims_choices) for i in range(dir_n_layers)]\n\n    scale_n_layers = trial.suggest_int(\"scale_n_layers\", 1, 6)\n    scale_hidden_dims_choices = [128, 256, 512, 1024, 1536, 2048, 4096]\n    scale_hidden_dims = [trial.suggest_categorical(f\"scale_l{i}_units\", scale_hidden_dims_choices) for i in range(scale_n_layers)]\n\n    activation_name = trial.suggest_categorical(\"activation\", list(ACTIVATIONS.keys()))\n    activation_fn = ACTIVATIONS[activation_name]\n\n    batch_size = trial.suggest_categorical(\"batch_size\", [128, 256, 512, 1024, 2048, 4096])\n    lr = trial.suggest_float(\"lr\", 1e-6, 1e-2, log=True)\n    dropout_rate = trial.suggest_categorical('dropout_rate', [0.1, 0.2, 0.25, 0.3])\n\n    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n\n    #temp = trial.suggest_float(\"temp\", 0.01, 0.2, log=True)\n    \n    lambda_mag = trial.suggest_float(\"lambda_mag\", 0.2, 1, log=True)\n\n    # --- Modello ---\n    model_args = {\n        'input_dim': input_dim,\n        'output_dim': output_dim,\n        'dir_hidden_dims': dir_hidden_dims,\n        'scale_hidden_dims': scale_hidden_dims,\n        'activation': activation_fn,\n        'dropout_rate': dropout_rate\n    }\n    model = Translator(**model_args).to(device)\n\n    optimizer = torch.optim.AdamW(model.parameters(), lr=lr, weight_decay=1e-4)\n\n    for epoch in range(epochs):\n        model.train()\n        train_loss = 0.0\n        \n        for X_batch, y_batch in train_loader:\n            X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n            optimizer.zero_grad()\n            \n            outputs = model(X_batch)\n            \n            loss = combined_loss(outputs, y_batch, model.logit_scale, lambda_mag)\n            \n            loss.backward()\n            \n            optimizer.step()\n            train_loss += loss.item()\n        \n        train_loss /= len(train_loader)\n\n        # --- Validation ---\n        model.eval()\n        \n        val_loss = 0.0\n        \n        with torch.no_grad():\n            for X_batch, y_batch in val_loader:\n                X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n        \n                outputs = model(X_batch)\n                val_loss += combined_loss(outputs, y_batch, model.logit_scale, lambda_mag).item()\n        \n        val_loss /= len(val_loader)\n\n        results = test(val_dataset, model, device)\n        trial.report(results['mrr'], epoch)\n\n        if trial.should_prune():\n            raise optuna.exceptions.TrialPruned()\n\n    return results['mrr']\n\n\ndef run_optuna_search(data_path: Path, n_trials: int = 30, epochs: int = 30, n_jobs: int = 1, sampler=None, pruner=None):\n    if pruner is None:\n        pruner = MedianPruner(n_startup_trials=5, n_warmup_steps=1)\n\n    train_dataset, val_dataset = load_data(data_path)\n    input_dim = train_dataset[0][0].shape[0]\n    output_dim = train_dataset[0][1].shape[0]\n\n    study = optuna.create_study(direction=\"maximize\", pruner=pruner)\n    func = lambda trial: objective(trial, train_dataset=train_dataset, val_dataset=val_dataset,\n                                   input_dim=input_dim, output_dim=output_dim,\n                                   epochs=epochs)\n    study.optimize(func, n_trials=n_trials, n_jobs=n_jobs)\n\n    print(\"Study statistics:\")\n    print(\"  Number of finished trials: \", len(study.trials))\n    print(\"  Best trial:\")\n    trial = study.best_trial\n    print(\"    Value: \", trial.value)\n    print(\"    Params: \")\n    for k, v in trial.params.items():\n        print(f\"      {k}: {v}\")\n\n    return study\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-03T21:02:31.844670Z","iopub.execute_input":"2025-11-03T21:02:31.845310Z","iopub.status.idle":"2025-11-03T21:02:32.169297Z","shell.execute_reply.started":"2025-11-03T21:02:31.845289Z","shell.execute_reply":"2025-11-03T21:02:32.168764Z"}},"outputs":[],"execution_count":27},{"cell_type":"code","source":"study = run_optuna_search(data_path=data_path, n_trials=500, epochs=10, n_jobs=1)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-03T21:02:53.668265Z","iopub.execute_input":"2025-11-03T21:02:53.668812Z"}},"outputs":[{"name":"stdout","text":"Texts shape torch.Size([125000, 1024])\nImages shape torch.Size([125000, 1024])\n","output_type":"stream"},{"name":"stderr","text":"[I 2025-11-03 21:03:09,042] A new study created in memory with name: no-name-cc70a51e-8e09-4843-a927-6c0caf0f91df\n","output_type":"stream"},{"name":"stdout","text":"X: mean of stds per dim = 0.788078248500824 , max = 3.573546886444092 , min = 0.3716050386428833\nY: mean of stds per dim = 0.4244377911090851 , max = 1.8597956895828247 , min = 0.08161858469247818\n","output_type":"stream"},{"name":"stderr","text":"[I 2025-11-03 21:04:03,121] Trial 0 finished with value: 0.6050784127383727 and parameters: {'dir_n_layers': 2, 'dir_l0_units': 2048, 'dir_l1_units': 1536, 'scale_n_layers': 2, 'scale_l0_units': 1536, 'scale_l1_units': 1024, 'activation': 'celu', 'batch_size': 4096, 'lr': 9.673498046526665e-05, 'dropout_rate': 0.3, 'lambda_mag': 0.4691544144696144}. Best is trial 0 with value: 0.6050784127383727.\n[I 2025-11-03 21:05:10,762] Trial 1 finished with value: 0.3886452068046552 and parameters: {'dir_n_layers': 3, 'dir_l0_units': 1024, 'dir_l1_units': 1024, 'dir_l2_units': 2048, 'scale_n_layers': 4, 'scale_l0_units': 512, 'scale_l1_units': 512, 'scale_l2_units': 4096, 'scale_l3_units': 1024, 'activation': 'gelu', 'batch_size': 256, 'lr': 2.7403039601983457e-06, 'dropout_rate': 0.3, 'lambda_mag': 0.33412562946208335}. Best is trial 0 with value: 0.6050784127383727.\n[I 2025-11-03 21:06:18,061] Trial 2 finished with value: 0.2633644598365897 and parameters: {'dir_n_layers': 6, 'dir_l0_units': 1024, 'dir_l1_units': 1024, 'dir_l2_units': 1024, 'dir_l3_units': 4096, 'dir_l4_units': 2048, 'dir_l5_units': 1536, 'scale_n_layers': 3, 'scale_l0_units': 128, 'scale_l1_units': 128, 'scale_l2_units': 1024, 'activation': 'selu', 'batch_size': 4096, 'lr': 3.026194562874811e-06, 'dropout_rate': 0.25, 'lambda_mag': 0.6728434892671455}. Best is trial 0 with value: 0.6050784127383727.\n[I 2025-11-03 21:07:17,947] Trial 3 finished with value: 0.739044794048756 and parameters: {'dir_n_layers': 3, 'dir_l0_units': 4096, 'dir_l1_units': 2048, 'dir_l2_units': 1024, 'scale_n_layers': 2, 'scale_l0_units': 1024, 'scale_l1_units': 512, 'activation': 'silu', 'batch_size': 512, 'lr': 0.00014681222412994577, 'dropout_rate': 0.2, 'lambda_mag': 0.6039711748473259}. Best is trial 3 with value: 0.739044794048756.\n[I 2025-11-03 21:09:17,247] Trial 4 finished with value: 0.5388983208148012 and parameters: {'dir_n_layers': 6, 'dir_l0_units': 4096, 'dir_l1_units': 4096, 'dir_l2_units': 4096, 'dir_l3_units': 4096, 'dir_l4_units': 1024, 'dir_l5_units': 4096, 'scale_n_layers': 1, 'scale_l0_units': 512, 'activation': 'gelu', 'batch_size': 1024, 'lr': 1.2506710431696383e-05, 'dropout_rate': 0.25, 'lambda_mag': 0.5614511992448413}. Best is trial 3 with value: 0.739044794048756.\n[I 2025-11-03 21:09:43,236] Trial 5 pruned. \n[I 2025-11-03 21:09:54,422] Trial 6 pruned. \n[I 2025-11-03 21:10:04,789] Trial 7 pruned. \n[I 2025-11-03 21:11:07,951] Trial 8 finished with value: 0.7059989535770217 and parameters: {'dir_n_layers': 5, 'dir_l0_units': 1536, 'dir_l1_units': 1536, 'dir_l2_units': 1024, 'dir_l3_units': 4096, 'dir_l4_units': 1536, 'scale_n_layers': 2, 'scale_l0_units': 512, 'scale_l1_units': 256, 'activation': 'silu', 'batch_size': 512, 'lr': 9.483273107906124e-05, 'dropout_rate': 0.2, 'lambda_mag': 0.3711985378372735}. Best is trial 3 with value: 0.739044794048756.\n[I 2025-11-03 21:12:08,408] Trial 9 finished with value: 0.8939954594193107 and parameters: {'dir_n_layers': 3, 'dir_l0_units': 2048, 'dir_l1_units': 1024, 'dir_l2_units': 1024, 'scale_n_layers': 4, 'scale_l0_units': 256, 'scale_l1_units': 512, 'scale_l2_units': 2048, 'scale_l3_units': 4096, 'activation': 'selu', 'batch_size': 512, 'lr': 0.002001433274786925, 'dropout_rate': 0.25, 'lambda_mag': 0.7698692903280898}. Best is trial 9 with value: 0.8939954594193107.\n[I 2025-11-03 21:13:35,568] Trial 10 finished with value: 0.9067675228329911 and parameters: {'dir_n_layers': 1, 'dir_l0_units': 2048, 'scale_n_layers': 6, 'scale_l0_units': 256, 'scale_l1_units': 2048, 'scale_l2_units': 512, 'scale_l3_units': 4096, 'scale_l4_units': 256, 'scale_l5_units': 1536, 'activation': 'selu', 'batch_size': 128, 'lr': 0.004565679225694776, 'dropout_rate': 0.1, 'lambda_mag': 0.9884848664862191}. Best is trial 10 with value: 0.9067675228329911.\n[I 2025-11-03 21:15:02,610] Trial 11 finished with value: 0.904773772332163 and parameters: {'dir_n_layers': 1, 'dir_l0_units': 2048, 'scale_n_layers': 6, 'scale_l0_units': 256, 'scale_l1_units': 2048, 'scale_l2_units': 512, 'scale_l3_units': 4096, 'scale_l4_units': 256, 'scale_l5_units': 1536, 'activation': 'selu', 'batch_size': 128, 'lr': 0.006102035075903921, 'dropout_rate': 0.1, 'lambda_mag': 0.9725084452710921}. Best is trial 10 with value: 0.9067675228329911.\n[I 2025-11-03 21:16:29,733] Trial 12 finished with value: 0.9075144366924258 and parameters: {'dir_n_layers': 1, 'dir_l0_units': 2048, 'scale_n_layers': 6, 'scale_l0_units': 256, 'scale_l1_units': 2048, 'scale_l2_units': 512, 'scale_l3_units': 4096, 'scale_l4_units': 256, 'scale_l5_units': 1536, 'activation': 'selu', 'batch_size': 128, 'lr': 0.008200772113828646, 'dropout_rate': 0.1, 'lambda_mag': 0.9237467253430673}. Best is trial 12 with value: 0.9075144366924258.\n[I 2025-11-03 21:18:00,923] Trial 13 finished with value: 0.8986283073167716 and parameters: {'dir_n_layers': 1, 'dir_l0_units': 2048, 'scale_n_layers': 6, 'scale_l0_units': 2048, 'scale_l1_units': 2048, 'scale_l2_units': 512, 'scale_l3_units': 256, 'scale_l4_units': 256, 'scale_l5_units': 1536, 'activation': 'selu', 'batch_size': 128, 'lr': 0.0011923337486289436, 'dropout_rate': 0.1, 'lambda_mag': 0.9999678465566132}. Best is trial 12 with value: 0.9075144366924258.\n[I 2025-11-03 21:20:04,223] Trial 14 finished with value: 0.902326343127864 and parameters: {'dir_n_layers': 2, 'dir_l0_units': 1536, 'dir_l1_units': 2048, 'scale_n_layers': 5, 'scale_l0_units': 256, 'scale_l1_units': 4096, 'scale_l2_units': 256, 'scale_l3_units': 4096, 'scale_l4_units': 4096, 'activation': 'selu', 'batch_size': 128, 'lr': 0.009587794926998326, 'dropout_rate': 0.1, 'lambda_mag': 0.8179233019107148}. Best is trial 12 with value: 0.9075144366924258.\n[I 2025-11-03 21:22:10,398] Trial 15 finished with value: 0.8832708162601158 and parameters: {'dir_n_layers': 2, 'dir_l0_units': 2048, 'dir_l1_units': 4096, 'scale_n_layers': 6, 'scale_l0_units': 256, 'scale_l1_units': 2048, 'scale_l2_units': 1536, 'scale_l3_units': 1536, 'scale_l4_units': 2048, 'scale_l5_units': 1536, 'activation': 'selu', 'batch_size': 128, 'lr': 0.000758269470041583, 'dropout_rate': 0.1, 'lambda_mag': 0.8357662785942562}. Best is trial 12 with value: 0.9075144366924258.\n[I 2025-11-03 21:23:29,751] Trial 16 finished with value: 0.9049959137502529 and parameters: {'dir_n_layers': 1, 'dir_l0_units': 2048, 'scale_n_layers': 5, 'scale_l0_units': 256, 'scale_l1_units': 2048, 'scale_l2_units': 512, 'scale_l3_units': 128, 'scale_l4_units': 256, 'activation': 'selu', 'batch_size': 128, 'lr': 0.002932905596827614, 'dropout_rate': 0.1, 'lambda_mag': 0.24881112214237577}. Best is trial 12 with value: 0.9075144366924258.\n[I 2025-11-03 21:24:04,769] Trial 17 pruned. \n[I 2025-11-03 21:25:01,248] Trial 18 finished with value: 0.8951275443598529 and parameters: {'dir_n_layers': 1, 'dir_l0_units': 4096, 'scale_n_layers': 6, 'scale_l0_units': 1024, 'scale_l1_units': 1536, 'scale_l2_units': 512, 'scale_l3_units': 4096, 'scale_l4_units': 128, 'scale_l5_units': 2048, 'activation': 'gelu', 'batch_size': 1024, 'lr': 0.004143613839867919, 'dropout_rate': 0.1, 'lambda_mag': 0.7381958864238343}. Best is trial 12 with value: 0.9075144366924258.\n[I 2025-11-03 21:25:25,757] Trial 19 pruned. \n[I 2025-11-03 21:27:18,256] Trial 20 finished with value: 0.9080268795762106 and parameters: {'dir_n_layers': 2, 'dir_l0_units': 2048, 'dir_l1_units': 2048, 'scale_n_layers': 6, 'scale_l0_units': 2048, 'scale_l1_units': 4096, 'scale_l2_units': 128, 'scale_l3_units': 512, 'scale_l4_units': 1536, 'scale_l5_units': 1024, 'activation': 'selu', 'batch_size': 128, 'lr': 0.00981085371179943, 'dropout_rate': 0.1, 'lambda_mag': 0.7206962379672956}. Best is trial 20 with value: 0.9080268795762106.\n[I 2025-11-03 21:29:10,602] Trial 21 finished with value: 0.908484482345458 and parameters: {'dir_n_layers': 2, 'dir_l0_units': 2048, 'dir_l1_units': 2048, 'scale_n_layers': 6, 'scale_l0_units': 2048, 'scale_l1_units': 4096, 'scale_l2_units': 128, 'scale_l3_units': 512, 'scale_l4_units': 1536, 'scale_l5_units': 1024, 'activation': 'selu', 'batch_size': 128, 'lr': 0.008985309125384058, 'dropout_rate': 0.1, 'lambda_mag': 0.7137830203317971}. Best is trial 21 with value: 0.908484482345458.\n[I 2025-11-03 21:31:00,815] Trial 22 finished with value: 0.9069908270650382 and parameters: {'dir_n_layers': 2, 'dir_l0_units': 2048, 'dir_l1_units': 2048, 'scale_n_layers': 5, 'scale_l0_units': 2048, 'scale_l1_units': 4096, 'scale_l2_units': 128, 'scale_l3_units': 512, 'scale_l4_units': 1536, 'activation': 'selu', 'batch_size': 128, 'lr': 0.00855278539697029, 'dropout_rate': 0.1, 'lambda_mag': 0.7176853793419085}. Best is trial 21 with value: 0.908484482345458.\n[I 2025-11-03 21:32:59,272] Trial 23 finished with value: 0.9061908292174248 and parameters: {'dir_n_layers': 2, 'dir_l0_units': 2048, 'dir_l1_units': 2048, 'scale_n_layers': 6, 'scale_l0_units': 2048, 'scale_l1_units': 4096, 'scale_l2_units': 128, 'scale_l3_units': 512, 'scale_l4_units': 1536, 'scale_l5_units': 1024, 'activation': 'selu', 'batch_size': 128, 'lr': 0.0017820981494911041, 'dropout_rate': 0.1, 'lambda_mag': 0.539435953228306}. Best is trial 21 with value: 0.908484482345458.\n[I 2025-11-03 21:33:23,432] Trial 24 pruned. \n[I 2025-11-03 21:34:27,215] Trial 25 pruned. \n[I 2025-11-03 21:34:42,289] Trial 26 pruned. \n[I 2025-11-03 21:35:02,335] Trial 27 pruned. \n[I 2025-11-03 21:35:18,057] Trial 28 pruned. \n[I 2025-11-03 21:35:34,861] Trial 29 pruned. \n[I 2025-11-03 21:35:45,127] Trial 30 pruned. \n[I 2025-11-03 21:37:44,951] Trial 31 finished with value: 0.9056872149742933 and parameters: {'dir_n_layers': 2, 'dir_l0_units': 2048, 'dir_l1_units': 2048, 'scale_n_layers': 5, 'scale_l0_units': 2048, 'scale_l1_units': 4096, 'scale_l2_units': 128, 'scale_l3_units': 512, 'scale_l4_units': 1536, 'activation': 'selu', 'batch_size': 128, 'lr': 0.00972734138818789, 'dropout_rate': 0.1, 'lambda_mag': 0.7205313239979612}. Best is trial 21 with value: 0.908484482345458.\n[I 2025-11-03 21:39:33,768] Trial 32 finished with value: 0.9058567852575303 and parameters: {'dir_n_layers': 2, 'dir_l0_units': 2048, 'dir_l1_units': 2048, 'scale_n_layers': 5, 'scale_l0_units': 2048, 'scale_l1_units': 1024, 'scale_l2_units': 128, 'scale_l3_units': 512, 'scale_l4_units': 1536, 'activation': 'selu', 'batch_size': 128, 'lr': 0.00571752004170031, 'dropout_rate': 0.1, 'lambda_mag': 0.7947230864280728}. Best is trial 21 with value: 0.908484482345458.\n[I 2025-11-03 21:40:00,735] Trial 33 pruned. \n[I 2025-11-03 21:41:11,903] Trial 34 pruned. \n[I 2025-11-03 21:41:34,304] Trial 35 pruned. \n[I 2025-11-03 21:42:26,560] Trial 36 pruned. \n[I 2025-11-03 21:42:39,415] Trial 37 pruned. \n[I 2025-11-03 21:42:56,551] Trial 38 pruned. \n[I 2025-11-03 21:43:07,328] Trial 39 pruned. \n[I 2025-11-03 21:43:18,017] Trial 40 pruned. \n[I 2025-11-03 21:44:46,816] Trial 41 finished with value: 0.9063409821863257 and parameters: {'dir_n_layers': 1, 'dir_l0_units': 2048, 'scale_n_layers': 6, 'scale_l0_units': 256, 'scale_l1_units': 2048, 'scale_l2_units': 512, 'scale_l3_units': 4096, 'scale_l4_units': 256, 'scale_l5_units': 1536, 'activation': 'selu', 'batch_size': 128, 'lr': 0.004989184481758295, 'dropout_rate': 0.1, 'lambda_mag': 0.9866663812687254}. Best is trial 21 with value: 0.908484482345458.\n[I 2025-11-03 21:46:15,221] Trial 42 finished with value: 0.9048456805681662 and parameters: {'dir_n_layers': 1, 'dir_l0_units': 2048, 'scale_n_layers': 6, 'scale_l0_units': 256, 'scale_l1_units': 2048, 'scale_l2_units': 512, 'scale_l3_units': 4096, 'scale_l4_units': 256, 'scale_l5_units': 1024, 'activation': 'selu', 'batch_size': 128, 'lr': 0.007417186459313886, 'dropout_rate': 0.1, 'lambda_mag': 0.9247538440699186}. Best is trial 21 with value: 0.908484482345458.\n[I 2025-11-03 21:46:25,242] Trial 43 pruned. \n[I 2025-11-03 21:47:11,628] Trial 44 pruned. \n[I 2025-11-03 21:47:28,361] Trial 45 pruned. \n[I 2025-11-03 21:49:10,439] Trial 46 finished with value: 0.9079273520156145 and parameters: {'dir_n_layers': 1, 'dir_l0_units': 1536, 'scale_n_layers': 6, 'scale_l0_units': 1024, 'scale_l1_units': 2048, 'scale_l2_units': 4096, 'scale_l3_units': 256, 'scale_l4_units': 256, 'scale_l5_units': 4096, 'activation': 'selu', 'batch_size': 128, 'lr': 0.006530377933945494, 'dropout_rate': 0.25, 'lambda_mag': 0.7580764328009179}. Best is trial 21 with value: 0.908484482345458.\n[I 2025-11-03 21:49:25,066] Trial 47 pruned. \n[I 2025-11-03 21:49:49,973] Trial 48 pruned. \n[I 2025-11-03 21:50:05,745] Trial 49 pruned. \n[I 2025-11-03 21:50:33,672] Trial 50 pruned. \n[I 2025-11-03 21:51:33,860] Trial 51 pruned. \n[I 2025-11-03 21:53:17,913] Trial 52 finished with value: 0.911619159094567 and parameters: {'dir_n_layers': 1, 'dir_l0_units': 2048, 'scale_n_layers': 6, 'scale_l0_units': 4096, 'scale_l1_units': 2048, 'scale_l2_units': 512, 'scale_l3_units': 128, 'scale_l4_units': 256, 'scale_l5_units': 128, 'activation': 'selu', 'batch_size': 128, 'lr': 0.006273968435224478, 'dropout_rate': 0.3, 'lambda_mag': 0.9999428276666952}. Best is trial 52 with value: 0.911619159094567.\n[I 2025-11-03 21:53:59,539] Trial 53 pruned. \n[I 2025-11-03 21:54:20,540] Trial 54 pruned. \n[I 2025-11-03 21:54:43,579] Trial 55 pruned. \n[I 2025-11-03 21:55:07,043] Trial 56 pruned. \n[I 2025-11-03 21:55:25,126] Trial 57 pruned. \n[I 2025-11-03 21:55:35,703] Trial 58 pruned. \n[I 2025-11-03 21:57:03,878] Trial 59 finished with value: 0.9112074568910393 and parameters: {'dir_n_layers': 1, 'dir_l0_units': 2048, 'scale_n_layers': 6, 'scale_l0_units': 2048, 'scale_l1_units': 512, 'scale_l2_units': 1536, 'scale_l3_units': 1024, 'scale_l4_units': 128, 'scale_l5_units': 256, 'activation': 'selu', 'batch_size': 128, 'lr': 0.006536729919652637, 'dropout_rate': 0.3, 'lambda_mag': 0.4313869765582368}. Best is trial 52 with value: 0.911619159094567.\n[I 2025-11-03 21:57:15,139] Trial 60 pruned. \n[I 2025-11-03 21:57:41,761] Trial 61 pruned. \n[I 2025-11-03 21:59:36,120] Trial 62 finished with value: 0.9113901244675398 and parameters: {'dir_n_layers': 1, 'dir_l0_units': 2048, 'scale_n_layers': 6, 'scale_l0_units': 2048, 'scale_l1_units': 4096, 'scale_l2_units': 1536, 'scale_l3_units': 1024, 'scale_l4_units': 128, 'scale_l5_units': 256, 'activation': 'selu', 'batch_size': 128, 'lr': 0.009742170651656232, 'dropout_rate': 0.3, 'lambda_mag': 0.4492045991497853}. Best is trial 52 with value: 0.911619159094567.\n[I 2025-11-03 22:00:11,547] Trial 63 pruned. \n[I 2025-11-03 22:01:39,737] Trial 64 finished with value: 0.9098615421311245 and parameters: {'dir_n_layers': 1, 'dir_l0_units': 2048, 'scale_n_layers': 6, 'scale_l0_units': 2048, 'scale_l1_units': 512, 'scale_l2_units': 1536, 'scale_l3_units': 1024, 'scale_l4_units': 128, 'scale_l5_units': 256, 'activation': 'selu', 'batch_size': 128, 'lr': 0.004998558678390906, 'dropout_rate': 0.3, 'lambda_mag': 0.49254823630207767}. Best is trial 52 with value: 0.911619159094567.\n[I 2025-11-03 22:01:51,299] Trial 65 pruned. \n[I 2025-11-03 22:03:27,922] Trial 66 finished with value: 0.9118359514436225 and parameters: {'dir_n_layers': 1, 'dir_l0_units': 2048, 'scale_n_layers': 6, 'scale_l0_units': 2048, 'scale_l1_units': 512, 'scale_l2_units': 1536, 'scale_l3_units': 1024, 'scale_l4_units': 128, 'scale_l5_units': 256, 'activation': 'selu', 'batch_size': 128, 'lr': 0.003443626107654058, 'dropout_rate': 0.3, 'lambda_mag': 0.4595158655553572}. Best is trial 66 with value: 0.9118359514436225.\n[I 2025-11-03 22:04:55,668] Trial 67 finished with value: 0.9090605782278101 and parameters: {'dir_n_layers': 1, 'dir_l0_units': 2048, 'scale_n_layers': 6, 'scale_l0_units': 2048, 'scale_l1_units': 512, 'scale_l2_units': 1536, 'scale_l3_units': 1024, 'scale_l4_units': 128, 'scale_l5_units': 256, 'activation': 'selu', 'batch_size': 128, 'lr': 0.003485942159632952, 'dropout_rate': 0.3, 'lambda_mag': 0.44637789069608774}. Best is trial 66 with value: 0.9118359514436225.\n[I 2025-11-03 22:06:23,519] Trial 68 finished with value: 0.9113887594839826 and parameters: {'dir_n_layers': 1, 'dir_l0_units': 2048, 'scale_n_layers': 6, 'scale_l0_units': 2048, 'scale_l1_units': 512, 'scale_l2_units': 1536, 'scale_l3_units': 1024, 'scale_l4_units': 128, 'scale_l5_units': 256, 'activation': 'selu', 'batch_size': 128, 'lr': 0.003558108483701608, 'dropout_rate': 0.3, 'lambda_mag': 0.46539976008030154}. Best is trial 66 with value: 0.9118359514436225.\n[I 2025-11-03 22:06:41,288] Trial 69 pruned. \n[I 2025-11-03 22:06:51,463] Trial 70 pruned. \n[I 2025-11-03 22:07:09,229] Trial 71 pruned. \n[I 2025-11-03 22:08:37,552] Trial 72 finished with value: 0.9124349584187953 and parameters: {'dir_n_layers': 1, 'dir_l0_units': 2048, 'scale_n_layers': 6, 'scale_l0_units': 2048, 'scale_l1_units': 512, 'scale_l2_units': 1536, 'scale_l3_units': 1024, 'scale_l4_units': 128, 'scale_l5_units': 256, 'activation': 'selu', 'batch_size': 128, 'lr': 0.004284659757441428, 'dropout_rate': 0.3, 'lambda_mag': 0.48564557105678446}. Best is trial 72 with value: 0.9124349584187953.\n[I 2025-11-03 22:09:47,521] Trial 73 finished with value: 0.9110051961208695 and parameters: {'dir_n_layers': 1, 'dir_l0_units': 2048, 'scale_n_layers': 1, 'scale_l0_units': 2048, 'activation': 'selu', 'batch_size': 128, 'lr': 0.003546501062374242, 'dropout_rate': 0.3, 'lambda_mag': 0.48442021895951876}. Best is trial 72 with value: 0.9124349584187953.\n[I 2025-11-03 22:10:01,738] Trial 74 pruned. \n[I 2025-11-03 22:10:17,355] Trial 75 pruned. \n[I 2025-11-03 22:10:28,448] Trial 76 pruned. \n[I 2025-11-03 22:11:38,341] Trial 77 finished with value: 0.9118138261579437 and parameters: {'dir_n_layers': 1, 'dir_l0_units': 2048, 'scale_n_layers': 1, 'scale_l0_units': 2048, 'activation': 'selu', 'batch_size': 128, 'lr': 0.003612230342503175, 'dropout_rate': 0.3, 'lambda_mag': 0.4283505367834018}. Best is trial 72 with value: 0.9124349584187953.\n[I 2025-11-03 22:11:52,218] Trial 78 pruned. \n[I 2025-11-03 22:12:01,126] Trial 79 pruned. \n[I 2025-11-03 22:12:10,811] Trial 80 pruned. \n[I 2025-11-03 22:13:21,092] Trial 81 finished with value: 0.9099635672010324 and parameters: {'dir_n_layers': 1, 'dir_l0_units': 2048, 'scale_n_layers': 1, 'scale_l0_units': 2048, 'activation': 'selu', 'batch_size': 128, 'lr': 0.004527834265925886, 'dropout_rate': 0.3, 'lambda_mag': 0.4606099986232414}. Best is trial 72 with value: 0.9124349584187953.\n[I 2025-11-03 22:13:35,086] Trial 82 pruned. \n[I 2025-11-03 22:14:45,373] Trial 83 finished with value: 0.9086506318582539 and parameters: {'dir_n_layers': 1, 'dir_l0_units': 2048, 'scale_n_layers': 1, 'scale_l0_units': 2048, 'activation': 'selu', 'batch_size': 128, 'lr': 0.00558681568477126, 'dropout_rate': 0.3, 'lambda_mag': 0.5222065501326127}. Best is trial 72 with value: 0.9124349584187953.\n[I 2025-11-03 22:15:06,899] Trial 84 pruned. \n[I 2025-11-03 22:16:17,014] Trial 85 finished with value: 0.9104342119030501 and parameters: {'dir_n_layers': 1, 'dir_l0_units': 2048, 'scale_n_layers': 1, 'scale_l0_units': 2048, 'activation': 'selu', 'batch_size': 128, 'lr': 0.004210924434092959, 'dropout_rate': 0.3, 'lambda_mag': 0.46143231905389326}. Best is trial 72 with value: 0.9124349584187953.\n[I 2025-11-03 22:16:37,133] Trial 86 pruned. \n[I 2025-11-03 22:17:57,531] Trial 87 finished with value: 0.9108701278102652 and parameters: {'dir_n_layers': 1, 'dir_l0_units': 2048, 'scale_n_layers': 2, 'scale_l0_units': 4096, 'scale_l1_units': 512, 'activation': 'selu', 'batch_size': 128, 'lr': 0.0038618291866976246, 'dropout_rate': 0.3, 'lambda_mag': 0.30475012270103985}. Best is trial 72 with value: 0.9124349584187953.\n[I 2025-11-03 22:18:07,857] Trial 88 pruned. \n[I 2025-11-03 22:18:26,645] Trial 89 pruned. \n","output_type":"stream"}],"execution_count":null},{"cell_type":"code","source":"study.trials_dataframe().to_csv(\"optuna_trials.csv\", index=False)\n\nbest_trial_number = study.best_trial.number\nprint(\"Best params:\", study.best_params)\nprint(\"Best trial number:\", study.best_trial.number)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-02T21:11:34.398889Z","iopub.status.idle":"2025-11-02T21:11:34.399102Z","shell.execute_reply.started":"2025-11-02T21:11:34.399003Z","shell.execute_reply":"2025-11-02T21:11:34.399012Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"","metadata":{}}]}