{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.13"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":117959,"databundleVersionId":14220991,"sourceType":"competition"}],"dockerImageVersionId":31154,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"### model.py","metadata":{}},{"cell_type":"code","source":"import torch\nfrom typing import Optional\nfrom torch import nn\nfrom torch.nn import functional as F\n\nclass Translator(nn.Module):\n    def __init__(\n        self,\n        input_dim: int,\n        output_dim: int,\n        dir_hidden_dims: list[int],\n        scale_hidden_dims: list[int],\n        activation=nn.ReLU,\n        dropout_rate: float=0.3\n    ):\n        super().__init__()\n\n        def build_mlp(hidden_dims, out_dim, apply_softplus=False):\n            layers = []\n            last_dim = input_dim\n            for hidden in hidden_dims:\n                layers += [\n                    nn.Linear(last_dim, hidden),\n                    activation(),\n                    #nn.LayerNorm(hidden),\n                    nn.Dropout(dropout_rate)\n                ]\n                last_dim = hidden\n            layers.append(nn.Linear(last_dim, out_dim))\n            \n            if apply_softplus:\n                layers.append(nn.Softplus())\n            \n            return nn.Sequential(*layers)\n\n        self.dir_head = build_mlp(dir_hidden_dims, output_dim, apply_softplus=False)\n        self.scale_head = build_mlp(scale_hidden_dims, 1, apply_softplus=True)\n        self.logit_scale = nn.Parameter(torch.ones([]) * np.log(1/0.07))\n\n        self.apply(self.init_weights)\n\n    def init_weights(self, module):\n        if isinstance(module, nn.Linear):\n            nn.init.xavier_uniform_(module.weight)\n            if module.bias is not None:\n                nn.init.constant_(module.bias, 0.0)\n        elif isinstance(module, nn.LayerNorm):\n            nn.init.ones_(module.weight)\n            nn.init.zeros_(module.bias)\n\n    def forward(self, x):\n        direction = F.normalize(self.dir_head(x), dim=-1)\n        scale = self.scale_head(x)\n        return direction * scale\n\n\n\ndef procrustes_align(X, Y, scale=True):\n    mu_X = X.mean(dim=0, keepdim=True)\n    mu_Y = Y.mean(dim=0, keepdim=True)\n\n    X_centered = X - mu_X\n    Y_centered = Y - mu_Y\n\n    C = X_centered.T @ Y_centered\n\n    U, S, Vt = torch.linalg.svd(C, full_matrices=True)\n    R = U @ Vt\n\n    if torch.det(R) < 0:\n        Vt[-1, :] *= -1\n        R = U @ Vt\n\n    if scale:\n        s = S.sum() / (X_centered ** 2).sum()\n    else:\n        s = 1.0\n\n    t = mu_Y.squeeze() - s * (mu_X @ R)\n\n    return R, s, t\n\ndef align_matrix(m: torch.Tensor, R, s, t):\n    return s * (m @ R) + t","metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.status.busy":"2025-10-31T17:46:15.538603Z","iopub.execute_input":"2025-10-31T17:46:15.539157Z","iopub.status.idle":"2025-10-31T17:46:15.550054Z","shell.execute_reply.started":"2025-10-31T17:46:15.539132Z","shell.execute_reply":"2025-10-31T17:46:15.549280Z"},"trusted":true},"outputs":[],"execution_count":43},{"cell_type":"markdown","source":"### eval.py","metadata":{}},{"cell_type":"code","source":"from pathlib import Path\nimport numpy as np\nimport torch\nimport pandas as pd\n\n'''Code from https://github.com/Mamiglia/challenge'''\n\ndef mrr(pred_indices: np.ndarray, gt_indices: np.ndarray) -> float:\n    \"\"\"\n    Compute Mean Reciprocal Rank (MRR)\n    Args:\n        pred_indices: (N, K) array of predicted indices for N queries (top-K)\n        gt_indices: (N,) array of ground truth indices\n    Returns:\n        mrr: Mean Reciprocal Rank\n    \"\"\"\n    reciprocal_ranks = []\n    for i in range(len(gt_indices)):\n        matches = np.where(pred_indices[i] == gt_indices[i])[0]\n        if matches.size > 0:\n            reciprocal_ranks.append(1.0 / (matches[0] + 1))\n        else:\n            reciprocal_ranks.append(0.0)\n    return np.mean(reciprocal_ranks)\n\n\ndef recall_at_k(pred_indices: np.ndarray, gt_indices: np.ndarray, k: int) -> float:\n    \"\"\"Compute Recall@k\n    Args:\n        pred_indices: (N, N) array of top indices for N queries\n        gt_indices: (N,) array of ground truth indices\n        k: number of top predictions to consider\n    Returns:\n        recall: Recall@k\n    \"\"\"\n    recall = 0\n    for i in range(len(gt_indices)):\n        if gt_indices[i] in pred_indices[i, :k]:\n            recall += 1\n    recall /= len(gt_indices)\n    return recall\n\nimport numpy as np\n\ndef ndcg(pred_indices: np.ndarray, gt_indices: np.ndarray, k: int = 100) -> float:\n    \"\"\"\n    Compute Normalized Discounted Cumulative Gain (NDCG@k)\n    Args:\n        pred_indices: (N, K) array of predicted indices for N queries\n        gt_indices: (N,) array of ground truth indices\n        k: number of top predictions to consider\n    Returns:\n        ndcg: NDCG@k\n    \"\"\"\n    ndcg_total = 0.0\n    for i in range(len(gt_indices)):\n        matches = np.where(pred_indices[i, :k] == gt_indices[i])[0]\n        if matches.size > 0:\n            rank = matches[0] + 1\n            ndcg_total += 1.0 / np.log2(rank + 1)  # DCG (IDCG = 1)\n    return ndcg_total / len(gt_indices)\n\n\n\n@torch.inference_mode()\ndef evaluate_retrieval(translated_embd, image_embd, gt_indices, max_indices = 99, batch_size=100):\n    \"\"\"Evaluate retrieval performance using cosine similarity\n    Args:\n        translated_embd: (N_captions, D) translated caption embeddings\n        image_embd: (N_images, D) image embeddings\n        gt_indices: (N_captions,) ground truth image indices for each caption\n        max_indices: number of top predictions to consider\n    Returns:\n        results: dict of evaluation metrics\n    \n    \"\"\"\n    # Compute similarity matrix\n    if isinstance(translated_embd, np.ndarray):\n        translated_embd = torch.from_numpy(translated_embd).float()\n    if isinstance(image_embd, np.ndarray):\n        image_embd = torch.from_numpy(image_embd).float()\n    \n    n_queries = translated_embd.shape[0]\n    device = translated_embd.device\n    \n    # Prepare containers for the fragments to be reassembled\n    all_sorted_indices = []\n    l2_distances = []\n    \n    # Process in batches - the narrow gate approach\n    for start_idx in range(0, n_queries, batch_size):\n        batch_slice = slice(start_idx, min(start_idx + batch_size, n_queries))\n        batch_translated = translated_embd[batch_slice]\n        batch_img_embd = image_embd[batch_slice]\n        \n        # Compute similarity only for this batch\n        batch_similarity = batch_translated @ batch_img_embd.T\n\n        # Get top-k predictions for this batch\n        batch_indices = batch_similarity.topk(k=max_indices, dim=1, sorted=True).indices.numpy()\n        all_sorted_indices.append(gt_indices[batch_slice][batch_indices])\n\n        # Compute L2 distance for this batch\n        batch_gt = gt_indices[batch_slice]\n        batch_gt_embeddings = image_embd[batch_gt]\n        batch_l2 = (batch_translated - batch_gt_embeddings).norm(dim=1)\n        l2_distances.append(batch_l2)\n    \n    # Reassemble the fragments\n    sorted_indices = np.concatenate(all_sorted_indices, axis=0)\n    \n    # Apply the sacred metrics to the whole\n    metrics = {\n        'mrr': mrr,\n        'ndcg': ndcg,\n        'recall_at_1': lambda preds, gt: recall_at_k(preds, gt, 1),\n        'recall_at_3': lambda preds, gt: recall_at_k(preds, gt, 3),\n        'recall_at_5': lambda preds, gt: recall_at_k(preds, gt, 5),\n        'recall_at_10': lambda preds, gt: recall_at_k(preds, gt, 10),\n        'recall_at_50': lambda preds, gt: recall_at_k(preds, gt, 50),\n    }\n    \n    results = {\n        name: func(sorted_indices, gt_indices)\n        for name, func in metrics.items()\n    }\n    \n    l2_dist = torch.cat(l2_distances, dim=0).mean().item()\n    results['l2_dist'] = l2_dist\n    \n    return results\n\ndef eval_on_val(x_val: np.ndarray, y_val: np.ndarray, model: Translator, device) -> dict:\n    gt_indices = torch.arange(len(y_val))\n    \n    model.eval()\n\n    with torch.inference_mode():\n        translated = model(x_val.to(device)).to('cpu')\n\n    results = evaluate_retrieval(translated, y_val, gt_indices)\n    \n    return results\n\ndef generate_submission(model: Translator, test_path: Path, output_file=\"submission.csv\", device=None, procrustes_data: tuple=()):\n    test_data = np.load(test_path)\n    sample_ids = test_data['captions/ids']\n    test_embds = test_data['captions/embeddings']\n    test_embds = torch.from_numpy(test_embds).float()\n    test_data.close()\n\n    with torch.no_grad():\n        pred_embds = model(test_embds.to(device)).cpu()\n\n    if procrustes_data:\n        print('Using Procrusted')\n        pred_embds = align_matrix(pred_embds, R, s, t)\n\n    print(\"Generating submission file...\")\n\n    if isinstance(pred_embds, torch.Tensor):\n        pred_embds = pred_embds.cpu().numpy()\n\n    df_submission = pd.DataFrame({'id': sample_ids, 'embedding': pred_embds.tolist()})\n\n    df_submission.to_csv(output_file, index=False, float_format='%.17g')\n    print(f\"✓ Saved submission to {output_file}\")\n\n    return df_submission","metadata":{"execution":{"iopub.status.busy":"2025-10-31T18:03:07.135211Z","iopub.execute_input":"2025-10-31T18:03:07.135711Z","iopub.status.idle":"2025-10-31T18:03:07.152855Z","shell.execute_reply.started":"2025-10-31T18:03:07.135686Z","shell.execute_reply":"2025-10-31T18:03:07.151932Z"},"trusted":true},"outputs":[],"execution_count":62},{"cell_type":"markdown","source":"### configs","metadata":{}},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"code","source":"\nimport numpy as np\nimport torch\nimport torch.nn.functional as F\nfrom torch.utils.data import TensorDataset, DataLoader\nfrom torch.utils.data import random_split\nfrom pathlib import Path\nfrom tqdm import tqdm\n\ndef info_nce_loss(dir_preds, img_targets, temp: float):\n    logits = (dir_preds @ img_targets.T) / temp\n    labels = torch.arange(logits.size(0), device=logits.device)\n    #loss = F.cross_entropy(logits, labels)    \n    #return loss\n    loss_t2i = F.cross_entropy(logits, labels)          \n    loss_i2t = F.cross_entropy(logits.T, labels)        \n    return 0.5 * (loss_t2i + loss_i2t)\n\n\ndef train_model(\n    model: Translator,\n    model_path: Path,\n    train_dataset: TensorDataset,\n    val_dataset: TensorDataset,\n    batch_size: int,\n    epochs: int,\n    lr: float,\n    patience: int\n) -> Translator:    \n    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\n    print(f\"Using device: {device}\")\n    \n    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n    val_loader = DataLoader(val_dataset, batch_size=batch_size)\n    \n    optimizer = torch.optim.AdamW(model.parameters(), lr=lr, weight_decay=1e-4)\n\n    best_val_loss = float('inf')\n    no_improvements = 0\n\n    for epoch in range(epochs):\n        model.train()\n\n        train_loss = 0\n        for X_batch, y_batch in tqdm(train_loader, desc=f\"Epoch {epoch+1}/{epochs}\"):\n            X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n            y_batch = F.normalize(y_batch, dim=-1)\n\n            optimizer.zero_grad()\n\n            outputs = model(X_batch)\n\n            loss = info_nce_loss(outputs, y_batch, temp=model.logit_scale)\n\n            loss.backward()\n\n            optimizer.step()\n\n            train_loss += loss.item()\n\n        train_loss /= len(train_loader)\n\n        model.eval()\n\n        val_loss = 0\n\n        with torch.no_grad():\n            for X_batch, y_batch in val_loader:\n                X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n                outputs = model(X_batch)\n\n                loss = info_nce_loss(outputs, y_batch, temp=model.logit_scale)\n\n                val_loss += loss.item()\n\n        val_loss /= len(val_loader)\n\n        print(f\"Epoch {epoch+1}: Train Loss = {train_loss:.6f}, Val Loss = {val_loss:.6f}\")\n        test(val_dataset, model, device)\n\n\n        if val_loss < best_val_loss:\n            best_val_loss = val_loss\n            no_improvements = 0\n\n            Path(model_path).parent.mkdir(parents=True, exist_ok=True)\n\n            torch.save(model.state_dict(), model_path)\n\n            print(f\"✓ Saved best model (val_loss={val_loss:.6f})\")\n        elif no_improvements >= patience:\n            return model\n        else:\n            no_improvements += 1\n\n    return model\n\n\n\ndef load_data(data_path: Path):\n    data = np.load(data_path)\n    caption_embeddings = data['captions/embeddings']\n    image_embeddings = data['images/embeddings']\n    caption_labels = data['captions/label']\n\n    X_abs, y_abs = torch.tensor(caption_embeddings), torch.tensor(image_embeddings[np.argmax(caption_labels, axis=1)])\n    \n    print('Texts shape', X_abs.shape)\n    print('Images shape', X_abs.shape)\n    \n    dataset = TensorDataset(X_abs, y_abs)\n    train_dataset, val_dataset = random_split(dataset, [0.9, 0.1], generator=torch.Generator().manual_seed(42))\n    \n    return train_dataset, val_dataset\n\n\ndef test(val_dataset: TensorDataset, model: Translator, device):\n    val_loader = DataLoader(val_dataset, batch_size=len(val_dataset))\n    for x_val, y_val in val_loader:\n        results = eval_on_val(x_val, y_val, model=model, device=device)\n    return results","metadata":{"execution":{"iopub.status.busy":"2025-10-31T17:10:45.350958Z","iopub.execute_input":"2025-10-31T17:10:45.351227Z","iopub.status.idle":"2025-10-31T17:10:45.365155Z","shell.execute_reply.started":"2025-10-31T17:10:45.351210Z","shell.execute_reply":"2025-10-31T17:10:45.364143Z"},"trusted":true},"outputs":[],"execution_count":26},{"cell_type":"code","source":"device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\n\nbatch_size= 1024\nlr= 0.0001\nepochs= 200\npatience = 5\n\ndata_path= '/kaggle/input/aml-competition/train/train/train.npz'\ntest_path= '/kaggle/input/aml-competition/test/test/test.clean.npz'\n\nmodel_save_path= './models/exp1.pth'\n\ntrain_dataset, val_dataset = load_data(data_path)","metadata":{"execution":{"iopub.status.busy":"2025-10-31T17:09:48.849028Z","iopub.execute_input":"2025-10-31T17:09:48.849300Z","iopub.status.idle":"2025-10-31T17:10:03.220412Z","shell.execute_reply.started":"2025-10-31T17:09:48.849281Z","shell.execute_reply":"2025-10-31T17:10:03.219696Z"},"trusted":true},"outputs":[{"name":"stdout","text":"Texts shape torch.Size([125000, 1024])\nImages shape torch.Size([125000, 1024])\n","output_type":"stream"}],"execution_count":24},{"cell_type":"code","source":"model_args = {\n    'input_dim': 1024,\n    'output_dim': 1536,\n    'dir_hidden_dims': [1024, 2048, 1024],\n    'scale_hidden_dims': [1024, 1024],\n    'activation': nn.SiLU,\n    'dropout_rate': 0.3\n}\nmodel = Translator(**model_args).to(device)\n\ntrain_model(model, model_save_path, train_dataset, val_dataset, batch_size, epochs, lr, patience)\n\nprint('Finished training. Now testing using best model...')\n\nstate = torch.load(model_save_path)\nmodel.load_state_dict(state)\nresults = test(val_dataset, model, device)\n\nprint(\"Test Results:\", results)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-31T17:23:36.651286Z","iopub.execute_input":"2025-10-31T17:23:36.651559Z","iopub.status.idle":"2025-10-31T17:26:47.817719Z","shell.execute_reply.started":"2025-10-31T17:23:36.651538Z","shell.execute_reply":"2025-10-31T17:26:47.816787Z"}},"outputs":[{"name":"stdout","text":"Using device: cuda\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1/200: 100%|██████████| 110/110 [00:03<00:00, 32.78it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 1: Train Loss = 4.667129, Val Loss = 41.517302\n✓ Saved best model (val_loss=41.517302)\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2/200: 100%|██████████| 110/110 [00:03<00:00, 34.23it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 2: Train Loss = 2.818234, Val Loss = 35.083778\n✓ Saved best model (val_loss=35.083778)\n","output_type":"stream"},{"name":"stderr","text":"Epoch 3/200: 100%|██████████| 110/110 [00:03<00:00, 32.47it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 3: Train Loss = 2.440394, Val Loss = 31.997264\n✓ Saved best model (val_loss=31.997264)\n","output_type":"stream"},{"name":"stderr","text":"Epoch 4/200: 100%|██████████| 110/110 [00:03<00:00, 32.50it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 4: Train Loss = 2.218421, Val Loss = 30.146695\n✓ Saved best model (val_loss=30.146695)\n","output_type":"stream"},{"name":"stderr","text":"Epoch 5/200: 100%|██████████| 110/110 [00:03<00:00, 32.39it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 5: Train Loss = 2.067796, Val Loss = 29.011839\n✓ Saved best model (val_loss=29.011839)\n","output_type":"stream"},{"name":"stderr","text":"Epoch 6/200: 100%|██████████| 110/110 [00:03<00:00, 32.46it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 6: Train Loss = 1.944504, Val Loss = 27.749160\n✓ Saved best model (val_loss=27.749160)\n","output_type":"stream"},{"name":"stderr","text":"Epoch 7/200: 100%|██████████| 110/110 [00:03<00:00, 32.47it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 7: Train Loss = 1.844366, Val Loss = 27.214054\n✓ Saved best model (val_loss=27.214054)\n","output_type":"stream"},{"name":"stderr","text":"Epoch 8/200: 100%|██████████| 110/110 [00:03<00:00, 32.78it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 8: Train Loss = 1.763212, Val Loss = 26.797282\n✓ Saved best model (val_loss=26.797282)\n","output_type":"stream"},{"name":"stderr","text":"Epoch 9/200: 100%|██████████| 110/110 [00:03<00:00, 32.93it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 9: Train Loss = 1.691858, Val Loss = 26.009679\n✓ Saved best model (val_loss=26.009679)\n","output_type":"stream"},{"name":"stderr","text":"Epoch 10/200: 100%|██████████| 110/110 [00:03<00:00, 33.97it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 10: Train Loss = 1.627888, Val Loss = 25.680139\n✓ Saved best model (val_loss=25.680139)\n","output_type":"stream"},{"name":"stderr","text":"Epoch 11/200: 100%|██████████| 110/110 [00:03<00:00, 32.86it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 11: Train Loss = 1.568089, Val Loss = 25.298645\n✓ Saved best model (val_loss=25.298645)\n","output_type":"stream"},{"name":"stderr","text":"Epoch 12/200: 100%|██████████| 110/110 [00:03<00:00, 32.66it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 12: Train Loss = 1.507927, Val Loss = 24.786871\n✓ Saved best model (val_loss=24.786871)\n","output_type":"stream"},{"name":"stderr","text":"Epoch 13/200: 100%|██████████| 110/110 [00:03<00:00, 32.91it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 13: Train Loss = 1.465404, Val Loss = 24.824306\n","output_type":"stream"},{"name":"stderr","text":"Epoch 14/200: 100%|██████████| 110/110 [00:03<00:00, 32.86it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 14: Train Loss = 1.424134, Val Loss = 24.343636\n✓ Saved best model (val_loss=24.343636)\n","output_type":"stream"},{"name":"stderr","text":"Epoch 15/200: 100%|██████████| 110/110 [00:03<00:00, 32.69it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 15: Train Loss = 1.384076, Val Loss = 24.204970\n✓ Saved best model (val_loss=24.204970)\n","output_type":"stream"},{"name":"stderr","text":"Epoch 16/200: 100%|██████████| 110/110 [00:03<00:00, 32.78it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 16: Train Loss = 1.341548, Val Loss = 24.077963\n✓ Saved best model (val_loss=24.077963)\n","output_type":"stream"},{"name":"stderr","text":"Epoch 17/200: 100%|██████████| 110/110 [00:03<00:00, 32.77it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 17: Train Loss = 1.304856, Val Loss = 23.733538\n✓ Saved best model (val_loss=23.733538)\n","output_type":"stream"},{"name":"stderr","text":"Epoch 18/200: 100%|██████████| 110/110 [00:03<00:00, 34.08it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 18: Train Loss = 1.270314, Val Loss = 23.857379\n","output_type":"stream"},{"name":"stderr","text":"Epoch 19/200: 100%|██████████| 110/110 [00:03<00:00, 32.37it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 19: Train Loss = 1.237943, Val Loss = 23.814359\n","output_type":"stream"},{"name":"stderr","text":"Epoch 20/200: 100%|██████████| 110/110 [00:03<00:00, 32.89it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 20: Train Loss = 1.208326, Val Loss = 23.569187\n✓ Saved best model (val_loss=23.569187)\n","output_type":"stream"},{"name":"stderr","text":"Epoch 21/200: 100%|██████████| 110/110 [00:03<00:00, 32.84it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 21: Train Loss = 1.178924, Val Loss = 23.415336\n✓ Saved best model (val_loss=23.415336)\n","output_type":"stream"},{"name":"stderr","text":"Epoch 22/200: 100%|██████████| 110/110 [00:03<00:00, 32.91it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 22: Train Loss = 1.150263, Val Loss = 23.454975\n","output_type":"stream"},{"name":"stderr","text":"Epoch 23/200: 100%|██████████| 110/110 [00:03<00:00, 32.56it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 23: Train Loss = 1.117995, Val Loss = 23.223691\n✓ Saved best model (val_loss=23.223691)\n","output_type":"stream"},{"name":"stderr","text":"Epoch 24/200: 100%|██████████| 110/110 [00:03<00:00, 32.51it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 24: Train Loss = 1.094549, Val Loss = 23.437679\n","output_type":"stream"},{"name":"stderr","text":"Epoch 25/200: 100%|██████████| 110/110 [00:03<00:00, 32.88it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 25: Train Loss = 1.074457, Val Loss = 23.325184\n","output_type":"stream"},{"name":"stderr","text":"Epoch 26/200: 100%|██████████| 110/110 [00:03<00:00, 32.44it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 26: Train Loss = 1.050563, Val Loss = 23.311684\n","output_type":"stream"},{"name":"stderr","text":"Epoch 27/200: 100%|██████████| 110/110 [00:03<00:00, 33.00it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 27: Train Loss = 1.030228, Val Loss = 23.096148\n✓ Saved best model (val_loss=23.096148)\n","output_type":"stream"},{"name":"stderr","text":"Epoch 28/200: 100%|██████████| 110/110 [00:03<00:00, 33.87it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 28: Train Loss = 1.003861, Val Loss = 23.115674\n","output_type":"stream"},{"name":"stderr","text":"Epoch 29/200: 100%|██████████| 110/110 [00:03<00:00, 32.71it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 29: Train Loss = 0.991370, Val Loss = 23.144019\n","output_type":"stream"},{"name":"stderr","text":"Epoch 30/200: 100%|██████████| 110/110 [00:03<00:00, 32.78it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 30: Train Loss = 0.965004, Val Loss = 23.351679\n","output_type":"stream"},{"name":"stderr","text":"Epoch 31/200: 100%|██████████| 110/110 [00:03<00:00, 32.77it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 31: Train Loss = 0.942836, Val Loss = 23.545061\n","output_type":"stream"},{"name":"stderr","text":"Epoch 32/200: 100%|██████████| 110/110 [00:03<00:00, 32.63it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 32: Train Loss = 0.931619, Val Loss = 23.215234\n","output_type":"stream"},{"name":"stderr","text":"Epoch 33/200: 100%|██████████| 110/110 [00:03<00:00, 32.74it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 33: Train Loss = 0.912538, Val Loss = 23.517752\nFinished training. Now testing using best model...\nTest Results: {'mrr': 0.9325880964633875, 'ndcg': 0.9491635656130114, 'recall_at_1': 0.88944, 'recall_at_3': 0.97312, 'recall_at_5': 0.98648, 'recall_at_10': 0.99496, 'recall_at_50': 0.99928, 'l2_dist': 516.6212158203125}\n","output_type":"stream"}],"execution_count":36},{"cell_type":"code","source":"generate_submission(model, Path(test_path), device=device)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-31T17:27:05.607570Z","iopub.execute_input":"2025-10-31T17:27:05.608156Z","iopub.status.idle":"2025-10-31T17:27:08.677018Z","shell.execute_reply.started":"2025-10-31T17:27:05.608129Z","shell.execute_reply":"2025-10-31T17:27:08.676193Z"}},"outputs":[{"name":"stdout","text":"Generating submission file...\n✓ Saved submission to submission.csv\n","output_type":"stream"},{"execution_count":37,"output_type":"execute_result","data":{"text/plain":"        id                                          embedding\n0        1  [14.116164207458496, 4.051480293273926, 14.437...\n1        2  [-8.252291679382324, -5.295539379119873, -5.83...\n2        3  [-6.238521099090576, 3.012822151184082, 28.372...\n3        4  [19.693193435668945, -25.15383529663086, 1.899...\n4        5  [20.222675323486328, 24.787092208862305, 0.767...\n...    ...                                                ...\n1495  1496  [8.458430290222168, -6.62744665145874, 25.4995...\n1496  1497  [8.686895370483398, 10.717864036560059, 40.116...\n1497  1498  [-1.205926775932312, -0.44514358043670654, 4.7...\n1498  1499  [-15.145681381225586, -0.44480353593826294, 9....\n1499  1500  [8.713055610656738, -19.07129669189453, -9.766...\n\n[1500 rows x 2 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>embedding</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>[14.116164207458496, 4.051480293273926, 14.437...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>[-8.252291679382324, -5.295539379119873, -5.83...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>[-6.238521099090576, 3.012822151184082, 28.372...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>[19.693193435668945, -25.15383529663086, 1.899...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5</td>\n      <td>[20.222675323486328, 24.787092208862305, 0.767...</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>1495</th>\n      <td>1496</td>\n      <td>[8.458430290222168, -6.62744665145874, 25.4995...</td>\n    </tr>\n    <tr>\n      <th>1496</th>\n      <td>1497</td>\n      <td>[8.686895370483398, 10.717864036560059, 40.116...</td>\n    </tr>\n    <tr>\n      <th>1497</th>\n      <td>1498</td>\n      <td>[-1.205926775932312, -0.44514358043670654, 4.7...</td>\n    </tr>\n    <tr>\n      <th>1498</th>\n      <td>1499</td>\n      <td>[-15.145681381225586, -0.44480353593826294, 9....</td>\n    </tr>\n    <tr>\n      <th>1499</th>\n      <td>1500</td>\n      <td>[8.713055610656738, -19.07129669189453, -9.766...</td>\n    </tr>\n  </tbody>\n</table>\n<p>1500 rows × 2 columns</p>\n</div>"},"metadata":{}}],"execution_count":37},{"cell_type":"code","source":"from torchsummary import summary\nsummary(model, input_size=(1024,))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-31T17:32:42.543813Z","iopub.execute_input":"2025-10-31T17:32:42.544387Z","iopub.status.idle":"2025-10-31T17:32:42.606568Z","shell.execute_reply.started":"2025-10-31T17:32:42.544365Z","shell.execute_reply":"2025-10-31T17:32:42.605777Z"}},"outputs":[{"name":"stdout","text":"----------------------------------------------------------------\n        Layer (type)               Output Shape         Param #\n================================================================\n            Linear-1                 [-1, 1024]       1,049,600\n              SiLU-2                 [-1, 1024]               0\n           Dropout-3                 [-1, 1024]               0\n            Linear-4                 [-1, 2048]       2,099,200\n              SiLU-5                 [-1, 2048]               0\n           Dropout-6                 [-1, 2048]               0\n            Linear-7                 [-1, 1024]       2,098,176\n              SiLU-8                 [-1, 1024]               0\n           Dropout-9                 [-1, 1024]               0\n           Linear-10                 [-1, 1536]       1,574,400\n           Linear-11                 [-1, 1024]       1,049,600\n             SiLU-12                 [-1, 1024]               0\n          Dropout-13                 [-1, 1024]               0\n           Linear-14                 [-1, 1024]       1,049,600\n             SiLU-15                 [-1, 1024]               0\n          Dropout-16                 [-1, 1024]               0\n           Linear-17                    [-1, 1]           1,025\n         Softplus-18                    [-1, 1]               0\n================================================================\nTotal params: 8,921,601\nTrainable params: 8,921,601\nNon-trainable params: 0\n----------------------------------------------------------------\nInput size (MB): 0.00\nForward/backward pass size (MB): 0.15\nParams size (MB): 34.03\nEstimated Total Size (MB): 34.19\n----------------------------------------------------------------\n","output_type":"stream"}],"execution_count":42},{"cell_type":"code","source":"all_X = torch.stack([train_dataset[i][0] for i in range(len(train_dataset))])\nall_y = torch.stack([train_dataset[i][1] for i in range(len(train_dataset))])\n\nwith torch.inference_mode():\n    translated = model(all_X.to(device)).to('cpu')\n\nprint(\"Mean squared distance before alignment:\", ((translated - all_y) ** 2).mean().item())\n\nR, s, t = procrustes_align(translated, all_y)\n\ntranslated_align = align_matrix(translated, R, s, t)\n\nprint(\"Mean squared distance after alignment:\", ((translated_align - all_y) ** 2).mean().item())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-31T18:08:06.012569Z","iopub.execute_input":"2025-10-31T18:08:06.013355Z","iopub.status.idle":"2025-10-31T18:08:18.889025Z","shell.execute_reply.started":"2025-10-31T18:08:06.013329Z","shell.execute_reply":"2025-10-31T18:08:18.888305Z"}},"outputs":[{"name":"stdout","text":"Mean squared distance before alignment: 175.68894958496094\nMean squared distance after alignment: 0.15851448476314545\n","output_type":"stream"}],"execution_count":66},{"cell_type":"code","source":"generate_submission(model, Path(test_path), output_file=\"submission-aligned.csv\", device=device, procrustes_data=(R, s, t))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-31T18:04:24.044479Z","iopub.execute_input":"2025-10-31T18:04:24.044813Z","iopub.status.idle":"2025-10-31T18:04:27.134141Z","shell.execute_reply.started":"2025-10-31T18:04:24.044778Z","shell.execute_reply":"2025-10-31T18:04:27.133388Z"}},"outputs":[{"name":"stdout","text":"Using Procrusted\nGenerating submission file...\n✓ Saved submission to submission-aligned.csv\n","output_type":"stream"},{"execution_count":64,"output_type":"execute_result","data":{"text/plain":"        id                                          embedding\n0        1  [0.6429033875465393, 0.11905805766582489, -0.0...\n1        2  [0.34022626280784607, 0.06264924257993698, -0....\n2        3  [0.38776659965515137, 0.10746285319328308, 0.2...\n3        4  [0.5170254707336426, 0.17834457755088806, -0.0...\n4        5  [0.7246093153953552, 0.2914654016494751, -0.04...\n...    ...                                                ...\n1495  1496  [0.4948069751262665, -0.05043584108352661, 0.0...\n1496  1497  [0.7435898184776306, 0.17692360281944275, 0.06...\n1497  1498  [0.8017455339431763, 0.019157446920871735, -0....\n1498  1499  [0.6866579651832581, 0.12024844437837601, -0.3...\n1499  1500  [0.5650301575660706, -0.14703373610973358, -0....\n\n[1500 rows x 2 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>embedding</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>[0.6429033875465393, 0.11905805766582489, -0.0...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>[0.34022626280784607, 0.06264924257993698, -0....</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>[0.38776659965515137, 0.10746285319328308, 0.2...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>[0.5170254707336426, 0.17834457755088806, -0.0...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5</td>\n      <td>[0.7246093153953552, 0.2914654016494751, -0.04...</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>1495</th>\n      <td>1496</td>\n      <td>[0.4948069751262665, -0.05043584108352661, 0.0...</td>\n    </tr>\n    <tr>\n      <th>1496</th>\n      <td>1497</td>\n      <td>[0.7435898184776306, 0.17692360281944275, 0.06...</td>\n    </tr>\n    <tr>\n      <th>1497</th>\n      <td>1498</td>\n      <td>[0.8017455339431763, 0.019157446920871735, -0....</td>\n    </tr>\n    <tr>\n      <th>1498</th>\n      <td>1499</td>\n      <td>[0.6866579651832581, 0.12024844437837601, -0.3...</td>\n    </tr>\n    <tr>\n      <th>1499</th>\n      <td>1500</td>\n      <td>[0.5650301575660706, -0.14703373610973358, -0....</td>\n    </tr>\n  </tbody>\n</table>\n<p>1500 rows × 2 columns</p>\n</div>"},"metadata":{}}],"execution_count":64}]}