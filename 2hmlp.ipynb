{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.13"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":117959,"databundleVersionId":14220991,"sourceType":"competition"}],"dockerImageVersionId":31154,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"### model.py","metadata":{}},{"cell_type":"code","source":"import torch\nfrom typing import Optional\nfrom torch import nn\nfrom torch.nn import functional as F\n\nclass Translator(nn.Module):\n    def __init__(\n        self,\n        input_dim: int,\n        output_dim: int,\n        dir_hidden_dims: list[int],\n        scale_hidden_dims: list[int],\n        activation=nn.ReLU,\n        dropout_rate: float=0.3\n    ):\n        super().__init__()\n\n        def build_mlp(hidden_dims, out_dim, apply_softplus=False):\n            layers = []\n            last_dim = input_dim\n            for hidden in hidden_dims:\n                layers += [\n                    nn.Linear(last_dim, hidden),\n                    activation(),\n                    nn.LayerNorm(hidden),\n                    nn.Dropout(dropout_rate)\n                ]\n                last_dim = hidden\n            layers.append(nn.Linear(last_dim, out_dim))\n            \n            if apply_softplus:\n                layers.append(nn.Softplus())\n            \n            return nn.Sequential(*layers)\n\n        self.dir_head = build_mlp(dir_hidden_dims, output_dim, apply_softplus=False)\n        self.scale_head = build_mlp(scale_hidden_dims, 1, apply_softplus=True)\n\n        # self.logit_scale = nn.Parameter(torch.ones([]) * np.log(1/0.07))\n\n        self.apply(self.init_weights)\n\n    def init_weights(self, module):\n        if isinstance(module, nn.Linear):\n            nn.init.xavier_uniform_(module.weight)\n            if module.bias is not None:\n                nn.init.constant_(module.bias, 0.0)\n        elif isinstance(module, nn.LayerNorm):\n            nn.init.ones_(module.weight)\n            nn.init.zeros_(module.bias)\n\n    def forward(self, x):\n        direction = self.dir_head(x)\n        scale = self.scale_head(x)\n        \n        return F.normalize(direction, p=2, dim=-1) * scale","metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.status.busy":"2025-11-03T08:01:51.338877Z","iopub.execute_input":"2025-11-03T08:01:51.339607Z","iopub.status.idle":"2025-11-03T08:01:51.347407Z","shell.execute_reply.started":"2025-11-03T08:01:51.339559Z","shell.execute_reply":"2025-11-03T08:01:51.346467Z"},"trusted":true},"outputs":[],"execution_count":7},{"cell_type":"markdown","source":"### eval.py","metadata":{}},{"cell_type":"code","source":"from pathlib import Path\nimport numpy as np\nimport pandas as pd\n\n'''Code from https://github.com/Mamiglia/challenge'''\n\ndef mrr(pred_indices: np.ndarray, gt_indices: np.ndarray) -> float:\n    \"\"\"\n    Compute Mean Reciprocal Rank (MRR)\n    Args:\n        pred_indices: (N, K) array of predicted indices for N queries (top-K)\n        gt_indices: (N,) array of ground truth indices\n    Returns:\n        mrr: Mean Reciprocal Rank\n    \"\"\"\n    reciprocal_ranks = []\n    for i in range(len(gt_indices)):\n        matches = np.where(pred_indices[i] == gt_indices[i])[0]\n        if matches.size > 0:\n            reciprocal_ranks.append(1.0 / (matches[0] + 1))\n        else:\n            reciprocal_ranks.append(0.0)\n    return np.mean(reciprocal_ranks)\n\n\ndef recall_at_k(pred_indices: np.ndarray, gt_indices: np.ndarray, k: int) -> float:\n    \"\"\"Compute Recall@k\n    Args:\n        pred_indices: (N, N) array of top indices for N queries\n        gt_indices: (N,) array of ground truth indices\n        k: number of top predictions to consider\n    Returns:\n        recall: Recall@k\n    \"\"\"\n    recall = 0\n    for i in range(len(gt_indices)):\n        if gt_indices[i] in pred_indices[i, :k]:\n            recall += 1\n    recall /= len(gt_indices)\n    return recall\n\nimport numpy as np\n\ndef ndcg(pred_indices: np.ndarray, gt_indices: np.ndarray, k: int = 100) -> float:\n    \"\"\"\n    Compute Normalized Discounted Cumulative Gain (NDCG@k)\n    Args:\n        pred_indices: (N, K) array of predicted indices for N queries\n        gt_indices: (N,) array of ground truth indices\n        k: number of top predictions to consider\n    Returns:\n        ndcg: NDCG@k\n    \"\"\"\n    ndcg_total = 0.0\n    for i in range(len(gt_indices)):\n        matches = np.where(pred_indices[i, :k] == gt_indices[i])[0]\n        if matches.size > 0:\n            rank = matches[0] + 1\n            ndcg_total += 1.0 / np.log2(rank + 1)  # DCG (IDCG = 1)\n    return ndcg_total / len(gt_indices)\n\n\n\n@torch.inference_mode()\ndef evaluate_retrieval(translated_embd, image_embd, gt_indices, max_indices = 99, batch_size=100):\n    \"\"\"Evaluate retrieval performance using cosine similarity\n    Args:\n        translated_embd: (N_captions, D) translated caption embeddings\n        image_embd: (N_images, D) image embeddings\n        gt_indices: (N_captions,) ground truth image indices for each caption\n        max_indices: number of top predictions to consider\n    Returns:\n        results: dict of evaluation metrics\n    \n    \"\"\"\n    # Compute similarity matrix\n    if isinstance(translated_embd, np.ndarray):\n        translated_embd = torch.from_numpy(translated_embd).float()\n    if isinstance(image_embd, np.ndarray):\n        image_embd = torch.from_numpy(image_embd).float()\n    \n    n_queries = translated_embd.shape[0]\n    device = translated_embd.device\n    \n    # Prepare containers for the fragments to be reassembled\n    all_sorted_indices = []\n    l2_distances = []\n    \n    # Process in batches - the narrow gate approach\n    for start_idx in range(0, n_queries, batch_size):\n        batch_slice = slice(start_idx, min(start_idx + batch_size, n_queries))\n        batch_translated = translated_embd[batch_slice]\n        batch_img_embd = image_embd[batch_slice]\n        \n        # Compute similarity only for this batch\n        batch_similarity = batch_translated @ batch_img_embd.T\n\n        # Get top-k predictions for this batch\n        batch_indices = batch_similarity.topk(k=max_indices, dim=1, sorted=True).indices.numpy()\n        all_sorted_indices.append(gt_indices[batch_slice][batch_indices])\n\n        # Compute L2 distance for this batch\n        batch_gt = gt_indices[batch_slice]\n        batch_gt_embeddings = image_embd[batch_gt]\n        batch_l2 = (batch_translated - batch_gt_embeddings).norm(dim=1)\n        l2_distances.append(batch_l2)\n    \n    # Reassemble the fragments\n    sorted_indices = np.concatenate(all_sorted_indices, axis=0)\n    \n    # Apply the sacred metrics to the whole\n    metrics = {\n        'mrr': mrr,\n        'ndcg': ndcg,\n        'recall_at_1': lambda preds, gt: recall_at_k(preds, gt, 1),\n        'recall_at_3': lambda preds, gt: recall_at_k(preds, gt, 3),\n        'recall_at_5': lambda preds, gt: recall_at_k(preds, gt, 5),\n        'recall_at_10': lambda preds, gt: recall_at_k(preds, gt, 10),\n        'recall_at_50': lambda preds, gt: recall_at_k(preds, gt, 50),\n    }\n    \n    results = {\n        name: func(sorted_indices, gt_indices)\n        for name, func in metrics.items()\n    }\n    \n    l2_dist = torch.cat(l2_distances, dim=0).mean().item()\n    results['l2_dist'] = l2_dist\n    \n    return results\n\ndef eval_on_val(x_val: np.ndarray, y_val: np.ndarray, model: Translator, device) -> dict:\n    gt_indices = torch.arange(len(y_val))\n    \n    model.eval()\n\n    with torch.inference_mode():\n        translated = model(x_val.to(device)).to('cpu')\n\n    results = evaluate_retrieval(translated, y_val, gt_indices)\n    \n    return results\n\ndef generate_submission(model: Translator, test_path: Path, output_file=\"submission.csv\", device=None):\n    test_data = np.load(test_path)\n    sample_ids = test_data['captions/ids']\n    test_embds = test_data['captions/embeddings']\n    test_embds = torch.from_numpy(test_embds).float()\n\n    with torch.no_grad():\n        pred_embds = model(test_embds.to(device)).cpu()\n\n    print(\"Generating submission file...\")\n\n    if isinstance(pred_embds, torch.Tensor):\n        pred_embds = pred_embds.cpu().numpy()\n\n    df_submission = pd.DataFrame({'id': sample_ids, 'embedding': pred_embds.tolist()})\n\n    df_submission.to_csv(output_file, index=False, float_format='%.17g')\n    print(f\"✓ Saved submission to {output_file}\")\n\n    return df_submission","metadata":{"execution":{"iopub.status.busy":"2025-11-03T08:01:53.746340Z","iopub.execute_input":"2025-11-03T08:01:53.747043Z","iopub.status.idle":"2025-11-03T08:01:53.761548Z","shell.execute_reply.started":"2025-11-03T08:01:53.747016Z","shell.execute_reply":"2025-11-03T08:01:53.760762Z"},"trusted":true},"outputs":[],"execution_count":8},{"cell_type":"markdown","source":"### configs","metadata":{}},{"cell_type":"markdown","source":"### main.py","metadata":{}},{"cell_type":"code","source":"from torch.utils.data import TensorDataset, DataLoader\nfrom torch.utils.data import random_split\nfrom tqdm import tqdm\n\n\ndef info_nce_loss(preds_norm, targets_norm, temp=0.07):\n    logits = (preds_norm @ targets_norm.T) / temp\n    labels = torch.arange(logits.size(0), device=logits.device)\n\n    loss_t2i = F.cross_entropy(logits, labels)          \n    loss_i2t = F.cross_entropy(logits.T, labels)        \n    \n    return 0.5 * (loss_t2i + loss_i2t)\n\n\ndef mse_loss(preds, targets):\n    pred_norms = preds.norm(dim=-1)\n    target_norms = targets.norm(dim=-1)\n    \n    return F.mse_loss(pred_norms, target_norms)\n\n\ndef combined_loss(preds: torch.Tensor, targets: torch.Tensor, temp: float, lamb: float = 1.0):\n    preds_norm = F.normalize(preds, p=2, dim=1)\n    targets_norm = F.normalize(targets, p=2, dim=1)\n\n    l1 = info_nce_loss(preds_norm, targets_norm, temp)\n    l2 = mse_loss(preds, targets)\n\n    return l1 + lamb * l2\n\n\ndef train_model(\n    model: Translator,\n    model_path: Path,\n    train_dataset: TensorDataset,\n    val_dataset: TensorDataset,\n    batch_size: int,\n    epochs: int,\n    lr: float,\n    patience: int,\n    temp: float,\n    lambda_mag: float\n) -> Translator:    \n    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\n    print(f\"Using device: {device}\")\n    \n    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n    val_loader = DataLoader(val_dataset, batch_size=batch_size)\n    \n    optimizer = torch.optim.AdamW(model.parameters(), lr=lr, weight_decay=1e-4)\n\n    best_val_loss = float('inf')\n    no_improvements = 0\n\n    for epoch in range(epochs):\n        model.train()\n\n        train_loss = 0\n        for X_batch, y_batch in tqdm(train_loader, desc=f\"Epoch {epoch+1}/{epochs}\"):\n            X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n\n            optimizer.zero_grad()\n\n            outputs = model(X_batch)\n\n            loss = combined_loss(outputs, y_batch, temp, lambda_mag)\n            \n            loss.backward()\n\n            optimizer.step()\n\n            train_loss += loss.item()\n\n        train_loss /= len(train_loader)\n\n        model.eval()\n\n        val_loss = 0\n\n        with torch.no_grad():\n            for X_batch, y_batch in val_loader:\n                X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n                outputs = model(X_batch)\n                \n                loss = combined_loss(outputs, y_batch, temp, lambda_mag)\n                \n                val_loss += loss.item()\n\n        val_loss /= len(val_loader)\n\n        print(f\"Epoch {epoch+1}: Train Loss = {train_loss:.6f}, Val Loss = {val_loss:.6f}\")\n        test(val_dataset, model, device)\n\n\n        if val_loss < best_val_loss:\n            best_val_loss = val_loss\n            no_improvements = 0\n\n            Path(model_path).parent.mkdir(parents=True, exist_ok=True)\n\n            torch.save(model.state_dict(), model_path)\n\n            print(f\"✓ Saved best model (val_loss={val_loss:.6f})\")\n        elif no_improvements >= patience:\n            return model\n        else:\n            no_improvements += 1\n\n    return model\n\n\n\ndef load_data(data_path: Path):\n    data = np.load(data_path)\n    caption_embeddings = data['captions/embeddings']\n    image_embeddings = data['images/embeddings']\n    caption_labels = data['captions/label']\n\n    X_abs, y_abs = torch.tensor(caption_embeddings), torch.tensor(image_embeddings[np.argmax(caption_labels, axis=1)])\n    \n    print('Texts shape', X_abs.shape)\n    print('Images shape', X_abs.shape)\n\n    def print_stats():\n        mean_X = X_abs.mean(dim=0)\n        std_X = X_abs.std(dim=0)\n        \n        mean_Y = y_abs.mean(dim=0)\n        std_Y = y_abs.std(dim=0)\n\n        print(\"X: mean of stds per dim =\", std_X.mean().item(), \", max =\", std_X.max().item(), \", min =\", std_X.min().item())\n        print(\"Y: mean of stds per dim =\", std_Y.mean().item(), \", max =\", std_Y.max().item(), \", min =\", std_Y.min().item())\n\n    print_stats()\n    \n    dataset = TensorDataset(X_abs, y_abs)\n    train_dataset, val_dataset = random_split(dataset, [0.9, 0.1], generator=torch.Generator().manual_seed(42))\n    \n    return train_dataset, val_dataset\n\n\ndef test(val_dataset: TensorDataset, model: Translator, device):\n    val_loader = DataLoader(val_dataset, batch_size=len(val_dataset))\n    for x_val, y_val in val_loader:\n        results = eval_on_val(x_val, y_val, model=model, device=device)\n    return results","metadata":{"execution":{"iopub.status.busy":"2025-11-03T08:08:50.922807Z","iopub.execute_input":"2025-11-03T08:08:50.923530Z","iopub.status.idle":"2025-11-03T08:08:50.937750Z","shell.execute_reply.started":"2025-11-03T08:08:50.923503Z","shell.execute_reply":"2025-11-03T08:08:50.937014Z"},"trusted":true},"outputs":[],"execution_count":11},{"cell_type":"code","source":"device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\nbatch_size= 2048\nlr= 0.0005\nepochs= 200\npatience = 10\ntemp = 0.011284474643610163\nlambda_mag = 0.7763296874424117\ndropout_rate = 0.25\n\ndata_path= '/kaggle/input/aml-competition/train/train/train.npz'\ntest_path= '/kaggle/input/aml-competition/test/test/test.clean.npz'\n\nmodel_save_path= './models/exp1.pth'\n\ntrain_dataset, val_dataset = load_data(data_path)","metadata":{"execution":{"iopub.status.busy":"2025-11-03T07:50:03.938261Z","iopub.execute_input":"2025-11-03T07:50:03.938524Z","iopub.status.idle":"2025-11-03T07:50:25.712078Z","shell.execute_reply.started":"2025-11-03T07:50:03.938505Z","shell.execute_reply":"2025-11-03T07:50:25.711272Z"},"trusted":true},"outputs":[{"name":"stdout","text":"Texts shape torch.Size([125000, 1024])\nImages shape torch.Size([125000, 1024])\nX: mean of stds per dim = 0.788078248500824 , max = 3.573546886444092 , min = 0.3716050386428833\nY: mean of stds per dim = 0.4244377911090851 , max = 1.8597956895828247 , min = 0.08161858469247818\n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"model_args = {\n    'input_dim': 1024,\n    'output_dim': 1536,\n    'dir_hidden_dims': [2048, 4096],\n    'scale_hidden_dims': [1024, 512, 256],\n    'activation': nn.GELU,\n    'dropout_rate': dropout_rate\n}\nmodel = Translator(**model_args).to(device)\n\ntrain_model(model, model_save_path, train_dataset, val_dataset, batch_size, epochs, lr, patience, temp, lambda_mag)\n\nprint('Finished training. Now testing using best model...')\n\nstate = torch.load(model_save_path)\nmodel.load_state_dict(state)\nresults = test(val_dataset, model, device)\n\nprint(\"Test Results:\", results)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-03T08:27:10.881033Z","iopub.execute_input":"2025-11-03T08:27:10.881578Z","iopub.status.idle":"2025-11-03T08:34:34.101978Z","shell.execute_reply.started":"2025-11-03T08:27:10.881543Z","shell.execute_reply":"2025-11-03T08:34:34.101321Z"}},"outputs":[{"name":"stdout","text":"Using device: cuda\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1/200: 100%|██████████| 55/55 [00:05<00:00, 10.75it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 1: Train Loss = 63.403510, Val Loss = 4.756323\n✓ Saved best model (val_loss=4.756323)\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2/200: 100%|██████████| 55/55 [00:05<00:00, 10.76it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 2: Train Loss = 6.506368, Val Loss = 4.519658\n✓ Saved best model (val_loss=4.519658)\n","output_type":"stream"},{"name":"stderr","text":"Epoch 3/200: 100%|██████████| 55/55 [00:05<00:00, 10.90it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 3: Train Loss = 6.042053, Val Loss = 4.303803\n✓ Saved best model (val_loss=4.303803)\n","output_type":"stream"},{"name":"stderr","text":"Epoch 4/200: 100%|██████████| 55/55 [00:05<00:00, 10.90it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 4: Train Loss = 5.694650, Val Loss = 4.141370\n✓ Saved best model (val_loss=4.141370)\n","output_type":"stream"},{"name":"stderr","text":"Epoch 5/200: 100%|██████████| 55/55 [00:05<00:00, 10.83it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 5: Train Loss = 5.365307, Val Loss = 3.938814\n✓ Saved best model (val_loss=3.938814)\n","output_type":"stream"},{"name":"stderr","text":"Epoch 6/200: 100%|██████████| 55/55 [00:05<00:00, 10.77it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 6: Train Loss = 5.052535, Val Loss = 3.782082\n✓ Saved best model (val_loss=3.782082)\n","output_type":"stream"},{"name":"stderr","text":"Epoch 7/200: 100%|██████████| 55/55 [00:05<00:00, 10.74it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 7: Train Loss = 4.808344, Val Loss = 3.658976\n✓ Saved best model (val_loss=3.658976)\n","output_type":"stream"},{"name":"stderr","text":"Epoch 8/200: 100%|██████████| 55/55 [00:05<00:00, 10.84it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 8: Train Loss = 4.574966, Val Loss = 3.574367\n✓ Saved best model (val_loss=3.574367)\n","output_type":"stream"},{"name":"stderr","text":"Epoch 9/200: 100%|██████████| 55/55 [00:05<00:00, 10.78it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 9: Train Loss = 4.367667, Val Loss = 3.506182\n✓ Saved best model (val_loss=3.506182)\n","output_type":"stream"},{"name":"stderr","text":"Epoch 10/200: 100%|██████████| 55/55 [00:05<00:00, 10.71it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 10: Train Loss = 4.224765, Val Loss = 3.456625\n✓ Saved best model (val_loss=3.456625)\n","output_type":"stream"},{"name":"stderr","text":"Epoch 11/200: 100%|██████████| 55/55 [00:05<00:00, 10.83it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 11: Train Loss = 4.062249, Val Loss = 3.424075\n✓ Saved best model (val_loss=3.424075)\n","output_type":"stream"},{"name":"stderr","text":"Epoch 12/200: 100%|██████████| 55/55 [00:05<00:00, 10.71it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 12: Train Loss = 3.934872, Val Loss = 3.410171\n✓ Saved best model (val_loss=3.410171)\n","output_type":"stream"},{"name":"stderr","text":"Epoch 13/200: 100%|██████████| 55/55 [00:05<00:00, 10.37it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 13: Train Loss = 3.832203, Val Loss = 3.400214\n✓ Saved best model (val_loss=3.400214)\n","output_type":"stream"},{"name":"stderr","text":"Epoch 14/200: 100%|██████████| 55/55 [00:05<00:00, 10.65it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 14: Train Loss = 3.740494, Val Loss = 3.397689\n✓ Saved best model (val_loss=3.397689)\n","output_type":"stream"},{"name":"stderr","text":"Epoch 15/200: 100%|██████████| 55/55 [00:05<00:00, 10.41it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 15: Train Loss = 3.633952, Val Loss = 3.399666\n","output_type":"stream"},{"name":"stderr","text":"Epoch 16/200: 100%|██████████| 55/55 [00:05<00:00, 10.52it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 16: Train Loss = 3.561708, Val Loss = 3.343435\n✓ Saved best model (val_loss=3.343435)\n","output_type":"stream"},{"name":"stderr","text":"Epoch 17/200: 100%|██████████| 55/55 [00:05<00:00, 10.51it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 17: Train Loss = 3.504278, Val Loss = 3.348626\n","output_type":"stream"},{"name":"stderr","text":"Epoch 18/200: 100%|██████████| 55/55 [00:05<00:00, 10.50it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 18: Train Loss = 3.429238, Val Loss = 3.320605\n✓ Saved best model (val_loss=3.320605)\n","output_type":"stream"},{"name":"stderr","text":"Epoch 19/200: 100%|██████████| 55/55 [00:05<00:00, 10.51it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 19: Train Loss = 3.399527, Val Loss = 3.335627\n","output_type":"stream"},{"name":"stderr","text":"Epoch 20/200: 100%|██████████| 55/55 [00:05<00:00, 10.38it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 20: Train Loss = 3.332678, Val Loss = 3.318508\n✓ Saved best model (val_loss=3.318508)\n","output_type":"stream"},{"name":"stderr","text":"Epoch 21/200: 100%|██████████| 55/55 [00:05<00:00, 10.78it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 21: Train Loss = 3.308346, Val Loss = 3.321895\n","output_type":"stream"},{"name":"stderr","text":"Epoch 22/200: 100%|██████████| 55/55 [00:05<00:00, 10.44it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 22: Train Loss = 3.267964, Val Loss = 3.318960\n","output_type":"stream"},{"name":"stderr","text":"Epoch 23/200: 100%|██████████| 55/55 [00:05<00:00, 10.45it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 23: Train Loss = 3.220179, Val Loss = 3.337986\n","output_type":"stream"},{"name":"stderr","text":"Epoch 24/200: 100%|██████████| 55/55 [00:05<00:00, 10.34it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 24: Train Loss = 3.212539, Val Loss = 3.301433\n✓ Saved best model (val_loss=3.301433)\n","output_type":"stream"},{"name":"stderr","text":"Epoch 25/200: 100%|██████████| 55/55 [00:05<00:00, 10.30it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 25: Train Loss = 3.158418, Val Loss = 3.290306\n✓ Saved best model (val_loss=3.290306)\n","output_type":"stream"},{"name":"stderr","text":"Epoch 26/200: 100%|██████████| 55/55 [00:05<00:00, 10.77it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 26: Train Loss = 3.138638, Val Loss = 3.332640\n","output_type":"stream"},{"name":"stderr","text":"Epoch 27/200: 100%|██████████| 55/55 [00:05<00:00, 10.33it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 27: Train Loss = 3.116332, Val Loss = 3.311292\n","output_type":"stream"},{"name":"stderr","text":"Epoch 28/200: 100%|██████████| 55/55 [00:05<00:00, 10.43it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 28: Train Loss = 3.089696, Val Loss = 3.294357\n","output_type":"stream"},{"name":"stderr","text":"Epoch 29/200: 100%|██████████| 55/55 [00:05<00:00, 10.46it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 29: Train Loss = 3.081923, Val Loss = 3.299584\n","output_type":"stream"},{"name":"stderr","text":"Epoch 30/200: 100%|██████████| 55/55 [00:05<00:00, 10.44it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 30: Train Loss = 3.043829, Val Loss = 3.294397\n","output_type":"stream"},{"name":"stderr","text":"Epoch 31/200: 100%|██████████| 55/55 [00:05<00:00, 10.47it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 31: Train Loss = 3.010462, Val Loss = 3.300718\n","output_type":"stream"},{"name":"stderr","text":"Epoch 32/200: 100%|██████████| 55/55 [00:05<00:00, 10.46it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 32: Train Loss = 2.981384, Val Loss = 3.292304\n","output_type":"stream"},{"name":"stderr","text":"Epoch 33/200: 100%|██████████| 55/55 [00:05<00:00, 10.77it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 33: Train Loss = 3.009797, Val Loss = 3.285048\n✓ Saved best model (val_loss=3.285048)\n","output_type":"stream"},{"name":"stderr","text":"Epoch 34/200: 100%|██████████| 55/55 [00:05<00:00, 10.46it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 34: Train Loss = 2.971409, Val Loss = 3.318648\n","output_type":"stream"},{"name":"stderr","text":"Epoch 35/200: 100%|██████████| 55/55 [00:05<00:00, 10.44it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 35: Train Loss = 2.959987, Val Loss = 3.296684\n","output_type":"stream"},{"name":"stderr","text":"Epoch 36/200: 100%|██████████| 55/55 [00:05<00:00, 10.51it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 36: Train Loss = 2.937953, Val Loss = 3.294926\n","output_type":"stream"},{"name":"stderr","text":"Epoch 37/200: 100%|██████████| 55/55 [00:05<00:00, 10.45it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 37: Train Loss = 2.913658, Val Loss = 3.288248\n","output_type":"stream"},{"name":"stderr","text":"Epoch 38/200: 100%|██████████| 55/55 [00:05<00:00, 10.59it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 38: Train Loss = 2.909888, Val Loss = 3.288682\n","output_type":"stream"},{"name":"stderr","text":"Epoch 39/200: 100%|██████████| 55/55 [00:05<00:00, 10.34it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 39: Train Loss = 2.895155, Val Loss = 3.307273\n","output_type":"stream"},{"name":"stderr","text":"Epoch 40/200: 100%|██████████| 55/55 [00:05<00:00, 10.48it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 40: Train Loss = 2.877329, Val Loss = 3.287952\n","output_type":"stream"},{"name":"stderr","text":"Epoch 41/200: 100%|██████████| 55/55 [00:05<00:00, 10.47it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 41: Train Loss = 2.858980, Val Loss = 3.281878\n✓ Saved best model (val_loss=3.281878)\n","output_type":"stream"},{"name":"stderr","text":"Epoch 42/200: 100%|██████████| 55/55 [00:05<00:00, 10.44it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 42: Train Loss = 2.844573, Val Loss = 3.267917\n✓ Saved best model (val_loss=3.267917)\n","output_type":"stream"},{"name":"stderr","text":"Epoch 43/200: 100%|██████████| 55/55 [00:05<00:00, 10.29it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 43: Train Loss = 2.843100, Val Loss = 3.256049\n✓ Saved best model (val_loss=3.256049)\n","output_type":"stream"},{"name":"stderr","text":"Epoch 44/200: 100%|██████████| 55/55 [00:05<00:00, 10.30it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 44: Train Loss = 2.805466, Val Loss = 3.260415\n","output_type":"stream"},{"name":"stderr","text":"Epoch 45/200: 100%|██████████| 55/55 [00:05<00:00, 10.75it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 45: Train Loss = 2.813081, Val Loss = 3.269445\n","output_type":"stream"},{"name":"stderr","text":"Epoch 46/200: 100%|██████████| 55/55 [00:05<00:00, 10.42it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 46: Train Loss = 2.765885, Val Loss = 3.286369\n","output_type":"stream"},{"name":"stderr","text":"Epoch 47/200: 100%|██████████| 55/55 [00:05<00:00, 10.32it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 47: Train Loss = 2.761727, Val Loss = 3.257748\n","output_type":"stream"},{"name":"stderr","text":"Epoch 48/200: 100%|██████████| 55/55 [00:05<00:00, 10.31it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 48: Train Loss = 2.739805, Val Loss = 3.250500\n✓ Saved best model (val_loss=3.250500)\n","output_type":"stream"},{"name":"stderr","text":"Epoch 49/200: 100%|██████████| 55/55 [00:05<00:00, 10.26it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 49: Train Loss = 2.742031, Val Loss = 3.294099\n","output_type":"stream"},{"name":"stderr","text":"Epoch 50/200: 100%|██████████| 55/55 [00:05<00:00, 10.76it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 50: Train Loss = 2.724362, Val Loss = 3.265693\n","output_type":"stream"},{"name":"stderr","text":"Epoch 51/200: 100%|██████████| 55/55 [00:05<00:00, 10.42it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 51: Train Loss = 2.717613, Val Loss = 3.277410\n","output_type":"stream"},{"name":"stderr","text":"Epoch 52/200: 100%|██████████| 55/55 [00:05<00:00, 10.30it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 52: Train Loss = 2.686120, Val Loss = 3.270539\n","output_type":"stream"},{"name":"stderr","text":"Epoch 53/200: 100%|██████████| 55/55 [00:05<00:00, 10.27it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 53: Train Loss = 2.673258, Val Loss = 3.285613\n","output_type":"stream"},{"name":"stderr","text":"Epoch 54/200: 100%|██████████| 55/55 [00:05<00:00, 10.39it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 54: Train Loss = 2.641142, Val Loss = 3.284139\n","output_type":"stream"},{"name":"stderr","text":"Epoch 55/200: 100%|██████████| 55/55 [00:05<00:00, 10.30it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 55: Train Loss = 2.644398, Val Loss = 3.263867\n","output_type":"stream"},{"name":"stderr","text":"Epoch 56/200: 100%|██████████| 55/55 [00:05<00:00, 10.28it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 56: Train Loss = 2.637483, Val Loss = 3.273742\n","output_type":"stream"},{"name":"stderr","text":"Epoch 57/200: 100%|██████████| 55/55 [00:05<00:00, 10.64it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 57: Train Loss = 2.597506, Val Loss = 3.273258\n","output_type":"stream"},{"name":"stderr","text":"Epoch 58/200: 100%|██████████| 55/55 [00:05<00:00, 10.29it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 58: Train Loss = 2.603845, Val Loss = 3.272361\n","output_type":"stream"},{"name":"stderr","text":"Epoch 59/200: 100%|██████████| 55/55 [00:05<00:00, 10.32it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 59: Train Loss = 2.589099, Val Loss = 3.255983\nFinished training. Now testing using best model...\nTest Results: {'mrr': 0.8955046637625308, 'ndcg': 0.9201528960664349, 'recall_at_1': 0.84144, 'recall_at_3': 0.94104, 'recall_at_5': 0.962, 'recall_at_10': 0.97936, 'recall_at_50': 0.99808, 'l2_dist': 30.50058937072754}\n","output_type":"stream"}],"execution_count":16},{"cell_type":"code","source":"generate_submission(model, Path(test_path), device=device)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-03T07:57:30.336752Z","iopub.execute_input":"2025-11-03T07:57:30.337364Z","iopub.status.idle":"2025-11-03T07:57:33.328460Z","shell.execute_reply.started":"2025-11-03T07:57:30.337338Z","shell.execute_reply":"2025-11-03T07:57:33.327620Z"}},"outputs":[{"name":"stdout","text":"Generating submission file...\n✓ Saved submission to submission.csv\n","output_type":"stream"},{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"        id                                          embedding\n0        1  [-0.13813145458698273, -0.5371889472007751, 0....\n1        2  [-0.6189366579055786, -0.3590053915977478, 0.2...\n2        3  [-0.7931116819381714, -0.1779468059539795, 0.4...\n3        4  [0.45219361782073975, -1.561142086982727, -0.6...\n4        5  [1.2697274684906006, 1.481618046760559, -0.018...\n...    ...                                                ...\n1495  1496  [0.2991337180137634, -0.4530474543571472, 0.47...\n1496  1497  [-0.0717444121837616, 0.21529829502105713, -0....\n1497  1498  [0.2169097661972046, -1.007057547569275, -0.54...\n1498  1499  [0.27533355355262756, -0.3522982895374298, 0.1...\n1499  1500  [0.42060595750808716, -1.0974042415618896, -0....\n\n[1500 rows x 2 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>embedding</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>[-0.13813145458698273, -0.5371889472007751, 0....</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>[-0.6189366579055786, -0.3590053915977478, 0.2...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>[-0.7931116819381714, -0.1779468059539795, 0.4...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>[0.45219361782073975, -1.561142086982727, -0.6...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5</td>\n      <td>[1.2697274684906006, 1.481618046760559, -0.018...</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>1495</th>\n      <td>1496</td>\n      <td>[0.2991337180137634, -0.4530474543571472, 0.47...</td>\n    </tr>\n    <tr>\n      <th>1496</th>\n      <td>1497</td>\n      <td>[-0.0717444121837616, 0.21529829502105713, -0....</td>\n    </tr>\n    <tr>\n      <th>1497</th>\n      <td>1498</td>\n      <td>[0.2169097661972046, -1.007057547569275, -0.54...</td>\n    </tr>\n    <tr>\n      <th>1498</th>\n      <td>1499</td>\n      <td>[0.27533355355262756, -0.3522982895374298, 0.1...</td>\n    </tr>\n    <tr>\n      <th>1499</th>\n      <td>1500</td>\n      <td>[0.42060595750808716, -1.0974042415618896, -0....</td>\n    </tr>\n  </tbody>\n</table>\n<p>1500 rows × 2 columns</p>\n</div>"},"metadata":{}}],"execution_count":6},{"cell_type":"code","source":"from torchsummary import summary\nsummary(model, input_size=(1024,))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-02T21:32:03.639415Z","iopub.execute_input":"2025-11-02T21:32:03.640170Z","iopub.status.idle":"2025-11-02T21:32:03.648865Z","shell.execute_reply.started":"2025-11-02T21:32:03.640136Z","shell.execute_reply":"2025-11-02T21:32:03.648189Z"}},"outputs":[{"name":"stdout","text":"----------------------------------------------------------------\n        Layer (type)               Output Shape         Param #\n================================================================\n            Linear-1                 [-1, 2048]       2,099,200\n              SiLU-2                 [-1, 2048]               0\n         LayerNorm-3                 [-1, 2048]           4,096\n           Dropout-4                 [-1, 2048]               0\n            Linear-5                 [-1, 4096]       8,392,704\n              SiLU-6                 [-1, 4096]               0\n         LayerNorm-7                 [-1, 4096]           8,192\n           Dropout-8                 [-1, 4096]               0\n            Linear-9                 [-1, 1536]       6,292,992\n           Linear-10                  [-1, 512]         524,800\n             SiLU-11                  [-1, 512]               0\n        LayerNorm-12                  [-1, 512]           1,024\n          Dropout-13                  [-1, 512]               0\n           Linear-14                  [-1, 256]         131,328\n             SiLU-15                  [-1, 256]               0\n        LayerNorm-16                  [-1, 256]             512\n          Dropout-17                  [-1, 256]               0\n           Linear-18                    [-1, 1]             257\n         Softplus-19                    [-1, 1]               0\n================================================================\nTotal params: 17,455,105\nTrainable params: 17,455,105\nNon-trainable params: 0\n----------------------------------------------------------------\nInput size (MB): 0.00\nForward/backward pass size (MB): 0.22\nParams size (MB): 66.59\nEstimated Total Size (MB): 66.81\n----------------------------------------------------------------\n","output_type":"stream"}],"execution_count":28},{"cell_type":"code","source":"import optuna\nfrom optuna.pruners import MedianPruner\nfrom pathlib import Path\n\nACTIVATIONS = {\n    #\"relu\": nn.ReLU,\n    \"gelu\": nn.GELU,\n    \"silu\": nn.SiLU,\n    'selu': nn.SELU,\n    'celu': nn.CELU\n    #\"leakyrelu\": nn.LeakyReLU\n}\n\ndef objective(trial, train_dataset, val_dataset, input_dim, output_dim, epochs: int = 10, device=None):\n    if device is None:\n        device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\n    # --- Hyperparametri ---\n    dir_n_layers = trial.suggest_int(\"dir_n_layers\", 1, 4)\n    dir_hidden_dims_choices = [1024, 1536, 2048, 4096]\n    dir_hidden_dims = [trial.suggest_categorical(f\"dir_l{i}_units\", dir_hidden_dims_choices) for i in range(dir_n_layers)]\n\n    scale_n_layers = trial.suggest_int(\"scale_n_layers\", 1, 4)\n    scale_hidden_dims_choices = [128, 256, 512, 1024, 1536]\n    scale_hidden_dims = [trial.suggest_categorical(f\"scale_l{i}_units\", scale_hidden_dims_choices) for i in range(scale_n_layers)]\n\n    activation_name = trial.suggest_categorical(\"activation\", list(ACTIVATIONS.keys()))\n    activation_fn = ACTIVATIONS[activation_name]\n\n    batch_size = trial.suggest_categorical(\"batch_size\", [2048, 4096])\n    lr = trial.suggest_float(\"lr\", 1e-6, 1e-3, log=True)\n    dropout_rate = trial.suggest_categorical('dropout_rate', [0.2, 0.25, 0.3])\n\n    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n\n    temp = trial.suggest_float(\"temp\", 0.01, 0.2, log=True)\n    \n    lambda_mag = trial.suggest_float(\"lambda_mag\", 0.2, 1.3)\n\n    # --- Modello ---\n    model_args = {\n        'input_dim': input_dim,\n        'output_dim': output_dim,\n        'dir_hidden_dims': dir_hidden_dims,\n        'scale_hidden_dims': scale_hidden_dims,\n        'activation': activation_fn,\n        'dropout_rate': dropout_rate\n    }\n    model = Translator(**model_args).to(device)\n\n    optimizer = torch.optim.AdamW(model.parameters(), lr=lr, weight_decay=1e-4)\n\n    for epoch in range(epochs):\n        model.train()\n        train_loss = 0.0\n        \n        for X_batch, y_batch in train_loader:\n            X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n            optimizer.zero_grad()\n            \n            outputs = model(X_batch)\n            \n            loss = combined_loss(outputs, y_batch, temp, lambda_mag)\n            loss.backward()\n            \n            optimizer.step()\n            train_loss += loss.item()\n        \n        train_loss /= len(train_loader)\n\n        # --- Validation ---\n        model.eval()\n        \n        val_loss = 0.0\n        \n        with torch.no_grad():\n            for X_batch, y_batch in val_loader:\n                X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n        \n                outputs = model(X_batch)\n                val_loss += combined_loss(outputs, y_batch, temp, lambda_mag).item()\n        \n        val_loss /= len(val_loader)\n\n        results = test(val_dataset, model, device)\n        trial.report(results['recall_at_1'], epoch)\n\n        if trial.should_prune():\n            raise optuna.exceptions.TrialPruned()\n\n    return results['recall_at_1']\n\n\ndef run_optuna_search(data_path: Path, n_trials: int = 30, epochs: int = 30, n_jobs: int = 1, sampler=None, pruner=None):\n    if pruner is None:\n        pruner = MedianPruner(n_startup_trials=5, n_warmup_steps=1)\n\n    train_dataset, val_dataset = load_data(data_path)\n    input_dim = train_dataset[0][0].shape[0]\n    output_dim = train_dataset[0][1].shape[0]\n\n    study = optuna.create_study(direction=\"maximize\", pruner=pruner)\n    func = lambda trial: objective(trial, train_dataset=train_dataset, val_dataset=val_dataset,\n                                   input_dim=input_dim, output_dim=output_dim,\n                                   epochs=epochs)\n    study.optimize(func, n_trials=n_trials, n_jobs=n_jobs)\n\n    print(\"Study statistics:\")\n    print(\"  Number of finished trials: \", len(study.trials))\n    print(\"  Best trial:\")\n    trial = study.best_trial\n    print(\"    Value: \", trial.value)\n    print(\"    Params: \")\n    for k, v in trial.params.items():\n        print(f\"      {k}: {v}\")\n\n    return study\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-02T21:32:26.973490Z","iopub.execute_input":"2025-11-02T21:32:26.974359Z","iopub.status.idle":"2025-11-02T21:32:26.986929Z","shell.execute_reply.started":"2025-11-02T21:32:26.974331Z","shell.execute_reply":"2025-11-02T21:32:26.986212Z"}},"outputs":[],"execution_count":30},{"cell_type":"code","source":"study = run_optuna_search(data_path=data_path, n_trials=100, epochs=10, n_jobs=1)\nstudy.trials_dataframe().to_csv(\"optuna_trials.csv\", index=False)\n\nbest_trial_number = study.best_trial.number\nprint(\"Best params:\", study.best_params)\nprint(\"Best trial number:\", study.best_trial.number)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-02T21:32:29.944820Z","iopub.execute_input":"2025-11-02T21:32:29.945299Z","iopub.status.idle":"2025-11-02T23:05:08.836839Z","shell.execute_reply.started":"2025-11-02T21:32:29.945275Z","shell.execute_reply":"2025-11-02T23:05:08.835843Z"}},"outputs":[{"name":"stdout","text":"Texts shape torch.Size([125000, 1024])\nImages shape torch.Size([125000, 1024])\n","output_type":"stream"},{"name":"stderr","text":"[I 2025-11-02 21:32:45,301] A new study created in memory with name: no-name-dc48b929-0cc8-4de7-a056-aa3a39b6e3dd\n","output_type":"stream"},{"name":"stdout","text":"X: mean of stds per dim = 0.788078248500824 , max = 3.573546886444092 , min = 0.3716050386428833\nY: mean of stds per dim = 0.4244377911090851 , max = 1.8597956895828247 , min = 0.08161858469247818\n","output_type":"stream"},{"name":"stderr","text":"[I 2025-11-02 21:34:29,714] Trial 0 finished with value: 0.86928 and parameters: {'dir_n_layers': 4, 'dir_l0_units': 1024, 'dir_l1_units': 2048, 'dir_l2_units': 4096, 'dir_l3_units': 2048, 'scale_n_layers': 3, 'scale_l0_units': 256, 'scale_l1_units': 1024, 'scale_l2_units': 1024, 'activation': 'gelu', 'batch_size': 4096, 'lr': 0.0006374960046354015, 'dropout_rate': 0.3, 'temp': 0.010505979831525658, 'lambda_mag': 0.8413356793088904}. Best is trial 0 with value: 0.86928.\n[I 2025-11-02 21:35:32,120] Trial 1 finished with value: 0.188 and parameters: {'dir_n_layers': 2, 'dir_l0_units': 1024, 'dir_l1_units': 2048, 'scale_n_layers': 3, 'scale_l0_units': 128, 'scale_l1_units': 512, 'scale_l2_units': 512, 'activation': 'silu', 'batch_size': 4096, 'lr': 2.030535103415105e-06, 'dropout_rate': 0.3, 'temp': 0.07212758127415753, 'lambda_mag': 1.2920576865786182}. Best is trial 0 with value: 0.86928.\n[I 2025-11-02 21:37:23,009] Trial 2 finished with value: 0.3492 and parameters: {'dir_n_layers': 3, 'dir_l0_units': 4096, 'dir_l1_units': 4096, 'dir_l2_units': 1024, 'scale_n_layers': 3, 'scale_l0_units': 512, 'scale_l1_units': 512, 'scale_l2_units': 1536, 'activation': 'selu', 'batch_size': 4096, 'lr': 7.5148254544520435e-06, 'dropout_rate': 0.2, 'temp': 0.18243409791385334, 'lambda_mag': 0.28921363136463346}. Best is trial 0 with value: 0.86928.\n[I 2025-11-02 21:38:17,040] Trial 3 finished with value: 0.72048 and parameters: {'dir_n_layers': 1, 'dir_l0_units': 1024, 'scale_n_layers': 1, 'scale_l0_units': 256, 'activation': 'gelu', 'batch_size': 4096, 'lr': 0.00015350957122699693, 'dropout_rate': 0.2, 'temp': 0.03467939988820655, 'lambda_mag': 0.8490125244365294}. Best is trial 0 with value: 0.86928.\n[I 2025-11-02 21:39:36,603] Trial 4 finished with value: 0.43072 and parameters: {'dir_n_layers': 2, 'dir_l0_units': 1024, 'dir_l1_units': 4096, 'scale_n_layers': 3, 'scale_l0_units': 128, 'scale_l1_units': 1024, 'scale_l2_units': 1536, 'activation': 'selu', 'batch_size': 4096, 'lr': 1.763005256038937e-05, 'dropout_rate': 0.25, 'temp': 0.12530057816639645, 'lambda_mag': 0.23886231372378822}. Best is trial 0 with value: 0.86928.\n[I 2025-11-02 21:40:39,765] Trial 5 finished with value: 0.80088 and parameters: {'dir_n_layers': 3, 'dir_l0_units': 2048, 'dir_l1_units': 2048, 'dir_l2_units': 1024, 'scale_n_layers': 3, 'scale_l0_units': 256, 'scale_l1_units': 512, 'scale_l2_units': 256, 'activation': 'silu', 'batch_size': 2048, 'lr': 0.00012395391548028522, 'dropout_rate': 0.3, 'temp': 0.01989033961131795, 'lambda_mag': 0.8676035087651699}. Best is trial 0 with value: 0.86928.\n[I 2025-11-02 21:41:49,113] Trial 6 finished with value: 0.58904 and parameters: {'dir_n_layers': 1, 'dir_l0_units': 4096, 'scale_n_layers': 2, 'scale_l0_units': 256, 'scale_l1_units': 128, 'activation': 'celu', 'batch_size': 4096, 'lr': 9.347114995592863e-05, 'dropout_rate': 0.25, 'temp': 0.11225547862227028, 'lambda_mag': 1.2840942845291756}. Best is trial 0 with value: 0.86928.\n[I 2025-11-02 21:43:27,838] Trial 7 finished with value: 0.7092 and parameters: {'dir_n_layers': 4, 'dir_l0_units': 4096, 'dir_l1_units': 1536, 'dir_l2_units': 2048, 'dir_l3_units': 2048, 'scale_n_layers': 4, 'scale_l0_units': 512, 'scale_l1_units': 1536, 'scale_l2_units': 128, 'scale_l3_units': 128, 'activation': 'selu', 'batch_size': 4096, 'lr': 0.0006278246552721005, 'dropout_rate': 0.2, 'temp': 0.06904409237074786, 'lambda_mag': 1.1809715985023383}. Best is trial 0 with value: 0.86928.\n[I 2025-11-02 21:43:39,846] Trial 8 pruned. \n[I 2025-11-02 21:44:02,344] Trial 9 pruned. \n[I 2025-11-02 21:45:31,055] Trial 10 finished with value: 0.86936 and parameters: {'dir_n_layers': 4, 'dir_l0_units': 1536, 'dir_l1_units': 1024, 'dir_l2_units': 4096, 'dir_l3_units': 1536, 'scale_n_layers': 4, 'scale_l0_units': 1536, 'scale_l1_units': 1024, 'scale_l2_units': 1024, 'scale_l3_units': 1024, 'activation': 'gelu', 'batch_size': 2048, 'lr': 0.0006094728880732997, 'dropout_rate': 0.3, 'temp': 0.010477719239320624, 'lambda_mag': 0.63883449026425}. Best is trial 10 with value: 0.86936.\n[I 2025-11-02 21:46:59,751] Trial 11 finished with value: 0.86896 and parameters: {'dir_n_layers': 4, 'dir_l0_units': 1536, 'dir_l1_units': 1024, 'dir_l2_units': 4096, 'dir_l3_units': 1536, 'scale_n_layers': 4, 'scale_l0_units': 1536, 'scale_l1_units': 1024, 'scale_l2_units': 1024, 'scale_l3_units': 1024, 'activation': 'gelu', 'batch_size': 2048, 'lr': 0.0007701845244165387, 'dropout_rate': 0.3, 'temp': 0.010310003413849888, 'lambda_mag': 0.5665557134238282}. Best is trial 10 with value: 0.86936.\n[I 2025-11-02 21:48:17,308] Trial 12 finished with value: 0.87776 and parameters: {'dir_n_layers': 3, 'dir_l0_units': 1536, 'dir_l1_units': 1024, 'dir_l2_units': 4096, 'scale_n_layers': 4, 'scale_l0_units': 1536, 'scale_l1_units': 256, 'scale_l2_units': 1024, 'scale_l3_units': 1024, 'activation': 'gelu', 'batch_size': 2048, 'lr': 0.00036532889983492467, 'dropout_rate': 0.3, 'temp': 0.010137285806856211, 'lambda_mag': 0.6704783652082302}. Best is trial 12 with value: 0.87776.\n[I 2025-11-02 21:49:20,347] Trial 13 finished with value: 0.8356 and parameters: {'dir_n_layers': 3, 'dir_l0_units': 1536, 'dir_l1_units': 1024, 'dir_l2_units': 1536, 'scale_n_layers': 4, 'scale_l0_units': 1536, 'scale_l1_units': 256, 'scale_l2_units': 1024, 'scale_l3_units': 1024, 'activation': 'gelu', 'batch_size': 2048, 'lr': 0.00029228585966516564, 'dropout_rate': 0.3, 'temp': 0.01735846806579992, 'lambda_mag': 0.612754984426433}. Best is trial 12 with value: 0.87776.\n[I 2025-11-02 21:50:35,694] Trial 14 finished with value: 0.85704 and parameters: {'dir_n_layers': 3, 'dir_l0_units': 1536, 'dir_l1_units': 1024, 'dir_l2_units': 4096, 'scale_n_layers': 4, 'scale_l0_units': 1536, 'scale_l1_units': 256, 'scale_l2_units': 1024, 'scale_l3_units': 256, 'activation': 'gelu', 'batch_size': 2048, 'lr': 0.0002836157588569766, 'dropout_rate': 0.3, 'temp': 0.016945588387939376, 'lambda_mag': 0.9990494738482865}. Best is trial 12 with value: 0.87776.\n[I 2025-11-02 21:50:59,059] Trial 15 pruned. \n[I 2025-11-02 21:52:05,560] Trial 16 finished with value: 0.81896 and parameters: {'dir_n_layers': 3, 'dir_l0_units': 1536, 'dir_l1_units': 1024, 'dir_l2_units': 2048, 'scale_n_layers': 4, 'scale_l0_units': 1536, 'scale_l1_units': 128, 'scale_l2_units': 1024, 'scale_l3_units': 1536, 'activation': 'gelu', 'batch_size': 2048, 'lr': 0.000267417638931011, 'dropout_rate': 0.25, 'temp': 0.02523960491814401, 'lambda_mag': 0.7033046685355153}. Best is trial 12 with value: 0.87776.\n[I 2025-11-02 21:52:19,847] Trial 17 pruned. \n[I 2025-11-02 21:52:35,316] Trial 18 pruned. \n[I 2025-11-02 21:53:30,329] Trial 19 finished with value: 0.81616 and parameters: {'dir_n_layers': 2, 'dir_l0_units': 1536, 'dir_l1_units': 1024, 'scale_n_layers': 4, 'scale_l0_units': 1536, 'scale_l1_units': 256, 'scale_l2_units': 256, 'scale_l3_units': 1024, 'activation': 'celu', 'batch_size': 2048, 'lr': 0.0003607529387464129, 'dropout_rate': 0.25, 'temp': 0.023445782438333635, 'lambda_mag': 0.7349636069804693}. Best is trial 12 with value: 0.87776.\n[I 2025-11-02 21:53:48,739] Trial 20 pruned. \n[I 2025-11-02 21:55:33,373] Trial 21 finished with value: 0.8668 and parameters: {'dir_n_layers': 4, 'dir_l0_units': 1024, 'dir_l1_units': 2048, 'dir_l2_units': 4096, 'dir_l3_units': 2048, 'scale_n_layers': 3, 'scale_l0_units': 256, 'scale_l1_units': 1024, 'scale_l2_units': 1024, 'activation': 'gelu', 'batch_size': 4096, 'lr': 0.00042866816924538344, 'dropout_rate': 0.3, 'temp': 0.010231936386348138, 'lambda_mag': 0.8654863632197592}. Best is trial 12 with value: 0.87776.\n[I 2025-11-02 21:55:55,035] Trial 22 pruned. \n[I 2025-11-02 21:56:13,938] Trial 23 pruned. \n[I 2025-11-02 21:57:36,523] Trial 24 finished with value: 0.84536 and parameters: {'dir_n_layers': 4, 'dir_l0_units': 1536, 'dir_l1_units': 2048, 'dir_l2_units': 4096, 'dir_l3_units': 1024, 'scale_n_layers': 2, 'scale_l0_units': 128, 'scale_l1_units': 256, 'activation': 'gelu', 'batch_size': 2048, 'lr': 0.0004927547008521423, 'dropout_rate': 0.3, 'temp': 0.02015200597670936, 'lambda_mag': 0.974103115726349}. Best is trial 12 with value: 0.87776.\n[I 2025-11-02 21:57:47,578] Trial 25 pruned. \n[I 2025-11-02 21:59:43,787] Trial 26 finished with value: 0.8596 and parameters: {'dir_n_layers': 4, 'dir_l0_units': 4096, 'dir_l1_units': 1024, 'dir_l2_units': 2048, 'dir_l3_units': 4096, 'scale_n_layers': 4, 'scale_l0_units': 1536, 'scale_l1_units': 1536, 'scale_l2_units': 1024, 'scale_l3_units': 256, 'activation': 'gelu', 'batch_size': 4096, 'lr': 0.0004937152620110469, 'dropout_rate': 0.3, 'temp': 0.016321422799821714, 'lambda_mag': 0.9345588582244282}. Best is trial 12 with value: 0.87776.\n[I 2025-11-02 21:59:59,123] Trial 27 pruned. \n[I 2025-11-02 22:00:23,381] Trial 28 pruned. \n[I 2025-11-02 22:00:35,290] Trial 29 pruned. \n[I 2025-11-02 22:00:46,059] Trial 30 pruned. \n[I 2025-11-02 22:02:14,576] Trial 31 finished with value: 0.86928 and parameters: {'dir_n_layers': 4, 'dir_l0_units': 1536, 'dir_l1_units': 1024, 'dir_l2_units': 4096, 'dir_l3_units': 1536, 'scale_n_layers': 4, 'scale_l0_units': 1536, 'scale_l1_units': 1024, 'scale_l2_units': 1024, 'scale_l3_units': 1024, 'activation': 'gelu', 'batch_size': 2048, 'lr': 0.0008662705151696685, 'dropout_rate': 0.3, 'temp': 0.010931276986355588, 'lambda_mag': 0.5317127306027816}. Best is trial 12 with value: 0.87776.\n[I 2025-11-02 22:03:43,111] Trial 32 finished with value: 0.87136 and parameters: {'dir_n_layers': 4, 'dir_l0_units': 1536, 'dir_l1_units': 1024, 'dir_l2_units': 4096, 'dir_l3_units': 1536, 'scale_n_layers': 4, 'scale_l0_units': 1536, 'scale_l1_units': 1024, 'scale_l2_units': 1024, 'scale_l3_units': 1024, 'activation': 'gelu', 'batch_size': 2048, 'lr': 0.000849472387499449, 'dropout_rate': 0.3, 'temp': 0.011040689833076694, 'lambda_mag': 0.5151998987832487}. Best is trial 12 with value: 0.87776.\n[I 2025-11-02 22:05:18,285] Trial 33 finished with value: 0.85808 and parameters: {'dir_n_layers': 4, 'dir_l0_units': 1536, 'dir_l1_units': 1024, 'dir_l2_units': 4096, 'dir_l3_units': 2048, 'scale_n_layers': 4, 'scale_l0_units': 1536, 'scale_l1_units': 1024, 'scale_l2_units': 1024, 'scale_l3_units': 1024, 'activation': 'gelu', 'batch_size': 2048, 'lr': 0.0003914678691562764, 'dropout_rate': 0.3, 'temp': 0.014962557980550692, 'lambda_mag': 0.7210833141862166}. Best is trial 12 with value: 0.87776.\n[I 2025-11-02 22:06:48,391] Trial 34 finished with value: 0.86656 and parameters: {'dir_n_layers': 3, 'dir_l0_units': 1536, 'dir_l1_units': 2048, 'dir_l2_units': 4096, 'scale_n_layers': 3, 'scale_l0_units': 1536, 'scale_l1_units': 512, 'scale_l2_units': 1024, 'activation': 'selu', 'batch_size': 2048, 'lr': 0.0005485441323175688, 'dropout_rate': 0.2, 'temp': 0.012019390666582776, 'lambda_mag': 0.33783575566907187}. Best is trial 12 with value: 0.87776.\n[I 2025-11-02 22:07:02,505] Trial 35 pruned. \n[I 2025-11-02 22:07:17,769] Trial 36 pruned. \n[I 2025-11-02 22:07:36,742] Trial 37 pruned. \n[I 2025-11-02 22:08:02,696] Trial 38 pruned. \n[I 2025-11-02 22:08:19,127] Trial 39 pruned. \n[I 2025-11-02 22:08:30,395] Trial 40 pruned. \n[I 2025-11-02 22:09:58,930] Trial 41 finished with value: 0.86896 and parameters: {'dir_n_layers': 4, 'dir_l0_units': 1536, 'dir_l1_units': 1024, 'dir_l2_units': 4096, 'dir_l3_units': 1536, 'scale_n_layers': 4, 'scale_l0_units': 1536, 'scale_l1_units': 1024, 'scale_l2_units': 1024, 'scale_l3_units': 1024, 'activation': 'gelu', 'batch_size': 2048, 'lr': 0.0006955493602069831, 'dropout_rate': 0.3, 'temp': 0.01102292629230515, 'lambda_mag': 0.5349185236154939}. Best is trial 12 with value: 0.87776.\n[I 2025-11-02 22:10:43,367] Trial 42 pruned. \n[I 2025-11-02 22:11:53,490] Trial 43 finished with value: 0.8604 and parameters: {'dir_n_layers': 4, 'dir_l0_units': 1536, 'dir_l1_units': 1024, 'dir_l2_units': 1024, 'dir_l3_units': 1536, 'scale_n_layers': 4, 'scale_l0_units': 1536, 'scale_l1_units': 1024, 'scale_l2_units': 1024, 'scale_l3_units': 1024, 'activation': 'gelu', 'batch_size': 2048, 'lr': 0.0007081580582085418, 'dropout_rate': 0.3, 'temp': 0.010230687532113755, 'lambda_mag': 0.5837679467268461}. Best is trial 12 with value: 0.87776.\n[I 2025-11-02 22:12:21,071] Trial 44 pruned. \n[I 2025-11-02 22:12:40,424] Trial 45 pruned. \n[I 2025-11-02 22:14:37,561] Trial 46 finished with value: 0.86944 and parameters: {'dir_n_layers': 4, 'dir_l0_units': 1536, 'dir_l1_units': 1024, 'dir_l2_units': 4096, 'dir_l3_units': 4096, 'scale_n_layers': 3, 'scale_l0_units': 256, 'scale_l1_units': 1024, 'scale_l2_units': 1536, 'activation': 'gelu', 'batch_size': 2048, 'lr': 0.0004693908161957021, 'dropout_rate': 0.2, 'temp': 0.015700780725661882, 'lambda_mag': 0.4978758184239239}. Best is trial 12 with value: 0.87776.\n[I 2025-11-02 22:16:07,440] Trial 47 finished with value: 0.8732 and parameters: {'dir_n_layers': 4, 'dir_l0_units': 1536, 'dir_l1_units': 2048, 'dir_l2_units': 1536, 'dir_l3_units': 4096, 'scale_n_layers': 3, 'scale_l0_units': 256, 'scale_l1_units': 512, 'scale_l2_units': 1536, 'activation': 'gelu', 'batch_size': 2048, 'lr': 0.00042306982396842375, 'dropout_rate': 0.2, 'temp': 0.015039334397261635, 'lambda_mag': 0.5991681210669868}. Best is trial 12 with value: 0.87776.\n[I 2025-11-02 22:17:37,252] Trial 48 finished with value: 0.86392 and parameters: {'dir_n_layers': 4, 'dir_l0_units': 1536, 'dir_l1_units': 2048, 'dir_l2_units': 1536, 'dir_l3_units': 4096, 'scale_n_layers': 3, 'scale_l0_units': 256, 'scale_l1_units': 512, 'scale_l2_units': 1536, 'activation': 'gelu', 'batch_size': 2048, 'lr': 0.00031173430887739353, 'dropout_rate': 0.2, 'temp': 0.01820293581240042, 'lambda_mag': 0.6028780223723632}. Best is trial 12 with value: 0.87776.\n[I 2025-11-02 22:18:02,472] Trial 49 pruned. \n[I 2025-11-02 22:18:14,146] Trial 50 pruned. \n[I 2025-11-02 22:19:42,817] Trial 51 finished with value: 0.87656 and parameters: {'dir_n_layers': 4, 'dir_l0_units': 1536, 'dir_l1_units': 2048, 'dir_l2_units': 1536, 'dir_l3_units': 4096, 'scale_n_layers': 3, 'scale_l0_units': 256, 'scale_l1_units': 256, 'scale_l2_units': 1536, 'activation': 'gelu', 'batch_size': 2048, 'lr': 0.0006218139270677457, 'dropout_rate': 0.2, 'temp': 0.012735931094679262, 'lambda_mag': 0.6740829618440566}. Best is trial 12 with value: 0.87776.\n[I 2025-11-02 22:21:11,729] Trial 52 finished with value: 0.87536 and parameters: {'dir_n_layers': 4, 'dir_l0_units': 1536, 'dir_l1_units': 2048, 'dir_l2_units': 1536, 'dir_l3_units': 4096, 'scale_n_layers': 3, 'scale_l0_units': 256, 'scale_l1_units': 256, 'scale_l2_units': 1536, 'activation': 'gelu', 'batch_size': 2048, 'lr': 0.000554009750994732, 'dropout_rate': 0.2, 'temp': 0.012443557842432505, 'lambda_mag': 0.6750377506145792}. Best is trial 12 with value: 0.87776.\n[I 2025-11-02 22:22:40,600] Trial 53 finished with value: 0.8692 and parameters: {'dir_n_layers': 4, 'dir_l0_units': 1536, 'dir_l1_units': 2048, 'dir_l2_units': 1536, 'dir_l3_units': 4096, 'scale_n_layers': 3, 'scale_l0_units': 256, 'scale_l1_units': 256, 'scale_l2_units': 1536, 'activation': 'gelu', 'batch_size': 2048, 'lr': 0.00023018137260685033, 'dropout_rate': 0.2, 'temp': 0.01411146635235491, 'lambda_mag': 0.7455264932449398}. Best is trial 12 with value: 0.87776.\n[I 2025-11-02 22:24:09,457] Trial 54 finished with value: 0.8748 and parameters: {'dir_n_layers': 4, 'dir_l0_units': 1536, 'dir_l1_units': 2048, 'dir_l2_units': 1536, 'dir_l3_units': 4096, 'scale_n_layers': 3, 'scale_l0_units': 256, 'scale_l1_units': 256, 'scale_l2_units': 1536, 'activation': 'gelu', 'batch_size': 2048, 'lr': 0.0005591295611991235, 'dropout_rate': 0.2, 'temp': 0.013083283072664726, 'lambda_mag': 0.6749615444197985}. Best is trial 12 with value: 0.87776.\n[I 2025-11-02 22:25:38,409] Trial 55 finished with value: 0.8756 and parameters: {'dir_n_layers': 4, 'dir_l0_units': 1536, 'dir_l1_units': 2048, 'dir_l2_units': 1536, 'dir_l3_units': 4096, 'scale_n_layers': 3, 'scale_l0_units': 256, 'scale_l1_units': 256, 'scale_l2_units': 1536, 'activation': 'gelu', 'batch_size': 2048, 'lr': 0.0003343551722966735, 'dropout_rate': 0.2, 'temp': 0.012739621540129727, 'lambda_mag': 0.6811612250566559}. Best is trial 12 with value: 0.87776.\n[I 2025-11-02 22:27:07,449] Trial 56 finished with value: 0.8728 and parameters: {'dir_n_layers': 4, 'dir_l0_units': 1536, 'dir_l1_units': 2048, 'dir_l2_units': 1536, 'dir_l3_units': 4096, 'scale_n_layers': 3, 'scale_l0_units': 256, 'scale_l1_units': 256, 'scale_l2_units': 1536, 'activation': 'gelu', 'batch_size': 2048, 'lr': 0.00034053245573519757, 'dropout_rate': 0.2, 'temp': 0.01286204462393984, 'lambda_mag': 0.6850639993160414}. Best is trial 12 with value: 0.87776.\n[I 2025-11-02 22:27:25,148] Trial 57 pruned. \n[I 2025-11-02 22:27:43,837] Trial 58 pruned. \n[I 2025-11-02 22:27:56,939] Trial 59 pruned. \n[I 2025-11-02 22:28:13,400] Trial 60 pruned. \n[I 2025-11-02 22:29:42,428] Trial 61 finished with value: 0.87272 and parameters: {'dir_n_layers': 4, 'dir_l0_units': 1536, 'dir_l1_units': 2048, 'dir_l2_units': 1536, 'dir_l3_units': 4096, 'scale_n_layers': 3, 'scale_l0_units': 256, 'scale_l1_units': 256, 'scale_l2_units': 1536, 'activation': 'gelu', 'batch_size': 2048, 'lr': 0.000326371642638627, 'dropout_rate': 0.2, 'temp': 0.013108754970871214, 'lambda_mag': 0.6868933940339813}. Best is trial 12 with value: 0.87776.\n[I 2025-11-02 22:31:11,288] Trial 62 finished with value: 0.87248 and parameters: {'dir_n_layers': 4, 'dir_l0_units': 1536, 'dir_l1_units': 2048, 'dir_l2_units': 1536, 'dir_l3_units': 4096, 'scale_n_layers': 3, 'scale_l0_units': 256, 'scale_l1_units': 256, 'scale_l2_units': 1536, 'activation': 'gelu', 'batch_size': 2048, 'lr': 0.0003587195283303231, 'dropout_rate': 0.2, 'temp': 0.012701307496062185, 'lambda_mag': 0.6909274424973398}. Best is trial 12 with value: 0.87776.\n[I 2025-11-02 22:32:40,094] Trial 63 finished with value: 0.86904 and parameters: {'dir_n_layers': 4, 'dir_l0_units': 1536, 'dir_l1_units': 2048, 'dir_l2_units': 1536, 'dir_l3_units': 4096, 'scale_n_layers': 3, 'scale_l0_units': 256, 'scale_l1_units': 256, 'scale_l2_units': 1536, 'activation': 'gelu', 'batch_size': 2048, 'lr': 0.0004261217975796138, 'dropout_rate': 0.2, 'temp': 0.016485274057926536, 'lambda_mag': 0.7513629338236917}. Best is trial 12 with value: 0.87776.\n[I 2025-11-02 22:34:08,866] Trial 64 finished with value: 0.87008 and parameters: {'dir_n_layers': 4, 'dir_l0_units': 1536, 'dir_l1_units': 2048, 'dir_l2_units': 1536, 'dir_l3_units': 4096, 'scale_n_layers': 3, 'scale_l0_units': 256, 'scale_l1_units': 256, 'scale_l2_units': 1536, 'activation': 'gelu', 'batch_size': 2048, 'lr': 0.00027865749259137554, 'dropout_rate': 0.2, 'temp': 0.014238751445105821, 'lambda_mag': 0.5625162524596988}. Best is trial 12 with value: 0.87776.\n[I 2025-11-02 22:34:26,957] Trial 65 pruned. \n[I 2025-11-02 22:35:53,989] Trial 66 pruned. \n[I 2025-11-02 22:37:02,667] Trial 67 finished with value: 0.86992 and parameters: {'dir_n_layers': 4, 'dir_l0_units': 1536, 'dir_l1_units': 2048, 'dir_l2_units': 1536, 'dir_l3_units': 1024, 'scale_n_layers': 3, 'scale_l0_units': 1024, 'scale_l1_units': 256, 'scale_l2_units': 1536, 'activation': 'gelu', 'batch_size': 2048, 'lr': 0.0007212089927378279, 'dropout_rate': 0.2, 'temp': 0.010050759037318939, 'lambda_mag': 0.8127542944822341}. Best is trial 12 with value: 0.87776.\n[I 2025-11-02 22:37:14,721] Trial 68 pruned. \n[I 2025-11-02 22:38:45,536] Trial 69 finished with value: 0.87552 and parameters: {'dir_n_layers': 4, 'dir_l0_units': 2048, 'dir_l1_units': 2048, 'dir_l2_units': 1536, 'dir_l3_units': 4096, 'scale_n_layers': 3, 'scale_l0_units': 256, 'scale_l1_units': 256, 'scale_l2_units': 128, 'activation': 'gelu', 'batch_size': 2048, 'lr': 0.0002733102698684135, 'dropout_rate': 0.2, 'temp': 0.01180342987342388, 'lambda_mag': 0.7805654626467323}. Best is trial 12 with value: 0.87776.\n[I 2025-11-02 22:40:15,772] Trial 70 finished with value: 0.87928 and parameters: {'dir_n_layers': 4, 'dir_l0_units': 2048, 'dir_l1_units': 2048, 'dir_l2_units': 1536, 'dir_l3_units': 4096, 'scale_n_layers': 2, 'scale_l0_units': 128, 'scale_l1_units': 256, 'activation': 'gelu', 'batch_size': 2048, 'lr': 0.0004944305652643576, 'dropout_rate': 0.25, 'temp': 0.011284474643610163, 'lambda_mag': 0.7763296874424117}. Best is trial 70 with value: 0.87928.\n[I 2025-11-02 22:41:46,391] Trial 71 finished with value: 0.87864 and parameters: {'dir_n_layers': 4, 'dir_l0_units': 2048, 'dir_l1_units': 2048, 'dir_l2_units': 1536, 'dir_l3_units': 4096, 'scale_n_layers': 2, 'scale_l0_units': 128, 'scale_l1_units': 256, 'activation': 'gelu', 'batch_size': 2048, 'lr': 0.0004307555246577123, 'dropout_rate': 0.25, 'temp': 0.011561034962592864, 'lambda_mag': 0.8878984116962514}. Best is trial 70 with value: 0.87928.\n[I 2025-11-02 22:43:16,840] Trial 72 finished with value: 0.8768 and parameters: {'dir_n_layers': 4, 'dir_l0_units': 2048, 'dir_l1_units': 2048, 'dir_l2_units': 1536, 'dir_l3_units': 4096, 'scale_n_layers': 2, 'scale_l0_units': 128, 'scale_l1_units': 256, 'activation': 'gelu', 'batch_size': 2048, 'lr': 0.0005070836963052109, 'dropout_rate': 0.25, 'temp': 0.011365565807601397, 'lambda_mag': 0.905029455633118}. Best is trial 70 with value: 0.87928.\n[I 2025-11-02 22:44:47,139] Trial 73 finished with value: 0.87272 and parameters: {'dir_n_layers': 4, 'dir_l0_units': 2048, 'dir_l1_units': 2048, 'dir_l2_units': 1536, 'dir_l3_units': 4096, 'scale_n_layers': 2, 'scale_l0_units': 128, 'scale_l1_units': 256, 'activation': 'gelu', 'batch_size': 2048, 'lr': 0.00026796588011457063, 'dropout_rate': 0.25, 'temp': 0.011489408794396654, 'lambda_mag': 0.8902651273409765}. Best is trial 70 with value: 0.87928.\n[I 2025-11-02 22:45:06,912] Trial 74 pruned. \n[I 2025-11-02 22:45:20,846] Trial 75 pruned. \n[I 2025-11-02 22:45:38,323] Trial 76 pruned. \n[I 2025-11-02 22:45:56,794] Trial 77 pruned. \n[I 2025-11-02 22:47:33,696] Trial 78 finished with value: 0.87856 and parameters: {'dir_n_layers': 4, 'dir_l0_units': 2048, 'dir_l1_units': 4096, 'dir_l2_units': 1024, 'dir_l3_units': 4096, 'scale_n_layers': 2, 'scale_l0_units': 128, 'scale_l1_units': 128, 'activation': 'gelu', 'batch_size': 2048, 'lr': 0.0006365286983215328, 'dropout_rate': 0.25, 'temp': 0.011008532569730806, 'lambda_mag': 0.8268963173608025}. Best is trial 70 with value: 0.87928.\n[I 2025-11-02 22:48:49,183] Trial 79 pruned. \n[I 2025-11-02 22:49:11,909] Trial 80 pruned. \n[I 2025-11-02 22:50:48,729] Trial 81 finished with value: 0.87216 and parameters: {'dir_n_layers': 4, 'dir_l0_units': 2048, 'dir_l1_units': 4096, 'dir_l2_units': 1024, 'dir_l3_units': 4096, 'scale_n_layers': 2, 'scale_l0_units': 128, 'scale_l1_units': 128, 'activation': 'gelu', 'batch_size': 2048, 'lr': 0.0004940773812019216, 'dropout_rate': 0.25, 'temp': 0.011945553356604844, 'lambda_mag': 0.8022107501628023}. Best is trial 70 with value: 0.87928.\n[I 2025-11-02 22:51:08,715] Trial 82 pruned. \n[I 2025-11-02 22:51:26,947] Trial 83 pruned. \n[I 2025-11-02 22:53:05,708] Trial 84 pruned. \n[I 2025-11-02 22:54:52,906] Trial 85 finished with value: 0.8748 and parameters: {'dir_n_layers': 4, 'dir_l0_units': 2048, 'dir_l1_units': 4096, 'dir_l2_units': 1536, 'dir_l3_units': 4096, 'scale_n_layers': 1, 'scale_l0_units': 128, 'activation': 'gelu', 'batch_size': 2048, 'lr': 0.000378628081154963, 'dropout_rate': 0.25, 'temp': 0.013019323619871159, 'lambda_mag': 0.7750416482998286}. Best is trial 70 with value: 0.87928.\n[I 2025-11-02 22:55:06,449] Trial 86 pruned. \n[I 2025-11-02 22:55:23,639] Trial 87 pruned. \n[I 2025-11-02 22:55:37,994] Trial 88 pruned. \n[I 2025-11-02 22:55:53,792] Trial 89 pruned. \n[I 2025-11-02 22:56:07,772] Trial 90 pruned. \n[I 2025-11-02 22:57:51,200] Trial 91 finished with value: 0.87248 and parameters: {'dir_n_layers': 4, 'dir_l0_units': 4096, 'dir_l1_units': 2048, 'dir_l2_units': 1536, 'dir_l3_units': 4096, 'scale_n_layers': 2, 'scale_l0_units': 128, 'scale_l1_units': 256, 'activation': 'gelu', 'batch_size': 2048, 'lr': 0.0005709581446440632, 'dropout_rate': 0.2, 'temp': 0.013061799111446445, 'lambda_mag': 0.7638668415934866}. Best is trial 70 with value: 0.87928.\n[I 2025-11-02 22:59:21,844] Trial 92 finished with value: 0.87432 and parameters: {'dir_n_layers': 4, 'dir_l0_units': 2048, 'dir_l1_units': 2048, 'dir_l2_units': 1536, 'dir_l3_units': 4096, 'scale_n_layers': 3, 'scale_l0_units': 256, 'scale_l1_units': 256, 'scale_l2_units': 128, 'activation': 'gelu', 'batch_size': 2048, 'lr': 0.0004247406040595627, 'dropout_rate': 0.2, 'temp': 0.012700398086903032, 'lambda_mag': 0.6643536561202654}. Best is trial 70 with value: 0.87928.\n[I 2025-11-02 23:00:52,160] Trial 93 finished with value: 0.8772 and parameters: {'dir_n_layers': 4, 'dir_l0_units': 2048, 'dir_l1_units': 2048, 'dir_l2_units': 1536, 'dir_l3_units': 4096, 'scale_n_layers': 3, 'scale_l0_units': 128, 'scale_l1_units': 256, 'scale_l2_units': 128, 'activation': 'gelu', 'batch_size': 2048, 'lr': 0.0006585756427519437, 'dropout_rate': 0.2, 'temp': 0.011562573392022931, 'lambda_mag': 0.7219360610970212}. Best is trial 70 with value: 0.87928.\n[I 2025-11-02 23:02:22,740] Trial 94 finished with value: 0.8772 and parameters: {'dir_n_layers': 4, 'dir_l0_units': 2048, 'dir_l1_units': 2048, 'dir_l2_units': 1536, 'dir_l3_units': 4096, 'scale_n_layers': 3, 'scale_l0_units': 128, 'scale_l1_units': 256, 'scale_l2_units': 128, 'activation': 'gelu', 'batch_size': 2048, 'lr': 0.0007122469137576325, 'dropout_rate': 0.2, 'temp': 0.011140545638795789, 'lambda_mag': 0.710815805032105}. Best is trial 70 with value: 0.87928.\n[I 2025-11-02 23:02:41,263] Trial 95 pruned. \n[I 2025-11-02 23:02:59,672] Trial 96 pruned. \n[I 2025-11-02 23:04:32,289] Trial 97 finished with value: 0.87352 and parameters: {'dir_n_layers': 4, 'dir_l0_units': 2048, 'dir_l1_units': 4096, 'dir_l2_units': 1536, 'dir_l3_units': 2048, 'scale_n_layers': 3, 'scale_l0_units': 128, 'scale_l1_units': 256, 'scale_l2_units': 128, 'activation': 'gelu', 'batch_size': 2048, 'lr': 0.00045876137087184893, 'dropout_rate': 0.25, 'temp': 0.011527861252382567, 'lambda_mag': 0.8787682334397655}. Best is trial 70 with value: 0.87928.\n[I 2025-11-02 23:04:50,488] Trial 98 pruned. \n[I 2025-11-02 23:05:08,695] Trial 99 pruned. \n","output_type":"stream"},{"name":"stdout","text":"Study statistics:\n  Number of finished trials:  100\n  Best trial:\n    Value:  0.87928\n    Params: \n      dir_n_layers: 4\n      dir_l0_units: 2048\n      dir_l1_units: 2048\n      dir_l2_units: 1536\n      dir_l3_units: 4096\n      scale_n_layers: 2\n      scale_l0_units: 128\n      scale_l1_units: 256\n      activation: gelu\n      batch_size: 2048\n      lr: 0.0004944305652643576\n      dropout_rate: 0.25\n      temp: 0.011284474643610163\n      lambda_mag: 0.7763296874424117\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_37/3913331361.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mstudy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrun_optuna_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_trials\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0moptuna\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstudy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstudy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mStorage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mstudy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrials_dataframe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"optuna_trials.csv\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mbest_trial_number\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstudy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_trial\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumber\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mAttributeError\u001b[0m: module 'optuna.study.study' has no attribute 'Storage'"],"ename":"AttributeError","evalue":"module 'optuna.study.study' has no attribute 'Storage'","output_type":"error"}],"execution_count":31},{"cell_type":"code","source":"print(1)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-02T21:11:34.398889Z","iopub.status.idle":"2025-11-02T21:11:34.399102Z","shell.execute_reply.started":"2025-11-02T21:11:34.399003Z","shell.execute_reply":"2025-11-02T21:11:34.399012Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"","metadata":{}}]}