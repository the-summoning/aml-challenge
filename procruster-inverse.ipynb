{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":117959,"databundleVersionId":14220991,"sourceType":"competition"}],"dockerImageVersionId":31153,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport random\nimport pandas as pd\nfrom tqdm import tqdm\n\nimport numpy as np\nimport datetime\nimport torch.nn.functional as F\nfrom torch.utils.data import TensorDataset, DataLoader\n\nfrom pathlib import Path","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-10-30T14:23:05.240974Z","iopub.execute_input":"2025-10-30T14:23:05.241759Z","iopub.status.idle":"2025-10-30T14:23:05.245876Z","shell.execute_reply.started":"2025-10-30T14:23:05.241735Z","shell.execute_reply":"2025-10-30T14:23:05.244985Z"}},"outputs":[],"execution_count":16},{"cell_type":"code","source":"DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\nprint('Device:', DEVICE)\n\ndata_path= Path('/kaggle/input/aml-competition/train/train/train.npz')\ntest_path= Path('/kaggle/input/aml-competition/test/test/test.clean.npz')\n\ndata = np.load(data_path)\n\ncaption_embeddings = data['captions/embeddings']\nimage_embeddings = data['images/embeddings']\ncaption_labels = data['captions/label']\n\ndata.close()\n\nx_abs = torch.from_numpy(caption_embeddings) # captions space\ny_abs = torch.from_numpy(image_embeddings[np.argmax(caption_labels, axis=1)]) # images space\n\nprint('Captions latent space:', x_abs.shape)\nprint('Images latent space:', y_abs.shape)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-30T14:23:05.247238Z","iopub.execute_input":"2025-10-30T14:23:05.247519Z","iopub.status.idle":"2025-10-30T14:23:18.288119Z","shell.execute_reply.started":"2025-10-30T14:23:05.247503Z","shell.execute_reply":"2025-10-30T14:23:18.287400Z"}},"outputs":[{"name":"stdout","text":"Device: cuda\nCaptions latent space: torch.Size([125000, 1024])\nImages latent space: torch.Size([125000, 1536])\n","output_type":"stream"}],"execution_count":17},{"cell_type":"code","source":"def center(data: torch.Tensor):\n    return data - data.mean(dim=0, keepdim=True)\n\n\ndef normalize(data: torch.Tensor):\n    return F.normalize(data, p=2, dim=1)\n\n\ndef extract_anchors(x_abs: torch.Tensor, y_abs: torch.Tensor, anchors_number: int):\n    indices = torch.randperm(x_abs.size(0))[:anchors_number]\n    \n    return x_abs[indices], y_abs[indices]\n\n\ndef releative_representation(data: torch.Tensor, anchors: torch.Tensor):\n    return F.normalize(data, p=2, dim=1) @ F.normalize(anchors.T, p=2, dim=1)\n\ndef procrustes_align(X, Y, scale=True):\n    mu_X = X.mean(dim=0, keepdim=True)\n    mu_Y = Y.mean(dim=0, keepdim=True)\n\n    X_centered = X - mu_X\n    Y_centered = Y - mu_Y\n\n    C = X_centered.T @ Y_centered\n\n    U, S, Vt = torch.linalg.svd(C, full_matrices=True)\n    R = U @ Vt\n\n    if torch.det(R) < 0:\n        Vt[-1, :] *= -1\n        R = U @ Vt\n\n    if scale:\n        s = S.sum() / (X_centered ** 2).sum()\n    else:\n        s = 1.0\n\n    t = mu_Y.squeeze() - s * (mu_X @ R)\n\n    return R, s, t\n\ndef align_matrix(m: torch.Tensor, R, s, t):\n    return s * (m @ R) + t","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-30T14:23:18.289363Z","iopub.execute_input":"2025-10-30T14:23:18.289766Z","iopub.status.idle":"2025-10-30T14:23:18.296812Z","shell.execute_reply.started":"2025-10-30T14:23:18.289747Z","shell.execute_reply":"2025-10-30T14:23:18.296222Z"}},"outputs":[],"execution_count":18},{"cell_type":"code","source":"anchors_number = 1000\n\nx = normalize(center(x_abs))\ny = normalize(center(y_abs))\n\nx_anchors, y_anchors = extract_anchors(x, y, anchors_number)\n\nx_rel = x @ x_anchors.T\ny_rel = y @ y_anchors.T\n\nprint('Rank X anchors', torch.linalg.matrix_rank(x_anchors).item())\nprint('Rank Y anchors', torch.linalg.matrix_rank(y_anchors).item())\n\nR, s, t = procrustes_align(x_rel, y_rel)\n\nx_rel_aligned = align_matrix(x_rel, R, s, t)\n\nprint(\"Mean squared distance after alignment:\", ((x_rel_aligned - y_rel) ** 2).mean().item())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-30T14:23:18.297644Z","iopub.execute_input":"2025-10-30T14:23:18.297853Z","iopub.status.idle":"2025-10-30T14:23:27.884370Z","shell.execute_reply.started":"2025-10-30T14:23:18.297836Z","shell.execute_reply":"2025-10-30T14:23:27.883692Z"}},"outputs":[{"name":"stdout","text":"Rank X anchors 1000\nRank Y anchors 988\nMean squared distance after alignment: 0.009509388357400894\n","output_type":"stream"}],"execution_count":19},{"cell_type":"code","source":"torch.save({\n    'x_anchors': x_anchors,\n    'y_anchors': y_anchors,\n    'procrustes_R': R,\n    'procrustes_s': s,\n    'procrustes_t': t\n}, 'anchors_and_procrustes.pth')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-30T14:23:27.885629Z","iopub.execute_input":"2025-10-30T14:23:27.885856Z","iopub.status.idle":"2025-10-30T14:23:27.918410Z","shell.execute_reply.started":"2025-10-30T14:23:27.885841Z","shell.execute_reply":"2025-10-30T14:23:27.917625Z"}},"outputs":[],"execution_count":20},{"cell_type":"code","source":"def generate_submission(test_path: Path, output_file_name=\"submission\"):\n    timestamp = datetime.datetime.now().strftime('%Y-%m-%d_%H-%M-%S')\n\n    output_file = f'{output_file_name}--{timestamp}.csv'\n    \n    test_data = np.load(test_path)\n    \n    sample_ids = test_data['captions/ids']\n    test_embds = test_data['captions/embeddings']\n    \n    test_data.close()\n    \n    test_embds = torch.from_numpy(test_embds).float()\n    test_embds = normalize(center(test_embds)) # like training\n    \n    pseudo_inverse = torch.linalg.pinv(y_anchors.T)\n\n    x_rel_test = (test_embds @ x_anchors.T)\n    x_rel_test = align_matrix(x_rel_test, R, s, t)\n    \n    pred_embds = x_rel_test @ pseudo_inverse\n\n    print('Y abs reconstructed shape:', pred_embds.shape)\n\n    print(\"Generating submission file...\")\n\n    if isinstance(pred_embds, torch.Tensor):\n        pred_embds = pred_embds.cpu().numpy()\n\n    df_submission = pd.DataFrame({'id': sample_ids, 'embedding': pred_embds.tolist()})\n\n    df_submission.to_csv(output_file, index=False, float_format='%.17g')\n    print(f\"✓ Saved submission to {output_file}\")\n\n    return pred_embds\n\n\npred_embds = generate_submission(test_path)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-30T14:23:27.919219Z","iopub.execute_input":"2025-10-30T14:23:27.919469Z","iopub.status.idle":"2025-10-30T14:23:31.395636Z","shell.execute_reply.started":"2025-10-30T14:23:27.919447Z","shell.execute_reply":"2025-10-30T14:23:31.395010Z"}},"outputs":[{"name":"stdout","text":"Y abs reconstructed shape: torch.Size([1500, 1536])\nGenerating submission file...\n✓ Saved submission to submission--2025-10-30_14-23-27.csv\n","output_type":"stream"}],"execution_count":21}]}