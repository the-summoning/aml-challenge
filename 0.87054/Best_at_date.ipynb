{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "pErT3mEBFSji"
      },
      "outputs": [],
      "source": [
        "from typing import Optional\n",
        "from torch import nn\n",
        "from torch.nn import functional as F\n",
        "import torch\n",
        "\n",
        "class SpaceTranslator(nn.Module):\n",
        "    def __init__(\n",
        "        self,\n",
        "        input_dim,\n",
        "        output_dim,\n",
        "        hidden_layers,\n",
        "        activation,\n",
        "        dropout_rate,\n",
        "        scaling=None,\n",
        "        centering=None\n",
        "    ):\n",
        "        super().__init__()\n",
        "\n",
        "        self.scaling = scaling\n",
        "        self.centering = centering\n",
        "\n",
        "        layers = []\n",
        "        last = input_dim\n",
        "\n",
        "        for hidden in hidden_layers:\n",
        "            layers += [\n",
        "                nn.Linear(last, hidden),\n",
        "                # nn.LayerNorm(hidden),\n",
        "                nn.BatchNorm1d(hidden),\n",
        "                activation(),\n",
        "                nn.Dropout(dropout_rate)\n",
        "            ]\n",
        "            last = hidden\n",
        "\n",
        "        layers.append(nn.Linear(last, output_dim))\n",
        "        self.net = nn.Sequential(*layers)\n",
        "\n",
        "        self.logit_scale = nn.Parameter(torch.ones([]) * np.log(1/0.07))\n",
        "\n",
        "        self.apply(self.init_weights)\n",
        "\n",
        "    def init_weights(self, module):\n",
        "        if isinstance(module, nn.Linear):\n",
        "            nn.init.kaiming_uniform_(module.weight, a=0, mode='fan_in', nonlinearity='relu')\n",
        "            if module.bias is not None:\n",
        "                nn.init.constant_(module.bias, 0.0)\n",
        "        elif isinstance(module, nn.LayerNorm) or isinstance(module, nn.BatchNorm1d):\n",
        "            nn.init.ones_(module.weight)\n",
        "            nn.init.zeros_(module.bias)\n",
        "\n",
        "    def forward(self, x):\n",
        "      return self.net(x)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "umdq3vIdKFfa"
      },
      "outputs": [],
      "source": [
        "from pathlib import Path\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "'''Code from https://github.com/Mamiglia/challenge'''\n",
        "\n",
        "def mrr(pred_indices: np.ndarray, gt_indices: np.ndarray) -> float:\n",
        "    \"\"\"\n",
        "    Compute Mean Reciprocal Rank (MRR)\n",
        "    Args:\n",
        "        pred_indices: (N, K) array of predicted indices for N queries (top-K)\n",
        "        gt_indices: (N,) array of ground truth indices\n",
        "    Returns:\n",
        "        mrr: Mean Reciprocal Rank\n",
        "    \"\"\"\n",
        "    reciprocal_ranks = []\n",
        "    for i in range(len(gt_indices)):\n",
        "        matches = np.where(pred_indices[i] == gt_indices[i])[0]\n",
        "        if matches.size > 0:\n",
        "            reciprocal_ranks.append(1.0 / (matches[0] + 1))\n",
        "        else:\n",
        "            reciprocal_ranks.append(0.0)\n",
        "    return np.mean(reciprocal_ranks)\n",
        "\n",
        "\n",
        "def recall_at_k(pred_indices: np.ndarray, gt_indices: np.ndarray, k: int) -> float:\n",
        "    \"\"\"Compute Recall@k\n",
        "    Args:\n",
        "        pred_indices: (N, N) array of top indices for N queries\n",
        "        gt_indices: (N,) array of ground truth indices\n",
        "        k: number of top predictions to consider\n",
        "    Returns:\n",
        "        recall: Recall@k\n",
        "    \"\"\"\n",
        "    recall = 0\n",
        "    for i in range(len(gt_indices)):\n",
        "        if gt_indices[i] in pred_indices[i, :k]:\n",
        "            recall += 1\n",
        "    recall /= len(gt_indices)\n",
        "    return recall\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "def ndcg(pred_indices: np.ndarray, gt_indices: np.ndarray, k: int = 100) -> float:\n",
        "    \"\"\"\n",
        "    Compute Normalized Discounted Cumulative Gain (NDCG@k)\n",
        "    Args:\n",
        "        pred_indices: (N, K) array of predicted indices for N queries\n",
        "        gt_indices: (N,) array of ground truth indices\n",
        "        k: number of top predictions to consider\n",
        "    Returns:\n",
        "        ndcg: NDCG@k\n",
        "    \"\"\"\n",
        "    ndcg_total = 0.0\n",
        "    for i in range(len(gt_indices)):\n",
        "        matches = np.where(pred_indices[i, :k] == gt_indices[i])[0]\n",
        "        if matches.size > 0:\n",
        "            rank = matches[0] + 1\n",
        "            ndcg_total += 1.0 / np.log2(rank + 1)  # DCG (IDCG = 1)\n",
        "    return ndcg_total / len(gt_indices)\n",
        "\n",
        "\n",
        "\n",
        "@torch.inference_mode()\n",
        "def evaluate_retrieval(translated_embd, image_embd, gt_indices, max_indices = 99, batch_size=100):\n",
        "    \"\"\"Evaluate retrieval performance using cosine similarity\n",
        "    Args:\n",
        "        translated_embd: (N_captions, D) translated caption embeddings\n",
        "        image_embd: (N_images, D) image embeddings\n",
        "        gt_indices: (N_captions,) ground truth image indices for each caption\n",
        "        max_indices: number of top predictions to consider\n",
        "    Returns:\n",
        "        results: dict of evaluation metrics\n",
        "\n",
        "    \"\"\"\n",
        "    # Compute similarity matrix\n",
        "    if isinstance(translated_embd, np.ndarray):\n",
        "        translated_embd = torch.from_numpy(translated_embd).float()\n",
        "    if isinstance(image_embd, np.ndarray):\n",
        "        image_embd = torch.from_numpy(image_embd).float()\n",
        "\n",
        "    n_queries = translated_embd.shape[0]\n",
        "    device = translated_embd.device\n",
        "\n",
        "    # Prepare containers for the fragments to be reassembled\n",
        "    all_sorted_indices = []\n",
        "    l2_distances = []\n",
        "\n",
        "    # Process in batches - the narrow gate approach\n",
        "    for start_idx in range(0, n_queries, batch_size):\n",
        "        batch_slice = slice(start_idx, min(start_idx + batch_size, n_queries))\n",
        "        batch_translated = translated_embd[batch_slice]\n",
        "        batch_img_embd = image_embd[batch_slice]\n",
        "\n",
        "        # Compute similarity only for this batch\n",
        "        batch_similarity = batch_translated @ batch_img_embd.T\n",
        "\n",
        "        # Get top-k predictions for this batch\n",
        "        batch_indices = batch_similarity.topk(k=max_indices, dim=1, sorted=True).indices.numpy()\n",
        "        all_sorted_indices.append(gt_indices[batch_slice][batch_indices])\n",
        "\n",
        "        # Compute L2 distance for this batch\n",
        "        batch_gt = gt_indices[batch_slice]\n",
        "        batch_gt_embeddings = image_embd[batch_gt]\n",
        "        batch_l2 = (batch_translated - batch_gt_embeddings).norm(dim=1)\n",
        "        l2_distances.append(batch_l2)\n",
        "\n",
        "    # Reassemble the fragments\n",
        "    sorted_indices = np.concatenate(all_sorted_indices, axis=0)\n",
        "\n",
        "    # Apply the sacred metrics to the whole\n",
        "    metrics = {\n",
        "        'mrr': mrr,\n",
        "        'ndcg': ndcg,\n",
        "        'recall_at_1': lambda preds, gt: recall_at_k(preds, gt, 1),\n",
        "        'recall_at_3': lambda preds, gt: recall_at_k(preds, gt, 3),\n",
        "        'recall_at_5': lambda preds, gt: recall_at_k(preds, gt, 5),\n",
        "        'recall_at_10': lambda preds, gt: recall_at_k(preds, gt, 10),\n",
        "        'recall_at_50': lambda preds, gt: recall_at_k(preds, gt, 50),\n",
        "    }\n",
        "\n",
        "    results = {\n",
        "        name: func(sorted_indices, gt_indices)\n",
        "        for name, func in metrics.items()\n",
        "    }\n",
        "\n",
        "    l2_dist = torch.cat(l2_distances, dim=0).mean().item()\n",
        "    results['l2_dist'] = l2_dist\n",
        "\n",
        "    return results\n",
        "\n",
        "def eval_on_val(x_val: np.ndarray, y_val: np.ndarray, model: nn.Module, device) -> dict:\n",
        "    gt_indices = torch.arange(len(y_val))\n",
        "\n",
        "    model.eval()\n",
        "\n",
        "    with torch.inference_mode():\n",
        "        translated = model(x_val.to(device)).to('cpu')\n",
        "\n",
        "    results = evaluate_retrieval(translated, y_val, gt_indices)\n",
        "\n",
        "    return results\n",
        "\n",
        "\n",
        "def generate_submission(model: nn.Module, test_path: Path, output_file=\"submission-dirmodel.csv\", device=None):\n",
        "    test_data = np.load(test_path)\n",
        "    sample_ids = test_data['captions/ids']\n",
        "    test_embds = test_data['captions/embeddings']\n",
        "    test_embds = torch.from_numpy(test_embds).float()\n",
        "\n",
        "    with torch.no_grad():\n",
        "        pred_embds = model(test_embds.to(device)).cpu()\n",
        "\n",
        "    print(\"Generating submission file...\")\n",
        "\n",
        "    if isinstance(pred_embds, torch.Tensor):\n",
        "        pred_embds = pred_embds.cpu().numpy()\n",
        "\n",
        "    df_submission = pd.DataFrame({'id': sample_ids, 'embedding': pred_embds.tolist()})\n",
        "\n",
        "    df_submission.to_csv(output_file, index=False, float_format='%.17g')\n",
        "    print(f\"âœ“ Saved submission to {output_file}\")\n",
        "\n",
        "    return df_submission"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_Ng-afH6FqPt"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "from torch.utils.data import random_split\n",
        "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
        "from tqdm import tqdm\n",
        "\n",
        "def info_nce_loss(dir_preds, img_targets, logit_scale: float):\n",
        "    dir_preds = F.normalize(dir_preds, dim=-1)\n",
        "    img_targets = F.normalize(img_targets, dim=-1)\n",
        "\n",
        "    logit_scale = torch.clamp(logit_scale, max=np.log(100))\n",
        "\n",
        "    logits = (dir_preds @ img_targets.T) * logit_scale.exp()\n",
        "    labels = torch.arange(logits.size(0), device=logits.device)\n",
        "\n",
        "    loss_t2i = F.cross_entropy(logits, labels)\n",
        "    loss_i2t = F.cross_entropy(logits.T, labels)\n",
        "\n",
        "    return 0.5 * (loss_t2i + loss_i2t)\n",
        "\n",
        "def info_nce_loss_hard(dir_preds, img_targets, logit_scale, k=256):\n",
        "    # Normalize (important)\n",
        "    dir_preds = F.normalize(dir_preds, dim=-1)\n",
        "    img_targets = F.normalize(img_targets, dim=-1)\n",
        "\n",
        "    logit_scale = torch.clamp(logit_scale, max=np.log(100))\n",
        "    logits = torch.matmul(dir_preds, img_targets.t()) * logit_scale.exp()  # (B, B)\n",
        "    B = logits.size(0)\n",
        "    device = logits.device\n",
        "\n",
        "    labels = torch.arange(B, device=device)\n",
        "\n",
        "    # Mask out positives \n",
        "    diag_mask = torch.eye(B, device=device).bool()\n",
        "    neg_logits = logits.masked_fill(diag_mask, float('-inf'))  \n",
        "\n",
        "\n",
        "    # Get top-k hardest negatives per row \n",
        "    hard_vals_t2i, hard_idx_t2i = torch.topk(neg_logits, k, dim=1)  # (B, k)\n",
        "    # Get positive logits\n",
        "    pos_logits = logits[torch.arange(B, device=device), labels].unsqueeze(1)  # (B, 1)\n",
        "\n",
        "    logits_t2i_hard = torch.cat([pos_logits, hard_vals_t2i], dim=1)  # (B, 1+k)\n",
        "    labels_t2i = torch.zeros(B, dtype=torch.long, device=device)  # positive is index 0\n",
        "\n",
        "    loss_t2i = F.cross_entropy(logits_t2i_hard, labels_t2i)\n",
        "\n",
        "    neg_logits_T = logits.t().masked_fill(diag_mask, float('-inf'))  # (B, B)\n",
        "    hard_vals_i2t, hard_idx_i2t = torch.topk(neg_logits_T, k, dim=1)\n",
        "    pos_logits_i2t = logits.t()[torch.arange(B, device=device), labels].unsqueeze(1)\n",
        "    logits_i2t_hard = torch.cat([pos_logits_i2t, hard_vals_i2t], dim=1)\n",
        "    labels_i2t = torch.zeros(B, dtype=torch.long, device=device)\n",
        "    loss_i2t = F.cross_entropy(logits_i2t_hard, labels_i2t)\n",
        "\n",
        "    return 0.5 * (loss_t2i + loss_i2t)\n",
        "\n",
        "\n",
        "def l2_regularization(model, lambda_l2):\n",
        "    l2_norm = sum(p.pow(2.0).sum() for p in model.parameters())\n",
        "    return lambda_l2 * l2_norm\n",
        "\n",
        "\n",
        "def train_model_direction(\n",
        "    model: SpaceTranslator,\n",
        "    model_path: Path,\n",
        "    train_dataset: TensorDataset,\n",
        "    val_dataset: TensorDataset,\n",
        "    batch_size: int,\n",
        "    epochs: int,\n",
        "    lr: float,\n",
        "    patience: int,\n",
        "    reg_lambda: float = 0.03\n",
        "):\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    model.to(device)\n",
        "\n",
        "    print(f\"ðŸš€ Using device: {device}\")\n",
        "\n",
        "    # Dataloaders\n",
        "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "    val_loader = DataLoader(val_dataset, batch_size=batch_size)\n",
        "\n",
        "    # Optimizer and scheduler\n",
        "    optimizer = torch.optim.AdamW(model.parameters(), lr=lr, weight_decay=1e-4)\n",
        "\n",
        "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
        "        optimizer,\n",
        "        mode='max',\n",
        "        factor=0.5,\n",
        "        patience=3,\n",
        "        threshold=0.005,\n",
        "        min_lr=1e-6\n",
        "    )\n",
        "\n",
        "    best_mrr = float('-inf')\n",
        "    no_improvements = 0\n",
        "\n",
        "    for epoch in range(1, epochs + 1):\n",
        "        model.train()\n",
        "        running_train_loss = 0.0\n",
        "\n",
        "        progress_bar = tqdm(train_loader, desc=f\"Epoch {epoch}/{epochs}\", leave=False)\n",
        "        for X_batch, y_batch in progress_bar:\n",
        "            X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
        "\n",
        "            # X_batch = F.normalize(X_batch, p=2, dim=-1)\n",
        "            # y_batch = F.normalize(y_batch, p=2, dim=-1)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(X_batch)\n",
        "\n",
        "            loss = info_nce_loss(outputs, y_batch, model.logit_scale)\n",
        "            #loss += l2_regularization(model, reg_lambda)\n",
        "\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            running_train_loss += loss.item()\n",
        "            progress_bar.set_postfix(loss=loss.item())\n",
        "\n",
        "        train_loss = running_train_loss / len(train_loader)\n",
        "\n",
        "        # Validation phase\n",
        "        model.eval()\n",
        "        running_val_loss = 0.0\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for X_batch, y_batch in val_loader:\n",
        "                X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
        "\n",
        "                # X_batch = F.normalize(X_batch, p=2, dim=-1)\n",
        "                # y_batch = F.normalize(y_batch, p=2, dim=-1)\n",
        "\n",
        "                outputs = model(X_batch)\n",
        "\n",
        "                loss = info_nce_loss(outputs, y_batch, model.logit_scale)\n",
        "                #loss += l2_regularization(model, reg_lambda)\n",
        "\n",
        "                running_val_loss += loss.item()\n",
        "\n",
        "        val_loss = running_val_loss / len(val_loader)\n",
        "\n",
        "        print(f\"ðŸ“˜ Epoch {epoch:03d} | Train Loss: {train_loss:.6f} | Val Loss: {val_loss:.6f} | LR: {optimizer.param_groups[0]['lr']:.2e}\")\n",
        "\n",
        "        # Optional: external validation/test\n",
        "        results = test(val_dataset, model, device)\n",
        "        print(results, 'Logit scale:', model.logit_scale.exp().item())\n",
        "        mrr = results['mrr']\n",
        "\n",
        "        scheduler.step(mrr)\n",
        "\n",
        "        # Early stopping\n",
        "        if mrr > best_mrr:\n",
        "            best_mrr = mrr\n",
        "            no_improvements = 0\n",
        "\n",
        "            Path(model_path).parent.mkdir(parents=True, exist_ok=True)\n",
        "            torch.save(model.state_dict(), model_path)\n",
        "            print(f\"ðŸ’¾ Saved new best model (mrr={mrr:.6f})\")\n",
        "        else:\n",
        "            no_improvements += 1\n",
        "            if no_improvements >= patience:\n",
        "                print(\"â¹ Early stopping triggered.\")\n",
        "                break\n",
        "\n",
        "    print(f\"âœ… Training complete. Best mrr: {mrr:.6f}\")\n",
        "\n",
        "    return model\n",
        "\n",
        "\n",
        "def get_data(data_path: Path):\n",
        "    data = np.load(data_path)\n",
        "    caption_embeddings = data['captions/embeddings']\n",
        "    image_embeddings = data['images/embeddings']\n",
        "    caption_labels = data['captions/label']\n",
        "    data.close()\n",
        "\n",
        "    X_abs, y_abs = torch.tensor(caption_embeddings), torch.tensor(image_embeddings[np.argmax(caption_labels, axis=1)])\n",
        "\n",
        "    return X_abs, y_abs\n",
        "\n",
        "def get_datasets(X_abs, y_abs) -> tuple[torch.Tensor, torch.Tensor, torch.Tensor, torch.Tensor]:\n",
        "    print('Texts shape', X_abs.shape)\n",
        "    print('Images shape', y_abs.shape)\n",
        "\n",
        "    dataset = TensorDataset(X_abs, y_abs)\n",
        "    train_dataset, val_dataset = random_split(dataset, [0.8, 0.2], generator=torch.Generator().manual_seed(42))\n",
        "\n",
        "    return train_dataset, val_dataset\n",
        "\n",
        "def test(val_dataset: TensorDataset, model: nn.Module, device):\n",
        "    val_loader = DataLoader(val_dataset, batch_size=len(val_dataset))\n",
        "    for x_val, y_val in val_loader:\n",
        "        results = eval_on_val(x_val, y_val, model=model, device=device)\n",
        "    return results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "X_QhTeUoFrLm"
      },
      "outputs": [],
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "input_dim = 1024\n",
        "output_dim = 1536\n",
        "hidden_layers=[1256, 1656]\n",
        "dropout_rate = 0.5\n",
        "\n",
        "batch_size= 2048\n",
        "lr=0.01\n",
        "epochs= 250\n",
        "patience = 8\n",
        "\n",
        "data_path= '/content/drive/MyDrive/dav/train.npz'\n",
        "test_path= '/content/drive/MyDrive/dav/test.clean.npz'\n",
        "\n",
        "save_path = './models/dir-model.pth'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zI0blWNyFtDI",
        "outputId": "f68628d4-16ab-4da0-9416-1e20febe186d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Texts shape torch.Size([125000, 1024])\n",
            "Images shape torch.Size([125000, 1536])\n"
          ]
        }
      ],
      "source": [
        "x, y = get_data(data_path)\n",
        "\n",
        "train_dataset, val_dataset = get_datasets(x, y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P5k77RkVFuwg",
        "outputId": "1e6d4ab8-e127-434e-a4d4-60c71f19f25c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ðŸš€ Using device: cuda\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ðŸ“˜ Epoch 001 | Train Loss: 4.891643 | Val Loss: 3.718127 | LR: 1.00e-02\n",
            "{'mrr': np.float64(0.7448052281678955), 'ndcg': np.float64(0.8060800068067063), 'recall_at_1': 0.6124, 'recall_at_3': 0.85448, 'recall_at_5': 0.91964, 'recall_at_10': 0.97016, 'recall_at_50': 0.99888, 'l2_dist': 277.0684814453125} Logit scale: 23.2886962890625\n",
            "ðŸ’¾ Saved new best model (mrr=0.744805)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ðŸ“˜ Epoch 002 | Train Loss: 3.565430 | Val Loss: 2.843952 | LR: 1.00e-02\n",
            "{'mrr': np.float64(0.828902700497973), 'ndcg': np.float64(0.8705432968094536), 'recall_at_1': 0.7294, 'recall_at_3': 0.91752, 'recall_at_5': 0.95708, 'recall_at_10': 0.98412, 'recall_at_50': 0.99908, 'l2_dist': 260.9161682128906} Logit scale: 36.78339767456055\n",
            "ðŸ’¾ Saved new best model (mrr=0.828903)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ðŸ“˜ Epoch 003 | Train Loss: 2.977001 | Val Loss: 2.432778 | LR: 1.00e-02\n",
            "{'mrr': np.float64(0.8639403120457971), 'ndcg': np.float64(0.8972404897036886), 'recall_at_1': 0.78128, 'recall_at_3': 0.93876, 'recall_at_5': 0.969, 'recall_at_10': 0.98888, 'recall_at_50': 0.99932, 'l2_dist': 280.1271057128906} Logit scale: 50.50896453857422\n",
            "ðŸ’¾ Saved new best model (mrr=0.863940)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ðŸ“˜ Epoch 004 | Train Loss: 2.642725 | Val Loss: 2.211477 | LR: 1.00e-02\n",
            "{'mrr': np.float64(0.8805852670009757), 'ndcg': np.float64(0.9098967208232419), 'recall_at_1': 0.80644, 'recall_at_3': 0.94872, 'recall_at_5': 0.9734, 'recall_at_10': 0.99088, 'recall_at_50': 0.99952, 'l2_dist': 288.9298095703125} Logit scale: 62.784698486328125\n",
            "ðŸ’¾ Saved new best model (mrr=0.880585)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ðŸ“˜ Epoch 005 | Train Loss: 2.417431 | Val Loss: 2.081589 | LR: 1.00e-02\n",
            "{'mrr': np.float64(0.8900533708694727), 'ndcg': np.float64(0.91710763895202), 'recall_at_1': 0.8202, 'recall_at_3': 0.95488, 'recall_at_5': 0.97656, 'recall_at_10': 0.99164, 'recall_at_50': 0.99952, 'l2_dist': 300.37689208984375} Logit scale: 73.79359436035156\n",
            "ðŸ’¾ Saved new best model (mrr=0.890053)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ðŸ“˜ Epoch 006 | Train Loss: 2.246962 | Val Loss: 1.974991 | LR: 1.00e-02\n",
            "{'mrr': np.float64(0.897581012426187), 'ndcg': np.float64(0.9228032095624058), 'recall_at_1': 0.8324, 'recall_at_3': 0.95812, 'recall_at_5': 0.97916, 'recall_at_10': 0.9928, 'recall_at_50': 0.99932, 'l2_dist': 308.2652893066406} Logit scale: 83.82197570800781\n",
            "ðŸ’¾ Saved new best model (mrr=0.897581)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ðŸ“˜ Epoch 007 | Train Loss: 2.107811 | Val Loss: 1.910707 | LR: 1.00e-02\n",
            "{'mrr': np.float64(0.9032651542170819), 'ndcg': np.float64(0.9271036524105821), 'recall_at_1': 0.84104, 'recall_at_3': 0.96036, 'recall_at_5': 0.98072, 'recall_at_10': 0.99276, 'recall_at_50': 0.99948, 'l2_dist': 309.3061218261719} Logit scale: 92.93132781982422\n",
            "ðŸ’¾ Saved new best model (mrr=0.903265)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ðŸ“˜ Epoch 008 | Train Loss: 1.992101 | Val Loss: 1.850050 | LR: 1.00e-02\n",
            "{'mrr': np.float64(0.9084615343303902), 'ndcg': np.float64(0.931014161246044), 'recall_at_1': 0.84944, 'recall_at_3': 0.9632, 'recall_at_5': 0.9816, 'recall_at_10': 0.993, 'recall_at_50': 0.99948, 'l2_dist': 311.7698974609375} Logit scale: 100.69995880126953\n",
            "ðŸ’¾ Saved new best model (mrr=0.908462)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ðŸ“˜ Epoch 009 | Train Loss: 1.889147 | Val Loss: 1.811159 | LR: 1.00e-02\n",
            "{'mrr': np.float64(0.9111145997723354), 'ndcg': np.float64(0.9330271172842343), 'recall_at_1': 0.8536, 'recall_at_3': 0.96452, 'recall_at_5': 0.98224, 'recall_at_10': 0.99424, 'recall_at_50': 0.99952, 'l2_dist': 302.7626647949219} Logit scale: 101.06170654296875\n",
            "ðŸ’¾ Saved new best model (mrr=0.911115)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ðŸ“˜ Epoch 010 | Train Loss: 1.808816 | Val Loss: 1.774472 | LR: 1.00e-02\n",
            "{'mrr': np.float64(0.9154171242385657), 'ndcg': np.float64(0.9362706310871305), 'recall_at_1': 0.85996, 'recall_at_3': 0.96648, 'recall_at_5': 0.98328, 'recall_at_10': 0.99336, 'recall_at_50': 0.9994, 'l2_dist': 296.2349853515625} Logit scale: 101.0403060913086\n",
            "ðŸ’¾ Saved new best model (mrr=0.915417)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ðŸ“˜ Epoch 011 | Train Loss: 1.737900 | Val Loss: 1.754196 | LR: 1.00e-02\n",
            "{'mrr': np.float64(0.9157091669814397), 'ndcg': np.float64(0.936481907722531), 'recall_at_1': 0.86104, 'recall_at_3': 0.96708, 'recall_at_5': 0.98296, 'recall_at_10': 0.99376, 'recall_at_50': 0.9994, 'l2_dist': 285.4093322753906} Logit scale: 101.0167007446289\n",
            "ðŸ’¾ Saved new best model (mrr=0.915709)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ðŸ“˜ Epoch 012 | Train Loss: 1.676498 | Val Loss: 1.727795 | LR: 1.00e-02\n",
            "{'mrr': np.float64(0.9180617768564787), 'ndcg': np.float64(0.9382519496798783), 'recall_at_1': 0.8646, 'recall_at_3': 0.96832, 'recall_at_5': 0.98296, 'recall_at_10': 0.99356, 'recall_at_50': 0.99952, 'l2_dist': 276.0736999511719} Logit scale: 100.99310302734375\n",
            "ðŸ’¾ Saved new best model (mrr=0.918062)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ðŸ“˜ Epoch 013 | Train Loss: 1.618933 | Val Loss: 1.706196 | LR: 1.00e-02\n",
            "{'mrr': np.float64(0.9200216354640882), 'ndcg': np.float64(0.9397169031957647), 'recall_at_1': 0.86812, 'recall_at_3': 0.96864, 'recall_at_5': 0.98388, 'recall_at_10': 0.99328, 'recall_at_50': 0.9994, 'l2_dist': 273.0699768066406} Logit scale: 100.9695053100586\n",
            "ðŸ’¾ Saved new best model (mrr=0.920022)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ðŸ“˜ Epoch 014 | Train Loss: 1.573649 | Val Loss: 1.691857 | LR: 1.00e-02\n",
            "{'mrr': np.float64(0.920184612270918), 'ndcg': np.float64(0.9398266743692593), 'recall_at_1': 0.86812, 'recall_at_3': 0.968, 'recall_at_5': 0.98312, 'recall_at_10': 0.9934, 'recall_at_50': 0.99956, 'l2_dist': 266.114990234375} Logit scale: 100.9459228515625\n",
            "ðŸ’¾ Saved new best model (mrr=0.920185)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ðŸ“˜ Epoch 015 | Train Loss: 1.526073 | Val Loss: 1.677204 | LR: 1.00e-02\n",
            "{'mrr': np.float64(0.9217017193660212), 'ndcg': np.float64(0.9409671858890585), 'recall_at_1': 0.87092, 'recall_at_3': 0.96904, 'recall_at_5': 0.98312, 'recall_at_10': 0.99336, 'recall_at_50': 0.99952, 'l2_dist': 259.4028625488281} Logit scale: 100.92233276367188\n",
            "ðŸ’¾ Saved new best model (mrr=0.921702)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ðŸ“˜ Epoch 016 | Train Loss: 1.489168 | Val Loss: 1.667654 | LR: 1.00e-02\n",
            "{'mrr': np.float64(0.9232213677659135), 'ndcg': np.float64(0.9421126226247271), 'recall_at_1': 0.87312, 'recall_at_3': 0.97032, 'recall_at_5': 0.98368, 'recall_at_10': 0.9934, 'recall_at_50': 0.99952, 'l2_dist': 256.88397216796875} Logit scale: 100.89875793457031\n",
            "ðŸ’¾ Saved new best model (mrr=0.923221)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ðŸ“˜ Epoch 017 | Train Loss: 1.451431 | Val Loss: 1.655464 | LR: 1.00e-02\n",
            "{'mrr': np.float64(0.9231691622123692), 'ndcg': np.float64(0.9420509924874326), 'recall_at_1': 0.87352, 'recall_at_3': 0.96912, 'recall_at_5': 0.98352, 'recall_at_10': 0.99332, 'recall_at_50': 0.9994, 'l2_dist': 250.40480041503906} Logit scale: 100.87519073486328\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ðŸ“˜ Epoch 018 | Train Loss: 1.341547 | Val Loss: 1.622047 | LR: 5.00e-03\n",
            "{'mrr': np.float64(0.9246851534687374), 'ndcg': np.float64(0.9431888402702717), 'recall_at_1': 0.87628, 'recall_at_3': 0.97032, 'recall_at_5': 0.98364, 'recall_at_10': 0.99332, 'recall_at_50': 0.9994, 'l2_dist': 240.87246704101562} Logit scale: 100.8634033203125\n",
            "ðŸ’¾ Saved new best model (mrr=0.924685)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ðŸ“˜ Epoch 019 | Train Loss: 1.274832 | Val Loss: 1.610799 | LR: 5.00e-03\n",
            "{'mrr': np.float64(0.9252885841736561), 'ndcg': np.float64(0.9436515272442634), 'recall_at_1': 0.877, 'recall_at_3': 0.97028, 'recall_at_5': 0.98392, 'recall_at_10': 0.99328, 'recall_at_50': 0.99944, 'l2_dist': 233.29104614257812} Logit scale: 100.85161590576172\n",
            "ðŸ’¾ Saved new best model (mrr=0.925289)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ðŸ“˜ Epoch 020 | Train Loss: 1.237424 | Val Loss: 1.601771 | LR: 5.00e-03\n",
            "{'mrr': np.float64(0.9254553415946366), 'ndcg': np.float64(0.9437723496481311), 'recall_at_1': 0.87728, 'recall_at_3': 0.97048, 'recall_at_5': 0.98416, 'recall_at_10': 0.99316, 'recall_at_50': 0.99952, 'l2_dist': 226.0605926513672} Logit scale: 100.83983612060547\n",
            "ðŸ’¾ Saved new best model (mrr=0.925455)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ðŸ“˜ Epoch 021 | Train Loss: 1.211116 | Val Loss: 1.596574 | LR: 5.00e-03\n",
            "{'mrr': np.float64(0.9265547539256684), 'ndcg': np.float64(0.9445954489543181), 'recall_at_1': 0.87912, 'recall_at_3': 0.9706, 'recall_at_5': 0.98408, 'recall_at_10': 0.99328, 'recall_at_50': 0.99952, 'l2_dist': 221.04371643066406} Logit scale: 100.82805633544922\n",
            "ðŸ’¾ Saved new best model (mrr=0.926555)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ðŸ“˜ Epoch 022 | Train Loss: 1.184829 | Val Loss: 1.595622 | LR: 5.00e-03\n",
            "{'mrr': np.float64(0.9264834888277234), 'ndcg': np.float64(0.9445377598230831), 'recall_at_1': 0.87904, 'recall_at_3': 0.97076, 'recall_at_5': 0.9842, 'recall_at_10': 0.99304, 'recall_at_50': 0.99936, 'l2_dist': 216.5664825439453} Logit scale: 100.81627655029297\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ðŸ“˜ Epoch 023 | Train Loss: 1.137863 | Val Loss: 1.579742 | LR: 2.50e-03\n",
            "{'mrr': np.float64(0.9273002866107932), 'ndcg': np.float64(0.9451620504290176), 'recall_at_1': 0.88012, 'recall_at_3': 0.97096, 'recall_at_5': 0.98452, 'recall_at_10': 0.99308, 'recall_at_50': 0.99932, 'l2_dist': 211.97291564941406} Logit scale: 100.81156921386719\n",
            "ðŸ’¾ Saved new best model (mrr=0.927300)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ðŸ“˜ Epoch 024 | Train Loss: 1.108592 | Val Loss: 1.573265 | LR: 2.50e-03\n",
            "{'mrr': np.float64(0.9282403796542763), 'ndcg': np.float64(0.9458558829241452), 'recall_at_1': 0.88188, 'recall_at_3': 0.97116, 'recall_at_5': 0.98416, 'recall_at_10': 0.99316, 'recall_at_50': 0.9994, 'l2_dist': 209.7266845703125} Logit scale: 100.80685424804688\n",
            "ðŸ’¾ Saved new best model (mrr=0.928240)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ðŸ“˜ Epoch 025 | Train Loss: 1.092943 | Val Loss: 1.572593 | LR: 2.50e-03\n",
            "{'mrr': np.float64(0.9280009171716843), 'ndcg': np.float64(0.9456646536940462), 'recall_at_1': 0.88164, 'recall_at_3': 0.97128, 'recall_at_5': 0.98384, 'recall_at_10': 0.99316, 'recall_at_50': 0.99936, 'l2_dist': 206.2266387939453} Logit scale: 100.8021469116211\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ðŸ“˜ Epoch 026 | Train Loss: 1.076156 | Val Loss: 1.566753 | LR: 2.50e-03\n",
            "{'mrr': np.float64(0.9288723113896328), 'ndcg': np.float64(0.9463196352355275), 'recall_at_1': 0.88296, 'recall_at_3': 0.97144, 'recall_at_5': 0.98416, 'recall_at_10': 0.99272, 'recall_at_50': 0.99936, 'l2_dist': 203.7335968017578} Logit scale: 100.79743194580078\n",
            "ðŸ’¾ Saved new best model (mrr=0.928872)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ðŸ“˜ Epoch 027 | Train Loss: 1.049442 | Val Loss: 1.563583 | LR: 1.25e-03\n",
            "{'mrr': np.float64(0.9290771560158183), 'ndcg': np.float64(0.9464602342346443), 'recall_at_1': 0.88364, 'recall_at_3': 0.97104, 'recall_at_5': 0.9838, 'recall_at_10': 0.99316, 'recall_at_50': 0.99932, 'l2_dist': 202.90989685058594} Logit scale: 100.79508209228516\n",
            "ðŸ’¾ Saved new best model (mrr=0.929077)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ðŸ“˜ Epoch 028 | Train Loss: 1.035203 | Val Loss: 1.560664 | LR: 1.25e-03\n",
            "{'mrr': np.float64(0.9291593542002589), 'ndcg': np.float64(0.9465352459436297), 'recall_at_1': 0.8834, 'recall_at_3': 0.97124, 'recall_at_5': 0.98412, 'recall_at_10': 0.9932, 'recall_at_50': 0.99936, 'l2_dist': 201.26904296875} Logit scale: 100.792724609375\n",
            "ðŸ’¾ Saved new best model (mrr=0.929159)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ðŸ“˜ Epoch 029 | Train Loss: 1.031067 | Val Loss: 1.557243 | LR: 1.25e-03\n",
            "{'mrr': np.float64(0.9296569620717768), 'ndcg': np.float64(0.9468965950458721), 'recall_at_1': 0.88456, 'recall_at_3': 0.97104, 'recall_at_5': 0.9838, 'recall_at_10': 0.99304, 'recall_at_50': 0.9994, 'l2_dist': 200.1531219482422} Logit scale: 100.79037475585938\n",
            "ðŸ’¾ Saved new best model (mrr=0.929657)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ðŸ“˜ Epoch 030 | Train Loss: 1.020053 | Val Loss: 1.555266 | LR: 1.25e-03\n",
            "{'mrr': np.float64(0.929291663006627), 'ndcg': np.float64(0.9466254861452352), 'recall_at_1': 0.8838, 'recall_at_3': 0.97088, 'recall_at_5': 0.98428, 'recall_at_10': 0.99312, 'recall_at_50': 0.9994, 'l2_dist': 197.5496063232422} Logit scale: 100.78801727294922\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ðŸ“˜ Epoch 031 | Train Loss: 1.010725 | Val Loss: 1.553608 | LR: 1.25e-03\n",
            "{'mrr': np.float64(0.9294624616483831), 'ndcg': np.float64(0.9467463089761186), 'recall_at_1': 0.88424, 'recall_at_3': 0.97136, 'recall_at_5': 0.98396, 'recall_at_10': 0.99292, 'recall_at_50': 0.9994, 'l2_dist': 196.97219848632812} Logit scale: 100.7856674194336\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ðŸ“˜ Epoch 032 | Train Loss: 1.001863 | Val Loss: 1.553002 | LR: 1.25e-03\n",
            "{'mrr': np.float64(0.9293408477714518), 'ndcg': np.float64(0.9466533207974729), 'recall_at_1': 0.88416, 'recall_at_3': 0.97076, 'recall_at_5': 0.98388, 'recall_at_10': 0.99316, 'recall_at_50': 0.9994, 'l2_dist': 194.99513244628906} Logit scale: 100.78330993652344\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ðŸ“˜ Epoch 033 | Train Loss: 0.996867 | Val Loss: 1.552147 | LR: 1.25e-03\n",
            "{'mrr': np.float64(0.9295561098138111), 'ndcg': np.float64(0.9468081309371825), 'recall_at_1': 0.88464, 'recall_at_3': 0.97096, 'recall_at_5': 0.98404, 'recall_at_10': 0.99308, 'recall_at_50': 0.99932, 'l2_dist': 193.18850708007812} Logit scale: 100.78095245361328\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ðŸ“˜ Epoch 034 | Train Loss: 0.982834 | Val Loss: 1.548294 | LR: 6.25e-04\n",
            "{'mrr': np.float64(0.929701539703521), 'ndcg': np.float64(0.9469235348543653), 'recall_at_1': 0.88472, 'recall_at_3': 0.97128, 'recall_at_5': 0.98408, 'recall_at_10': 0.99304, 'recall_at_50': 0.99936, 'l2_dist': 192.81277465820312} Logit scale: 100.77859497070312\n",
            "ðŸ’¾ Saved new best model (mrr=0.929702)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ðŸ“˜ Epoch 035 | Train Loss: 0.974833 | Val Loss: 1.547715 | LR: 6.25e-04\n",
            "{'mrr': np.float64(0.9296114281649918), 'ndcg': np.float64(0.9468575401490896), 'recall_at_1': 0.88456, 'recall_at_3': 0.97096, 'recall_at_5': 0.98416, 'recall_at_10': 0.99316, 'recall_at_50': 0.9994, 'l2_dist': 192.4840545654297} Logit scale: 100.77623748779297\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ðŸ“˜ Epoch 036 | Train Loss: 0.973461 | Val Loss: 1.547908 | LR: 6.25e-04\n",
            "{'mrr': np.float64(0.9289045654493877), 'ndcg': np.float64(0.9463311071950766), 'recall_at_1': 0.88324, 'recall_at_3': 0.9712, 'recall_at_5': 0.98424, 'recall_at_10': 0.99328, 'recall_at_50': 0.99936, 'l2_dist': 191.2478790283203} Logit scale: 100.77388763427734\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ðŸ“˜ Epoch 037 | Train Loss: 0.967326 | Val Loss: 1.547713 | LR: 6.25e-04\n",
            "{'mrr': np.float64(0.9290907158968797), 'ndcg': np.float64(0.9464606794291943), 'recall_at_1': 0.88372, 'recall_at_3': 0.97136, 'recall_at_5': 0.98384, 'recall_at_10': 0.99296, 'recall_at_50': 0.9994, 'l2_dist': 191.04635620117188} Logit scale: 100.77153778076172\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ðŸ“˜ Epoch 038 | Train Loss: 0.958739 | Val Loss: 1.545992 | LR: 3.13e-04\n",
            "{'mrr': np.float64(0.9291883104469748), 'ndcg': np.float64(0.9465377966958666), 'recall_at_1': 0.88376, 'recall_at_3': 0.97136, 'recall_at_5': 0.98376, 'recall_at_10': 0.993, 'recall_at_50': 0.9994, 'l2_dist': 190.48269653320312} Logit scale: 100.76918029785156\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ðŸ“˜ Epoch 039 | Train Loss: 0.954723 | Val Loss: 1.545706 | LR: 3.13e-04\n",
            "{'mrr': np.float64(0.9292880102777151), 'ndcg': np.float64(0.9466120576423411), 'recall_at_1': 0.884, 'recall_at_3': 0.97124, 'recall_at_5': 0.9838, 'recall_at_10': 0.99308, 'recall_at_50': 0.99936, 'l2_dist': 190.5919189453125} Logit scale: 100.7668228149414\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ðŸ“˜ Epoch 040 | Train Loss: 0.956957 | Val Loss: 1.544283 | LR: 3.13e-04\n",
            "{'mrr': np.float64(0.9296174182082967), 'ndcg': np.float64(0.9468581847871166), 'recall_at_1': 0.88456, 'recall_at_3': 0.97124, 'recall_at_5': 0.98392, 'recall_at_10': 0.99308, 'recall_at_50': 0.9994, 'l2_dist': 190.02696228027344} Logit scale: 100.76447296142578\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ðŸ“˜ Epoch 041 | Train Loss: 0.950188 | Val Loss: 1.544157 | LR: 3.13e-04\n",
            "{'mrr': np.float64(0.92990678480899), 'ndcg': np.float64(0.9470688892323228), 'recall_at_1': 0.8852, 'recall_at_3': 0.9712, 'recall_at_5': 0.98392, 'recall_at_10': 0.99304, 'recall_at_50': 0.99936, 'l2_dist': 189.5748748779297} Logit scale: 100.76211547851562\n",
            "ðŸ’¾ Saved new best model (mrr=0.929907)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ðŸ“˜ Epoch 042 | Train Loss: 0.947687 | Val Loss: 1.543070 | LR: 1.56e-04\n",
            "{'mrr': np.float64(0.9295358064570918), 'ndcg': np.float64(0.9467957780708097), 'recall_at_1': 0.88448, 'recall_at_3': 0.97104, 'recall_at_5': 0.98412, 'recall_at_10': 0.99312, 'recall_at_50': 0.99936, 'l2_dist': 189.65907287597656} Logit scale: 100.76211547851562\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ðŸ“˜ Epoch 043 | Train Loss: 0.945150 | Val Loss: 1.543259 | LR: 1.56e-04\n",
            "{'mrr': np.float64(0.9297849687200863), 'ndcg': np.float64(0.9469785170244117), 'recall_at_1': 0.88496, 'recall_at_3': 0.97116, 'recall_at_5': 0.98404, 'recall_at_10': 0.993, 'recall_at_50': 0.99936, 'l2_dist': 189.41714477539062} Logit scale: 100.76211547851562\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ðŸ“˜ Epoch 044 | Train Loss: 0.945692 | Val Loss: 1.542981 | LR: 1.56e-04\n",
            "{'mrr': np.float64(0.9299668128234295), 'ndcg': np.float64(0.9471116568627964), 'recall_at_1': 0.8854, 'recall_at_3': 0.97124, 'recall_at_5': 0.98416, 'recall_at_10': 0.993, 'recall_at_50': 0.9994, 'l2_dist': 189.603515625} Logit scale: 100.76211547851562\n",
            "ðŸ’¾ Saved new best model (mrr=0.929967)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ðŸ“˜ Epoch 045 | Train Loss: 0.943841 | Val Loss: 1.543500 | LR: 1.56e-04\n",
            "{'mrr': np.float64(0.9294940605506691), 'ndcg': np.float64(0.9467586443798195), 'recall_at_1': 0.88452, 'recall_at_3': 0.97108, 'recall_at_5': 0.98412, 'recall_at_10': 0.99308, 'recall_at_50': 0.9994, 'l2_dist': 189.244873046875} Logit scale: 100.76211547851562\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ðŸ“˜ Epoch 046 | Train Loss: 0.945473 | Val Loss: 1.543117 | LR: 7.81e-05\n",
            "{'mrr': np.float64(0.929883377366751), 'ndcg': np.float64(0.9470472764876444), 'recall_at_1': 0.88528, 'recall_at_3': 0.97108, 'recall_at_5': 0.98404, 'recall_at_10': 0.99308, 'recall_at_50': 0.9994, 'l2_dist': 189.17323303222656} Logit scale: 100.76211547851562\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ðŸ“˜ Epoch 047 | Train Loss: 0.941299 | Val Loss: 1.542837 | LR: 7.81e-05\n",
            "{'mrr': np.float64(0.9298137324093603), 'ndcg': np.float64(0.9469957192198211), 'recall_at_1': 0.88516, 'recall_at_3': 0.97108, 'recall_at_5': 0.98404, 'recall_at_10': 0.993, 'recall_at_50': 0.9994, 'l2_dist': 188.52926635742188} Logit scale: 100.76211547851562\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ðŸ“˜ Epoch 048 | Train Loss: 0.941972 | Val Loss: 1.542526 | LR: 7.81e-05\n",
            "{'mrr': np.float64(0.9297132672773586), 'ndcg': np.float64(0.9469215497453004), 'recall_at_1': 0.88492, 'recall_at_3': 0.971, 'recall_at_5': 0.98408, 'recall_at_10': 0.993, 'recall_at_50': 0.99936, 'l2_dist': 188.7519989013672} Logit scale: 100.76211547851562\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ðŸ“˜ Epoch 049 | Train Loss: 0.937992 | Val Loss: 1.542267 | LR: 7.81e-05\n",
            "{'mrr': np.float64(0.9297524359036611), 'ndcg': np.float64(0.9469500398656241), 'recall_at_1': 0.88504, 'recall_at_3': 0.97112, 'recall_at_5': 0.98408, 'recall_at_10': 0.99288, 'recall_at_50': 0.9994, 'l2_dist': 188.34521484375} Logit scale: 100.76211547851562\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ðŸ“˜ Epoch 050 | Train Loss: 0.939952 | Val Loss: 1.542368 | LR: 3.91e-05\n",
            "{'mrr': np.float64(0.929758754678339), 'ndcg': np.float64(0.9469551543782836), 'recall_at_1': 0.88504, 'recall_at_3': 0.97104, 'recall_at_5': 0.98408, 'recall_at_10': 0.99296, 'recall_at_50': 0.9994, 'l2_dist': 188.19631958007812} Logit scale: 100.76211547851562\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ðŸ“˜ Epoch 051 | Train Loss: 0.940660 | Val Loss: 1.542644 | LR: 3.91e-05\n",
            "{'mrr': np.float64(0.9297640232634562), 'ndcg': np.float64(0.9469627405692421), 'recall_at_1': 0.88496, 'recall_at_3': 0.97132, 'recall_at_5': 0.98412, 'recall_at_10': 0.99296, 'recall_at_50': 0.9994, 'l2_dist': 188.56350708007812} Logit scale: 100.76211547851562\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ðŸ“˜ Epoch 052 | Train Loss: 0.936226 | Val Loss: 1.542225 | LR: 3.91e-05\n",
            "{'mrr': np.float64(0.9298726110844082), 'ndcg': np.float64(0.9470423322592552), 'recall_at_1': 0.88512, 'recall_at_3': 0.97108, 'recall_at_5': 0.98404, 'recall_at_10': 0.99296, 'recall_at_50': 0.9994, 'l2_dist': 188.78956604003906} Logit scale: 100.76211547851562\n",
            "â¹ Early stopping triggered.\n",
            "âœ… Training complete. Best mrr: 0.929873\n",
            "Finished training. Now testing using best model...\n",
            "Test Results: {'mrr': np.float64(0.9299668128234295), 'ndcg': np.float64(0.9471116568627964), 'recall_at_1': 0.8854, 'recall_at_3': 0.97124, 'recall_at_5': 0.98416, 'recall_at_10': 0.993, 'recall_at_50': 0.9994, 'l2_dist': 189.603515625}\n"
          ]
        }
      ],
      "source": [
        "model_args = {\n",
        "    'input_dim': x.size(1),\n",
        "    'output_dim': y.size(1),\n",
        "    'hidden_layers': hidden_layers,\n",
        "    'dropout_rate': dropout_rate,\n",
        "    'activation': nn.ReLU\n",
        "}\n",
        "\n",
        "model = SpaceTranslator(**model_args).to(device)\n",
        "\n",
        "train_model_direction(model, save_path, train_dataset, val_dataset, batch_size, epochs, lr, patience)\n",
        "\n",
        "print('Finished training. Now testing using best model...')\n",
        "\n",
        "state = torch.load(save_path)\n",
        "model.load_state_dict(state)\n",
        "results = test(val_dataset, model, device)\n",
        "print(\"Test Results:\", results)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 459
        },
        "id": "_Wk_esyYFw8X",
        "outputId": "9a0f2f43-7cd5-4d4f-b124-6e8fbf1765f1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generating submission file...\n",
            "âœ“ Saved submission to dav.csv\n"
          ]
        },
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "summary": "{\n  \"name\": \"generate_submission(model, Path(test_path), output_file=\\\"dav\",\n  \"rows\": 1500,\n  \"fields\": [\n    {\n      \"column\": \"id\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 433,\n        \"min\": 1,\n        \"max\": 1500,\n        \"num_unique_values\": 1500,\n        \"samples\": [\n          1117,\n          1369,\n          423\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"embedding\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
              "type": "dataframe"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-2ad83cd1-a3bf-4410-b650-0be5795bbd21\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>embedding</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>[0.7686144709587097, 2.381528854370117, 1.0353...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>[-4.1902289390563965, 0.8161473870277405, -0.6...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>[-1.2787296772003174, -1.561556100845337, -2.2...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>[11.185599327087402, -4.036659240722656, -3.34...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>[6.494488716125488, 8.447858810424805, 1.51297...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1495</th>\n",
              "      <td>1496</td>\n",
              "      <td>[-0.43608617782592773, -5.116342067718506, 5.4...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1496</th>\n",
              "      <td>1497</td>\n",
              "      <td>[-0.33950138092041016, 2.236297130584717, 9.56...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1497</th>\n",
              "      <td>1498</td>\n",
              "      <td>[2.6319985389709473, -4.231359004974365, -1.67...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1498</th>\n",
              "      <td>1499</td>\n",
              "      <td>[-3.7497448921203613, -3.935755729675293, -2.3...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1499</th>\n",
              "      <td>1500</td>\n",
              "      <td>[7.802744388580322, -21.419414520263672, -4.69...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1500 rows Ã— 2 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-2ad83cd1-a3bf-4410-b650-0be5795bbd21')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-2ad83cd1-a3bf-4410-b650-0be5795bbd21 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-2ad83cd1-a3bf-4410-b650-0be5795bbd21');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-623b95ef-9bf6-46a9-b7c4-7e2b20cb1045\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-623b95ef-9bf6-46a9-b7c4-7e2b20cb1045')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-623b95ef-9bf6-46a9-b7c4-7e2b20cb1045 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "        id                                          embedding\n",
              "0        1  [0.7686144709587097, 2.381528854370117, 1.0353...\n",
              "1        2  [-4.1902289390563965, 0.8161473870277405, -0.6...\n",
              "2        3  [-1.2787296772003174, -1.561556100845337, -2.2...\n",
              "3        4  [11.185599327087402, -4.036659240722656, -3.34...\n",
              "4        5  [6.494488716125488, 8.447858810424805, 1.51297...\n",
              "...    ...                                                ...\n",
              "1495  1496  [-0.43608617782592773, -5.116342067718506, 5.4...\n",
              "1496  1497  [-0.33950138092041016, 2.236297130584717, 9.56...\n",
              "1497  1498  [2.6319985389709473, -4.231359004974365, -1.67...\n",
              "1498  1499  [-3.7497448921203613, -3.935755729675293, -2.3...\n",
              "1499  1500  [7.802744388580322, -21.419414520263672, -4.69...\n",
              "\n",
              "[1500 rows x 2 columns]"
            ]
          },
          "execution_count": 37,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "generate_submission(model, Path(test_path), output_file=\"dav.csv\", device=device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "y46fQFKd3t4M"
      },
      "outputs": [],
      "source": [
        "torch.save(model, \"full_model.pth\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
