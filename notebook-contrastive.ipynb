{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.13"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":117959,"databundleVersionId":14220991,"sourceType":"competition"}],"dockerImageVersionId":31154,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"### model.py","metadata":{}},{"cell_type":"code","source":"from typing import Optional\nfrom torch import nn\nfrom torch.nn import functional as F\nimport torch\n\n\nclass Translator(nn.Module):\n    def __init__(self, input_dim, output_dim, hidden_layers):\n        super().__init__()\n        layers = []\n        last = input_dim\n        for hidden in hidden_layers:\n            layers += [nn.Linear(last, hidden), nn.GELU(), nn.LayerNorm(hidden), nn.Dropout(0.3)]\n            last = hidden\n        layers.append(nn.Linear(last, output_dim))\n        self.net = nn.Sequential(*layers)\n        def init_weights(module):\n            if isinstance(module, nn.Linear):\n                nn.init.xavier_uniform_(module.weight)\n                if module.bias is not None:\n                    nn.init.constant_(module.bias, 0.0)\n            elif isinstance(module, nn.LayerNorm):\n                nn.init.ones_(module.weight)\n                nn.init.zeros_(module.bias)\n        model.apply(init_weights)\n        \n    \n\n    def forward(self, x):\n        out = self.net(x)\n        \n        dir_vec = F.normalize(out, dim=-1)\n        return dir_vec\n","metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.status.busy":"2025-10-30T15:42:35.751118Z","iopub.execute_input":"2025-10-30T15:42:35.751674Z","iopub.status.idle":"2025-10-30T15:42:35.758128Z","shell.execute_reply.started":"2025-10-30T15:42:35.751653Z","shell.execute_reply":"2025-10-30T15:42:35.757416Z"},"trusted":true},"outputs":[],"execution_count":36},{"cell_type":"markdown","source":"### eval.py","metadata":{}},{"cell_type":"code","source":"from pathlib import Path\nimport numpy as np\nimport torch\nimport pandas as pd\n\n'''Code from https://github.com/Mamiglia/challenge'''\n\ndef mrr(pred_indices: np.ndarray, gt_indices: np.ndarray) -> float:\n    \"\"\"\n    Compute Mean Reciprocal Rank (MRR)\n    Args:\n        pred_indices: (N, K) array of predicted indices for N queries (top-K)\n        gt_indices: (N,) array of ground truth indices\n    Returns:\n        mrr: Mean Reciprocal Rank\n    \"\"\"\n    reciprocal_ranks = []\n    for i in range(len(gt_indices)):\n        matches = np.where(pred_indices[i] == gt_indices[i])[0]\n        if matches.size > 0:\n            reciprocal_ranks.append(1.0 / (matches[0] + 1))\n        else:\n            reciprocal_ranks.append(0.0)\n    return np.mean(reciprocal_ranks)\n\n\ndef recall_at_k(pred_indices: np.ndarray, gt_indices: np.ndarray, k: int) -> float:\n    \"\"\"Compute Recall@k\n    Args:\n        pred_indices: (N, N) array of top indices for N queries\n        gt_indices: (N,) array of ground truth indices\n        k: number of top predictions to consider\n    Returns:\n        recall: Recall@k\n    \"\"\"\n    recall = 0\n    for i in range(len(gt_indices)):\n        if gt_indices[i] in pred_indices[i, :k]:\n            recall += 1\n    recall /= len(gt_indices)\n    return recall\n\nimport numpy as np\n\ndef ndcg(pred_indices: np.ndarray, gt_indices: np.ndarray, k: int = 100) -> float:\n    \"\"\"\n    Compute Normalized Discounted Cumulative Gain (NDCG@k)\n    Args:\n        pred_indices: (N, K) array of predicted indices for N queries\n        gt_indices: (N,) array of ground truth indices\n        k: number of top predictions to consider\n    Returns:\n        ndcg: NDCG@k\n    \"\"\"\n    ndcg_total = 0.0\n    for i in range(len(gt_indices)):\n        matches = np.where(pred_indices[i, :k] == gt_indices[i])[0]\n        if matches.size > 0:\n            rank = matches[0] + 1\n            ndcg_total += 1.0 / np.log2(rank + 1)  # DCG (IDCG = 1)\n    return ndcg_total / len(gt_indices)\n\n\n\n@torch.inference_mode()\ndef evaluate_retrieval(translated_embd, image_embd, gt_indices, max_indices = 99, batch_size=100):\n    \"\"\"Evaluate retrieval performance using cosine similarity\n    Args:\n        translated_embd: (N_captions, D) translated caption embeddings\n        image_embd: (N_images, D) image embeddings\n        gt_indices: (N_captions,) ground truth image indices for each caption\n        max_indices: number of top predictions to consider\n    Returns:\n        results: dict of evaluation metrics\n    \n    \"\"\"\n    # Compute similarity matrix\n    if isinstance(translated_embd, np.ndarray):\n        translated_embd = torch.from_numpy(translated_embd).float()\n    if isinstance(image_embd, np.ndarray):\n        image_embd = torch.from_numpy(image_embd).float()\n    \n    n_queries = translated_embd.shape[0]\n    device = translated_embd.device\n    \n    # Prepare containers for the fragments to be reassembled\n    all_sorted_indices = []\n    l2_distances = []\n    \n    # Process in batches - the narrow gate approach\n    for start_idx in range(0, n_queries, batch_size):\n        batch_slice = slice(start_idx, min(start_idx + batch_size, n_queries))\n        batch_translated = translated_embd[batch_slice]\n        batch_img_embd = image_embd[batch_slice]\n        \n        # Compute similarity only for this batch\n        batch_similarity = batch_translated @ batch_img_embd.T\n\n        # Get top-k predictions for this batch\n        batch_indices = batch_similarity.topk(k=max_indices, dim=1, sorted=True).indices.numpy()\n        all_sorted_indices.append(gt_indices[batch_slice][batch_indices])\n\n        # Compute L2 distance for this batch\n        batch_gt = gt_indices[batch_slice]\n        batch_gt_embeddings = image_embd[batch_gt]\n        batch_l2 = (batch_translated - batch_gt_embeddings).norm(dim=1)\n        l2_distances.append(batch_l2)\n    \n    # Reassemble the fragments\n    sorted_indices = np.concatenate(all_sorted_indices, axis=0)\n    \n    # Apply the sacred metrics to the whole\n    metrics = {\n        'mrr': mrr,\n        'ndcg': ndcg,\n        'recall_at_1': lambda preds, gt: recall_at_k(preds, gt, 1),\n        'recall_at_3': lambda preds, gt: recall_at_k(preds, gt, 3),\n        'recall_at_5': lambda preds, gt: recall_at_k(preds, gt, 5),\n        'recall_at_10': lambda preds, gt: recall_at_k(preds, gt, 10),\n        'recall_at_50': lambda preds, gt: recall_at_k(preds, gt, 50),\n    }\n    \n    results = {\n        name: func(sorted_indices, gt_indices)\n        for name, func in metrics.items()\n    }\n    \n    l2_dist = torch.cat(l2_distances, dim=0).mean().item()\n    results['l2_dist'] = l2_dist\n    \n    return results\n\ndef eval_on_val(X_val: np.ndarray, y_val: np.ndarray, model: Translator, device) -> dict:\n    gt_indices = torch.arange(len(y_val))\n    \n    model.eval()\n\n    with torch.inference_mode():\n        translated = model(X_val.to(device)).to('cpu')\n\n    results = evaluate_retrieval(translated, y_val, gt_indices)\n    \n    return results\n\ndef generate_submission(model: Translator, test_path: Path, output_file=\"submission.csv\", device=None):\n    test_data = np.load(test_path)\n    sample_ids = test_data['captions/ids']\n    test_embds = test_data['captions/embeddings']\n    test_embds = torch.from_numpy(test_embds).float()\n\n    with torch.no_grad():\n        pred_embds = model(test_embds.to(device)).cpu()\n\n    print(\"Generating submission file...\")\n\n    if isinstance(pred_embds, torch.Tensor):\n        pred_embds = pred_embds.cpu().numpy()\n\n    df_submission = pd.DataFrame({'id': sample_ids, 'embedding': pred_embds.tolist()})\n\n    df_submission.to_csv(output_file, index=False, float_format='%.17g')\n    print(f\"✓ Saved submission to {output_file}\")\n\n    return df_submission","metadata":{"execution":{"iopub.status.busy":"2025-10-30T15:42:35.759255Z","iopub.execute_input":"2025-10-30T15:42:35.759522Z","iopub.status.idle":"2025-10-30T15:42:35.780751Z","shell.execute_reply.started":"2025-10-30T15:42:35.759482Z","shell.execute_reply":"2025-10-30T15:42:35.780153Z"},"trusted":true},"outputs":[],"execution_count":37},{"cell_type":"markdown","source":"### configs","metadata":{}},{"cell_type":"code","source":"device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\ninput_dim = 1024\noutput_dim = 1536\nhidden_layers=[2048, 512]\n\n\nbatch_size= 8196\nlr= 0.0001\nepochs= 30\ntemp = 0.07\ndata_path= '/kaggle/input/aml-competition/train/train/train.npz'\ntest_path= '/kaggle/input/aml-competition/test/test/test.clean.npz'\n\nmodel_save_path= './models/exp1.pth'","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-30T15:42:35.912931Z","iopub.execute_input":"2025-10-30T15:42:35.913103Z","iopub.status.idle":"2025-10-30T15:42:35.917204Z","shell.execute_reply.started":"2025-10-30T15:42:35.913089Z","shell.execute_reply":"2025-10-30T15:42:35.916649Z"}},"outputs":[],"execution_count":38},{"cell_type":"markdown","source":"### main.py","metadata":{}},{"cell_type":"code","source":"\nfrom typing import Literal\nimport numpy as np\nimport torch\nimport torch.nn.functional as F\nfrom torch.utils.data import TensorDataset, DataLoader\nfrom pathlib import Path\nfrom tqdm import tqdm\nfrom sklearn.decomposition import PCA\nfrom sklearn.cluster import KMeans\n\n\ndef info_nce_loss(dir_preds, img_targets, temp=0.07):\n    # dir_preds: (B, d) already normalized\n    # img_targets: (B, d) raw image embeddings -> we will normalize them\n    img_normed = F.normalize(img_targets, dim=-1)\n    logits = (dir_preds @ img_normed.T) / temp   # (B, B)\n    labels = torch.arange(logits.size(0), device=logits.device)\n    #loss = F.cross_entropy(logits, labels)      # row-wise: positive is same-index\n    #return loss\n    loss_t2i = F.cross_entropy(logits, labels)          # for each text row, positive at same idx\n    loss_i2t = F.cross_entropy(logits.T, labels)        # for each image row, positive at same idx\n    return 0.5 * (loss_t2i + loss_i2t)\ndef symmetric_nt_xent(z_text, z_img, temp=0.07):\n    B = z_text.size(0)\n    # compute similarity matrix\n    logits = (z_text @ z_img.T) / temp         # (B, B)\n    labels = torch.arange(B, device=logits.device)\n\n    loss_t2i = F.cross_entropy(logits, labels)          # for each text row, positive at same idx\n    loss_i2t = F.cross_entropy(logits.T, labels)        # for each image row, positive at same idx\n    return 0.5 * (loss_t2i + loss_i2t)\n\n\ndef train_model(model: Translator, model_path: Path, mode: str, \n                train_loader: DataLoader, val_loader: DataLoader,\n                epochs: int, lr: float, temp: float) -> Translator:\n    \n    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\n    print(f\"Using device: {device}\")\n\n    optimizer = torch.optim.AdamW(model.parameters(), lr=lr, weight_decay=1e-4)\n\n    best_val_loss = float('inf')\n\n    for epoch in range(epochs):\n        model.train()\n\n        train_loss = 0\n        for X_batch, y_batch in tqdm(train_loader, desc=f\"Epoch {epoch+1}/{epochs}\"):\n            X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n\n            optimizer.zero_grad()\n\n            outputs = model(X_batch)\n\n            loss = info_nce_loss(outputs, y_batch, temp=temp)\n\n            loss.backward()\n\n            optimizer.step()\n\n            train_loss += loss.item()\n\n        train_loss /= len(train_loader)\n\n        model.eval()\n\n        val_loss = 0\n\n        with torch.no_grad():\n            for X_batch, y_batch in val_loader:\n                X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n                outputs = model(X_batch)\n\n                loss = info_nce_loss(outputs, y_batch, temp=temp)\n\n                val_loss += loss.item()\n\n        val_loss /= len(val_loader)\n\n        print(f\"Epoch {epoch+1}: Train Loss = {train_loss:.6f}, Val Loss = {val_loss:.6f}\")\n\n        if val_loss < best_val_loss:\n            best_val_loss = val_loss\n\n            Path(model_path).parent.mkdir(parents=True, exist_ok=True)\n\n            torch.save(model.state_dict(), model_path)\n\n            print(f\"✓ Saved best model (val_loss={val_loss:.6f})\")\n\n    return model\n\ndef load_data(data_path: Path, config: dict) -> tuple[torch.Tensor, torch.Tensor, torch.Tensor, torch.Tensor]:\n\n    data = np.load(data_path)\n    caption_embeddings = data['captions/embeddings']\n    image_embeddings = data['images/embeddings']\n    caption_labels = data['captions/label']\n\n    X_abs, y_abs = torch.tensor(caption_embeddings), torch.tensor(image_embeddings[np.argmax(caption_labels, axis=1)])\n    \n    print('Texts shape', X_abs.shape)\n    print('Images shape', X_abs.shape)\n\n    n_train = int(0.9 * X_abs.shape[0])\n    train_split = torch.zeros(X_abs.shape[0], dtype=torch.bool)\n    train_split[:n_train] = 1\n    \n    X_train, X_val = X_abs[train_split], X_abs[~train_split]\n    y_train, y_val = y_abs[train_split], y_abs[~train_split]\n    \n    return X_train, y_train, X_val, y_val\n\n    \ndef test(model: Translator, X_val: torch.Tensor, y_val: torch.tensor, device):\n    results = eval_on_val(X_val, y_val, model=model, device=device)\n    print(\"Test Results:\", results)\n\n\ndef train(config: dict, model: Translator, X_train: torch.Tensor, y_train: torch.Tensor, X_val: torch.Tensor, y_val: torch.Tensor, temp):\n        \n    train_dataset = TensorDataset(X_train, y_train)\n    val_dataset = TensorDataset(X_val, y_val)\n\n    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n    val_loader = DataLoader(val_dataset, batch_size=batch_size)\n\n    train_model(model, model_save_path, 'affine', train_loader, val_loader, epochs, lr, temp)\n\n    print('Finished training. Now testing using best model...')\n    ","metadata":{"execution":{"iopub.status.busy":"2025-10-30T15:42:35.995241Z","iopub.execute_input":"2025-10-30T15:42:35.995435Z","iopub.status.idle":"2025-10-30T15:42:36.028766Z","shell.execute_reply.started":"2025-10-30T15:42:35.995420Z","shell.execute_reply":"2025-10-30T15:42:36.027951Z"},"trusted":true},"outputs":[],"execution_count":39},{"cell_type":"code","source":"device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\nX_train, Y_train, X_val, y_val = load_data(data_path, dict())\n\nmodel_args = {\n    'input_dim': input_dim,\n    'output_dim': output_dim,\n    'hidden_layers': hidden_layers,\n}\nmodel = Translator(**model_args).to(device)\n\ntrain(config=dict(), model=model, X_train=X_train, y_train=Y_train, X_val=X_val, y_val=y_val, temp=temp)\n\nstate = torch.load(model_save_path)\nmodel.load_state_dict(state)\n\ntest(model, X_val, y_val, device)\ngenerate_submission(model, Path(test_path), device=device)\n\n\n\n","metadata":{"execution":{"iopub.status.busy":"2025-10-30T15:42:36.030049Z","iopub.execute_input":"2025-10-30T15:42:36.030528Z","iopub.status.idle":"2025-10-30T15:45:44.205363Z","shell.execute_reply.started":"2025-10-30T15:42:36.030480Z","shell.execute_reply":"2025-10-30T15:45:44.204641Z"},"trusted":true},"outputs":[{"name":"stdout","text":"Texts shape torch.Size([125000, 1024])\nImages shape torch.Size([125000, 1024])\nUsing device: cuda\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1/30: 100%|██████████| 14/14 [00:05<00:00,  2.71it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 1: Train Loss = 8.407278, Val Loss = 7.388747\n✓ Saved best model (val_loss=7.388747)\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2/30: 100%|██████████| 14/14 [00:05<00:00,  2.69it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 2: Train Loss = 7.668592, Val Loss = 6.915126\n✓ Saved best model (val_loss=6.915126)\n","output_type":"stream"},{"name":"stderr","text":"Epoch 3/30: 100%|██████████| 14/14 [00:05<00:00,  2.72it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 3: Train Loss = 7.280057, Val Loss = 6.607900\n✓ Saved best model (val_loss=6.607900)\n","output_type":"stream"},{"name":"stderr","text":"Epoch 4/30: 100%|██████████| 14/14 [00:05<00:00,  2.53it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 4: Train Loss = 7.019140, Val Loss = 6.397048\n✓ Saved best model (val_loss=6.397048)\n","output_type":"stream"},{"name":"stderr","text":"Epoch 5/30: 100%|██████████| 14/14 [00:05<00:00,  2.53it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 5: Train Loss = 6.831478, Val Loss = 6.244561\n✓ Saved best model (val_loss=6.244561)\n","output_type":"stream"},{"name":"stderr","text":"Epoch 6/30: 100%|██████████| 14/14 [00:05<00:00,  2.51it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 6: Train Loss = 6.691924, Val Loss = 6.129716\n✓ Saved best model (val_loss=6.129716)\n","output_type":"stream"},{"name":"stderr","text":"Epoch 7/30: 100%|██████████| 14/14 [00:05<00:00,  2.54it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 7: Train Loss = 6.581156, Val Loss = 6.039628\n✓ Saved best model (val_loss=6.039628)\n","output_type":"stream"},{"name":"stderr","text":"Epoch 8/30: 100%|██████████| 14/14 [00:05<00:00,  2.64it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 8: Train Loss = 6.489903, Val Loss = 5.966813\n✓ Saved best model (val_loss=5.966813)\n","output_type":"stream"},{"name":"stderr","text":"Epoch 9/30: 100%|██████████| 14/14 [00:05<00:00,  2.61it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 9: Train Loss = 6.413766, Val Loss = 5.905116\n✓ Saved best model (val_loss=5.905116)\n","output_type":"stream"},{"name":"stderr","text":"Epoch 10/30: 100%|██████████| 14/14 [00:05<00:00,  2.79it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 10: Train Loss = 6.349645, Val Loss = 5.852599\n✓ Saved best model (val_loss=5.852599)\n","output_type":"stream"},{"name":"stderr","text":"Epoch 11/30: 100%|██████████| 14/14 [00:05<00:00,  2.77it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 11: Train Loss = 6.290544, Val Loss = 5.806819\n✓ Saved best model (val_loss=5.806819)\n","output_type":"stream"},{"name":"stderr","text":"Epoch 12/30: 100%|██████████| 14/14 [00:05<00:00,  2.76it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 12: Train Loss = 6.237609, Val Loss = 5.766841\n✓ Saved best model (val_loss=5.766841)\n","output_type":"stream"},{"name":"stderr","text":"Epoch 13/30: 100%|██████████| 14/14 [00:05<00:00,  2.79it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 13: Train Loss = 6.189693, Val Loss = 5.731109\n✓ Saved best model (val_loss=5.731109)\n","output_type":"stream"},{"name":"stderr","text":"Epoch 14/30: 100%|██████████| 14/14 [00:05<00:00,  2.75it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 14: Train Loss = 6.145918, Val Loss = 5.697558\n✓ Saved best model (val_loss=5.697558)\n","output_type":"stream"},{"name":"stderr","text":"Epoch 15/30: 100%|██████████| 14/14 [00:05<00:00,  2.78it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 15: Train Loss = 6.107567, Val Loss = 5.668140\n✓ Saved best model (val_loss=5.668140)\n","output_type":"stream"},{"name":"stderr","text":"Epoch 16/30: 100%|██████████| 14/14 [00:05<00:00,  2.61it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 16: Train Loss = 6.070209, Val Loss = 5.641078\n✓ Saved best model (val_loss=5.641078)\n","output_type":"stream"},{"name":"stderr","text":"Epoch 17/30: 100%|██████████| 14/14 [00:05<00:00,  2.64it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 17: Train Loss = 6.035472, Val Loss = 5.616101\n✓ Saved best model (val_loss=5.616101)\n","output_type":"stream"},{"name":"stderr","text":"Epoch 18/30: 100%|██████████| 14/14 [00:05<00:00,  2.55it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 18: Train Loss = 6.002912, Val Loss = 5.592788\n✓ Saved best model (val_loss=5.592788)\n","output_type":"stream"},{"name":"stderr","text":"Epoch 19/30: 100%|██████████| 14/14 [00:05<00:00,  2.61it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 19: Train Loss = 5.971116, Val Loss = 5.571547\n✓ Saved best model (val_loss=5.571547)\n","output_type":"stream"},{"name":"stderr","text":"Epoch 20/30: 100%|██████████| 14/14 [00:05<00:00,  2.69it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 20: Train Loss = 5.942171, Val Loss = 5.551809\n✓ Saved best model (val_loss=5.551809)\n","output_type":"stream"},{"name":"stderr","text":"Epoch 21/30: 100%|██████████| 14/14 [00:05<00:00,  2.73it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 21: Train Loss = 5.912519, Val Loss = 5.532024\n✓ Saved best model (val_loss=5.532024)\n","output_type":"stream"},{"name":"stderr","text":"Epoch 22/30: 100%|██████████| 14/14 [00:05<00:00,  2.69it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 22: Train Loss = 5.884870, Val Loss = 5.513794\n✓ Saved best model (val_loss=5.513794)\n","output_type":"stream"},{"name":"stderr","text":"Epoch 23/30: 100%|██████████| 14/14 [00:05<00:00,  2.73it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 23: Train Loss = 5.858105, Val Loss = 5.496948\n✓ Saved best model (val_loss=5.496948)\n","output_type":"stream"},{"name":"stderr","text":"Epoch 24/30: 100%|██████████| 14/14 [00:05<00:00,  2.61it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 24: Train Loss = 5.833537, Val Loss = 5.480558\n✓ Saved best model (val_loss=5.480558)\n","output_type":"stream"},{"name":"stderr","text":"Epoch 25/30: 100%|██████████| 14/14 [00:05<00:00,  2.63it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 25: Train Loss = 5.808824, Val Loss = 5.466507\n✓ Saved best model (val_loss=5.466507)\n","output_type":"stream"},{"name":"stderr","text":"Epoch 26/30: 100%|██████████| 14/14 [00:05<00:00,  2.60it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 26: Train Loss = 5.784186, Val Loss = 5.451467\n✓ Saved best model (val_loss=5.451467)\n","output_type":"stream"},{"name":"stderr","text":"Epoch 27/30: 100%|██████████| 14/14 [00:05<00:00,  2.64it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 27: Train Loss = 5.760222, Val Loss = 5.439779\n✓ Saved best model (val_loss=5.439779)\n","output_type":"stream"},{"name":"stderr","text":"Epoch 28/30: 100%|██████████| 14/14 [00:05<00:00,  2.65it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 28: Train Loss = 5.737221, Val Loss = 5.426432\n✓ Saved best model (val_loss=5.426432)\n","output_type":"stream"},{"name":"stderr","text":"Epoch 29/30: 100%|██████████| 14/14 [00:05<00:00,  2.60it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 29: Train Loss = 5.714628, Val Loss = 5.415672\n✓ Saved best model (val_loss=5.415672)\n","output_type":"stream"},{"name":"stderr","text":"Epoch 30/30: 100%|██████████| 14/14 [00:05<00:00,  2.63it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 30: Train Loss = 5.693635, Val Loss = 5.405296\n✓ Saved best model (val_loss=5.405296)\nFinished training. Now testing using best model...\nTest Results: {'mrr': 0.3974786955385354, 'ndcg': 0.5398756323725631, 'recall_at_1': 0.16328, 'recall_at_3': 0.50248, 'recall_at_5': 0.84312, 'recall_at_10': 0.94824, 'recall_at_50': 0.99888, 'l2_dist': 25.634349822998047}\nGenerating submission file...\n✓ Saved submission to submission.csv\n","output_type":"stream"},{"execution_count":40,"output_type":"execute_result","data":{"text/plain":"        id                                          embedding\n0        1  [0.01817476749420166, 0.0036171807441860437, 0...\n1        2  [-0.00831032544374466, -0.0027059123385697603,...\n2        3  [-0.008676226250827312, -0.02103574201464653, ...\n3        4  [-0.010519394651055336, 0.009211746975779533, ...\n4        5  [0.009460922330617905, 0.015212705358862877, 0...\n...    ...                                                ...\n1495  1496  [-0.011934620328247547, -0.02548549324274063, ...\n1496  1497  [-0.00026255170814692974, 0.012432225979864597...\n1497  1498  [0.003439840395003557, -0.009417425841093063, ...\n1498  1499  [0.013452058658003807, 0.00010316609404981136,...\n1499  1500  [0.018197959288954735, -0.04125312715768814, -...\n\n[1500 rows x 2 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>embedding</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>[0.01817476749420166, 0.0036171807441860437, 0...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>[-0.00831032544374466, -0.0027059123385697603,...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>[-0.008676226250827312, -0.02103574201464653, ...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>[-0.010519394651055336, 0.009211746975779533, ...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5</td>\n      <td>[0.009460922330617905, 0.015212705358862877, 0...</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>1495</th>\n      <td>1496</td>\n      <td>[-0.011934620328247547, -0.02548549324274063, ...</td>\n    </tr>\n    <tr>\n      <th>1496</th>\n      <td>1497</td>\n      <td>[-0.00026255170814692974, 0.012432225979864597...</td>\n    </tr>\n    <tr>\n      <th>1497</th>\n      <td>1498</td>\n      <td>[0.003439840395003557, -0.009417425841093063, ...</td>\n    </tr>\n    <tr>\n      <th>1498</th>\n      <td>1499</td>\n      <td>[0.013452058658003807, 0.00010316609404981136,...</td>\n    </tr>\n    <tr>\n      <th>1499</th>\n      <td>1500</td>\n      <td>[0.018197959288954735, -0.04125312715768814, -...</td>\n    </tr>\n  </tbody>\n</table>\n<p>1500 rows × 2 columns</p>\n</div>"},"metadata":{}}],"execution_count":40}]}