{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### model.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-10-30T15:42:35.751674Z",
     "iopub.status.busy": "2025-10-30T15:42:35.751118Z",
     "iopub.status.idle": "2025-10-30T15:42:35.758128Z",
     "shell.execute_reply": "2025-10-30T15:42:35.757416Z",
     "shell.execute_reply.started": "2025-10-30T15:42:35.751653Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from typing import Optional\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "import torch\n",
    "\n",
    "\n",
    "class Translator(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim, hidden_layers):\n",
    "        super().__init__()\n",
    "        layers = []\n",
    "        last = input_dim\n",
    "        for hidden in hidden_layers:\n",
    "            layers += [nn.Linear(last, hidden), nn.GELU(), nn.LayerNorm(hidden), nn.Dropout(0.3)]\n",
    "            last = hidden\n",
    "        layers.append(nn.Linear(last, output_dim))\n",
    "        self.net = nn.Sequential(*layers)\n",
    "        \n",
    "        self.apply(self.init_weights)\n",
    "        \n",
    "    def init_weights(self, module):\n",
    "        if isinstance(module, nn.Linear):\n",
    "            nn.init.xavier_uniform_(module.weight)\n",
    "            if module.bias is not None:\n",
    "                nn.init.constant_(module.bias, 0.0)\n",
    "        elif isinstance(module, nn.LayerNorm):\n",
    "            nn.init.ones_(module.weight)\n",
    "            nn.init.zeros_(module.bias)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.normalize(x, dim=-1)\n",
    "        out = self.net(x)\n",
    "        \n",
    "        dir_vec = F.normalize(out, dim=-1)\n",
    "        return dir_vec\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### eval.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-30T15:42:35.759522Z",
     "iopub.status.busy": "2025-10-30T15:42:35.759255Z",
     "iopub.status.idle": "2025-10-30T15:42:35.780751Z",
     "shell.execute_reply": "2025-10-30T15:42:35.780153Z",
     "shell.execute_reply.started": "2025-10-30T15:42:35.759482Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import torch\n",
    "import pandas as pd\n",
    "\n",
    "'''Code from https://github.com/Mamiglia/challenge'''\n",
    "\n",
    "def mrr(pred_indices: np.ndarray, gt_indices: np.ndarray) -> float:\n",
    "    \"\"\"\n",
    "    Compute Mean Reciprocal Rank (MRR)\n",
    "    Args:\n",
    "        pred_indices: (N, K) array of predicted indices for N queries (top-K)\n",
    "        gt_indices: (N,) array of ground truth indices\n",
    "    Returns:\n",
    "        mrr: Mean Reciprocal Rank\n",
    "    \"\"\"\n",
    "    reciprocal_ranks = []\n",
    "    for i in range(len(gt_indices)):\n",
    "        matches = np.where(pred_indices[i] == gt_indices[i])[0]\n",
    "        if matches.size > 0:\n",
    "            reciprocal_ranks.append(1.0 / (matches[0] + 1))\n",
    "        else:\n",
    "            reciprocal_ranks.append(0.0)\n",
    "    return np.mean(reciprocal_ranks)\n",
    "\n",
    "\n",
    "def recall_at_k(pred_indices: np.ndarray, gt_indices: np.ndarray, k: int) -> float:\n",
    "    \"\"\"Compute Recall@k\n",
    "    Args:\n",
    "        pred_indices: (N, N) array of top indices for N queries\n",
    "        gt_indices: (N,) array of ground truth indices\n",
    "        k: number of top predictions to consider\n",
    "    Returns:\n",
    "        recall: Recall@k\n",
    "    \"\"\"\n",
    "    recall = 0\n",
    "    for i in range(len(gt_indices)):\n",
    "        if gt_indices[i] in pred_indices[i, :k]:\n",
    "            recall += 1\n",
    "    recall /= len(gt_indices)\n",
    "    return recall\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "def ndcg(pred_indices: np.ndarray, gt_indices: np.ndarray, k: int = 100) -> float:\n",
    "    \"\"\"\n",
    "    Compute Normalized Discounted Cumulative Gain (NDCG@k)\n",
    "    Args:\n",
    "        pred_indices: (N, K) array of predicted indices for N queries\n",
    "        gt_indices: (N,) array of ground truth indices\n",
    "        k: number of top predictions to consider\n",
    "    Returns:\n",
    "        ndcg: NDCG@k\n",
    "    \"\"\"\n",
    "    ndcg_total = 0.0\n",
    "    for i in range(len(gt_indices)):\n",
    "        matches = np.where(pred_indices[i, :k] == gt_indices[i])[0]\n",
    "        if matches.size > 0:\n",
    "            rank = matches[0] + 1\n",
    "            ndcg_total += 1.0 / np.log2(rank + 1)  # DCG (IDCG = 1)\n",
    "    return ndcg_total / len(gt_indices)\n",
    "\n",
    "\n",
    "\n",
    "@torch.inference_mode()\n",
    "def evaluate_retrieval(translated_embd, image_embd, gt_indices, max_indices = 99, batch_size=100):\n",
    "    \"\"\"Evaluate retrieval performance using cosine similarity\n",
    "    Args:\n",
    "        translated_embd: (N_captions, D) translated caption embeddings\n",
    "        image_embd: (N_images, D) image embeddings\n",
    "        gt_indices: (N_captions,) ground truth image indices for each caption\n",
    "        max_indices: number of top predictions to consider\n",
    "    Returns:\n",
    "        results: dict of evaluation metrics\n",
    "    \n",
    "    \"\"\"\n",
    "    # Compute similarity matrix\n",
    "    if isinstance(translated_embd, np.ndarray):\n",
    "        translated_embd = torch.from_numpy(translated_embd).float()\n",
    "    if isinstance(image_embd, np.ndarray):\n",
    "        image_embd = torch.from_numpy(image_embd).float()\n",
    "    \n",
    "    n_queries = translated_embd.shape[0]\n",
    "    device = translated_embd.device\n",
    "    \n",
    "    # Prepare containers for the fragments to be reassembled\n",
    "    all_sorted_indices = []\n",
    "    l2_distances = []\n",
    "    \n",
    "    # Process in batches - the narrow gate approach\n",
    "    for start_idx in range(0, n_queries, batch_size):\n",
    "        batch_slice = slice(start_idx, min(start_idx + batch_size, n_queries))\n",
    "        batch_translated = translated_embd[batch_slice]\n",
    "        batch_img_embd = image_embd[batch_slice]\n",
    "        \n",
    "        # Compute similarity only for this batch\n",
    "        batch_similarity = batch_translated @ batch_img_embd.T\n",
    "\n",
    "        # Get top-k predictions for this batch\n",
    "        batch_indices = batch_similarity.topk(k=max_indices, dim=1, sorted=True).indices.numpy()\n",
    "        all_sorted_indices.append(gt_indices[batch_slice][batch_indices])\n",
    "\n",
    "        # Compute L2 distance for this batch\n",
    "        batch_gt = gt_indices[batch_slice]\n",
    "        batch_gt_embeddings = image_embd[batch_gt]\n",
    "        batch_l2 = (batch_translated - batch_gt_embeddings).norm(dim=1)\n",
    "        l2_distances.append(batch_l2)\n",
    "    \n",
    "    # Reassemble the fragments\n",
    "    sorted_indices = np.concatenate(all_sorted_indices, axis=0)\n",
    "    \n",
    "    # Apply the sacred metrics to the whole\n",
    "    metrics = {\n",
    "        'mrr': mrr,\n",
    "        'ndcg': ndcg,\n",
    "        'recall_at_1': lambda preds, gt: recall_at_k(preds, gt, 1),\n",
    "        'recall_at_3': lambda preds, gt: recall_at_k(preds, gt, 3),\n",
    "        'recall_at_5': lambda preds, gt: recall_at_k(preds, gt, 5),\n",
    "        'recall_at_10': lambda preds, gt: recall_at_k(preds, gt, 10),\n",
    "        'recall_at_50': lambda preds, gt: recall_at_k(preds, gt, 50),\n",
    "    }\n",
    "    \n",
    "    results = {\n",
    "        name: func(sorted_indices, gt_indices)\n",
    "        for name, func in metrics.items()\n",
    "    }\n",
    "    \n",
    "    l2_dist = torch.cat(l2_distances, dim=0).mean().item()\n",
    "    results['l2_dist'] = l2_dist\n",
    "    \n",
    "    return results\n",
    "\n",
    "def eval_on_val(x_val: np.ndarray, y_val: np.ndarray, model: Translator, device) -> dict:\n",
    "    gt_indices = torch.arange(len(y_val))\n",
    "    \n",
    "    model.eval()\n",
    "\n",
    "    with torch.inference_mode():\n",
    "        translated = model(x_val.to(device)).to('cpu')\n",
    "\n",
    "    results = evaluate_retrieval(translated, y_val, gt_indices)\n",
    "    \n",
    "    return results\n",
    "\n",
    "def generate_submission(model: Translator, test_path: Path, output_file=\"submission.csv\", device=None):\n",
    "    test_data = np.load(test_path)\n",
    "    sample_ids = test_data['captions/ids']\n",
    "    test_embds = test_data['captions/embeddings']\n",
    "    test_embds = torch.from_numpy(test_embds).float()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        pred_embds = model(test_embds.to(device)).cpu()\n",
    "\n",
    "    print(\"Generating submission file...\")\n",
    "\n",
    "    if isinstance(pred_embds, torch.Tensor):\n",
    "        pred_embds = pred_embds.cpu().numpy()\n",
    "\n",
    "    df_submission = pd.DataFrame({'id': sample_ids, 'embedding': pred_embds.tolist()})\n",
    "\n",
    "    df_submission.to_csv(output_file, index=False, float_format='%.17g')\n",
    "    print(f\"✓ Saved submission to {output_file}\")\n",
    "\n",
    "    return df_submission"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### configs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-30T15:42:35.913103Z",
     "iopub.status.busy": "2025-10-30T15:42:35.912931Z",
     "iopub.status.idle": "2025-10-30T15:42:35.917204Z",
     "shell.execute_reply": "2025-10-30T15:42:35.916649Z",
     "shell.execute_reply.started": "2025-10-30T15:42:35.913089Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "input_dim = 1024\n",
    "output_dim = 1536\n",
    "hidden_layers=[2048, 512]\n",
    "\n",
    "\n",
    "batch_size= 4096\n",
    "lr= 0.0001\n",
    "epochs= 200\n",
    "patience = 10\n",
    "temp = 0.07\n",
    "data_path= '/kaggle/input/aml-competition/train/train/train.npz'\n",
    "test_path= '/kaggle/input/aml-competition/test/test/test.clean.npz'\n",
    "\n",
    "model_save_path= './models/exp1.pth'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### main.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-30T15:42:35.995435Z",
     "iopub.status.busy": "2025-10-30T15:42:35.995241Z",
     "iopub.status.idle": "2025-10-30T15:42:36.028766Z",
     "shell.execute_reply": "2025-10-30T15:42:36.027951Z",
     "shell.execute_reply.started": "2025-10-30T15:42:35.995420Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from torch.utils.data import random_split\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "\n",
    "def info_nce_loss(dir_preds, img_targets, temp=0.07):\n",
    "    logits = (dir_preds @ img_normed.T) / temp\n",
    "    labels = torch.arange(logits.size(0), device=logits.device)\n",
    "    #loss = F.cross_entropy(logits, labels)    \n",
    "    #return loss\n",
    "    loss_t2i = F.cross_entropy(logits, labels)          \n",
    "    loss_i2t = F.cross_entropy(logits.T, labels)        \n",
    "    return 0.5 * (loss_t2i + loss_i2t)\n",
    "\n",
    "\n",
    "\n",
    "def train_model(model: Translator, model_path: Path, \n",
    "                train_dataset: TensorDataset, val_dataset: TensorDataset, batch_size: int,\n",
    "                epochs: int, lr: float, temp: float, patience: int) -> Translator:\n",
    "    \n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    print(f\"Using device: {device}\")\n",
    "    \n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=batch_size)\n",
    "    \n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=lr, weight_decay=1e-4)\n",
    "\n",
    "    best_val_loss = float('inf')\n",
    "    no_improvements = 0\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "\n",
    "        train_loss = 0\n",
    "        for X_batch, y_batch in tqdm(train_loader, desc=f\"Epoch {epoch+1}/{epochs}\"):\n",
    "            X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "            y_batch = F.normalize(y_batch, dim=-1)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            outputs = model(X_batch)\n",
    "\n",
    "            loss = info_nce_loss(outputs, y_batch, temp=temp)\n",
    "\n",
    "            loss.backward()\n",
    "\n",
    "            optimizer.step()\n",
    "\n",
    "            train_loss += loss.item()\n",
    "\n",
    "        train_loss /= len(train_loader)\n",
    "\n",
    "        model.eval()\n",
    "\n",
    "        val_loss = 0\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for X_batch, y_batch in val_loader:\n",
    "                X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "                outputs = model(X_batch)\n",
    "\n",
    "                loss = info_nce_loss(outputs, y_batch, temp=temp)\n",
    "\n",
    "                val_loss += loss.item()\n",
    "\n",
    "        val_loss /= len(val_loader)\n",
    "\n",
    "        print(f\"Epoch {epoch+1}: Train Loss = {train_loss:.6f}, Val Loss = {val_loss:.6f}\")\n",
    "        test(val_dataset, model, device)\n",
    "\n",
    "\n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            no_improvements = 0\n",
    "\n",
    "            Path(model_path).parent.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "            torch.save(model.state_dict(), model_path)\n",
    "\n",
    "            print(f\"✓ Saved best model (val_loss={val_loss:.6f})\")\n",
    "        elif no_improvements >= patience:\n",
    "            return model\n",
    "        else:\n",
    "            no_improvements += 1\n",
    "\n",
    "    return model\n",
    "\n",
    "def load_data(data_path: Path, config: dict) -> tuple[torch.Tensor, torch.Tensor, torch.Tensor, torch.Tensor]:\n",
    "\n",
    "    data = np.load(data_path)\n",
    "    caption_embeddings = data['captions/embeddings']\n",
    "    image_embeddings = data['images/embeddings']\n",
    "    caption_labels = data['captions/label']\n",
    "\n",
    "    X_abs, y_abs = torch.tensor(caption_embeddings), torch.tensor(image_embeddings[np.argmax(caption_labels, axis=1)])\n",
    "    \n",
    "    print('Texts shape', X_abs.shape)\n",
    "    print('Images shape', X_abs.shape)\n",
    "    \n",
    "    dataset = TensorDataset(X_abs, y_abs)\n",
    "    train_dataset, val_dataset = random_split(dataset, [0.9, 0.1], generator=torch.Generator().manual_seed(42))\n",
    "    \n",
    "    return train_dataset, val_dataset\n",
    "\n",
    "def test(val_dataset: TensorDataset, model: Translator, device):\n",
    "    val_loader = DataLoader(val_dataset, batch_size=len(val_dataset))\n",
    "    for x_val, y_val in val_loader:\n",
    "        results = eval_on_val(x_val, y_val, model=model, device=device)\n",
    "    print(\"Test Results:\", results)\n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-30T15:42:36.030528Z",
     "iopub.status.busy": "2025-10-30T15:42:36.030049Z",
     "iopub.status.idle": "2025-10-30T15:45:44.205363Z",
     "shell.execute_reply": "2025-10-30T15:45:44.204641Z",
     "shell.execute_reply.started": "2025-10-30T15:42:36.030480Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Texts shape torch.Size([125000, 1024])\n",
      "Images shape torch.Size([125000, 1024])\n",
      "Using device: cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/30: 100%|██████████| 14/14 [00:05<00:00,  2.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Train Loss = 8.407278, Val Loss = 7.388747\n",
      "✓ Saved best model (val_loss=7.388747)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/30: 100%|██████████| 14/14 [00:05<00:00,  2.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: Train Loss = 7.668592, Val Loss = 6.915126\n",
      "✓ Saved best model (val_loss=6.915126)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/30: 100%|██████████| 14/14 [00:05<00:00,  2.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: Train Loss = 7.280057, Val Loss = 6.607900\n",
      "✓ Saved best model (val_loss=6.607900)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/30: 100%|██████████| 14/14 [00:05<00:00,  2.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: Train Loss = 7.019140, Val Loss = 6.397048\n",
      "✓ Saved best model (val_loss=6.397048)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/30: 100%|██████████| 14/14 [00:05<00:00,  2.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5: Train Loss = 6.831478, Val Loss = 6.244561\n",
      "✓ Saved best model (val_loss=6.244561)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/30: 100%|██████████| 14/14 [00:05<00:00,  2.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6: Train Loss = 6.691924, Val Loss = 6.129716\n",
      "✓ Saved best model (val_loss=6.129716)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/30: 100%|██████████| 14/14 [00:05<00:00,  2.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7: Train Loss = 6.581156, Val Loss = 6.039628\n",
      "✓ Saved best model (val_loss=6.039628)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/30: 100%|██████████| 14/14 [00:05<00:00,  2.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8: Train Loss = 6.489903, Val Loss = 5.966813\n",
      "✓ Saved best model (val_loss=5.966813)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/30: 100%|██████████| 14/14 [00:05<00:00,  2.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: Train Loss = 6.413766, Val Loss = 5.905116\n",
      "✓ Saved best model (val_loss=5.905116)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/30: 100%|██████████| 14/14 [00:05<00:00,  2.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10: Train Loss = 6.349645, Val Loss = 5.852599\n",
      "✓ Saved best model (val_loss=5.852599)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11/30: 100%|██████████| 14/14 [00:05<00:00,  2.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11: Train Loss = 6.290544, Val Loss = 5.806819\n",
      "✓ Saved best model (val_loss=5.806819)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12/30: 100%|██████████| 14/14 [00:05<00:00,  2.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12: Train Loss = 6.237609, Val Loss = 5.766841\n",
      "✓ Saved best model (val_loss=5.766841)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13/30: 100%|██████████| 14/14 [00:05<00:00,  2.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13: Train Loss = 6.189693, Val Loss = 5.731109\n",
      "✓ Saved best model (val_loss=5.731109)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 14/30: 100%|██████████| 14/14 [00:05<00:00,  2.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14: Train Loss = 6.145918, Val Loss = 5.697558\n",
      "✓ Saved best model (val_loss=5.697558)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 15/30: 100%|██████████| 14/14 [00:05<00:00,  2.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15: Train Loss = 6.107567, Val Loss = 5.668140\n",
      "✓ Saved best model (val_loss=5.668140)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 16/30: 100%|██████████| 14/14 [00:05<00:00,  2.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16: Train Loss = 6.070209, Val Loss = 5.641078\n",
      "✓ Saved best model (val_loss=5.641078)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 17/30: 100%|██████████| 14/14 [00:05<00:00,  2.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17: Train Loss = 6.035472, Val Loss = 5.616101\n",
      "✓ Saved best model (val_loss=5.616101)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 18/30: 100%|██████████| 14/14 [00:05<00:00,  2.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18: Train Loss = 6.002912, Val Loss = 5.592788\n",
      "✓ Saved best model (val_loss=5.592788)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 19/30: 100%|██████████| 14/14 [00:05<00:00,  2.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19: Train Loss = 5.971116, Val Loss = 5.571547\n",
      "✓ Saved best model (val_loss=5.571547)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 20/30: 100%|██████████| 14/14 [00:05<00:00,  2.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20: Train Loss = 5.942171, Val Loss = 5.551809\n",
      "✓ Saved best model (val_loss=5.551809)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 21/30: 100%|██████████| 14/14 [00:05<00:00,  2.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21: Train Loss = 5.912519, Val Loss = 5.532024\n",
      "✓ Saved best model (val_loss=5.532024)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 22/30: 100%|██████████| 14/14 [00:05<00:00,  2.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22: Train Loss = 5.884870, Val Loss = 5.513794\n",
      "✓ Saved best model (val_loss=5.513794)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 23/30: 100%|██████████| 14/14 [00:05<00:00,  2.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23: Train Loss = 5.858105, Val Loss = 5.496948\n",
      "✓ Saved best model (val_loss=5.496948)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 24/30: 100%|██████████| 14/14 [00:05<00:00,  2.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24: Train Loss = 5.833537, Val Loss = 5.480558\n",
      "✓ Saved best model (val_loss=5.480558)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 25/30: 100%|██████████| 14/14 [00:05<00:00,  2.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25: Train Loss = 5.808824, Val Loss = 5.466507\n",
      "✓ Saved best model (val_loss=5.466507)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 26/30: 100%|██████████| 14/14 [00:05<00:00,  2.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26: Train Loss = 5.784186, Val Loss = 5.451467\n",
      "✓ Saved best model (val_loss=5.451467)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 27/30: 100%|██████████| 14/14 [00:05<00:00,  2.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27: Train Loss = 5.760222, Val Loss = 5.439779\n",
      "✓ Saved best model (val_loss=5.439779)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 28/30: 100%|██████████| 14/14 [00:05<00:00,  2.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28: Train Loss = 5.737221, Val Loss = 5.426432\n",
      "✓ Saved best model (val_loss=5.426432)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 29/30: 100%|██████████| 14/14 [00:05<00:00,  2.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29: Train Loss = 5.714628, Val Loss = 5.415672\n",
      "✓ Saved best model (val_loss=5.415672)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 30/30: 100%|██████████| 14/14 [00:05<00:00,  2.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30: Train Loss = 5.693635, Val Loss = 5.405296\n",
      "✓ Saved best model (val_loss=5.405296)\n",
      "Finished training. Now testing using best model...\n",
      "Test Results: {'mrr': 0.3974786955385354, 'ndcg': 0.5398756323725631, 'recall_at_1': 0.16328, 'recall_at_3': 0.50248, 'recall_at_5': 0.84312, 'recall_at_10': 0.94824, 'recall_at_50': 0.99888, 'l2_dist': 25.634349822998047}\n",
      "Generating submission file...\n",
      "✓ Saved submission to submission.csv\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>embedding</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>[0.01817476749420166, 0.0036171807441860437, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>[-0.00831032544374466, -0.0027059123385697603,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>[-0.008676226250827312, -0.02103574201464653, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>[-0.010519394651055336, 0.009211746975779533, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>[0.009460922330617905, 0.015212705358862877, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1495</th>\n",
       "      <td>1496</td>\n",
       "      <td>[-0.011934620328247547, -0.02548549324274063, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1496</th>\n",
       "      <td>1497</td>\n",
       "      <td>[-0.00026255170814692974, 0.012432225979864597...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1497</th>\n",
       "      <td>1498</td>\n",
       "      <td>[0.003439840395003557, -0.009417425841093063, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1498</th>\n",
       "      <td>1499</td>\n",
       "      <td>[0.013452058658003807, 0.00010316609404981136,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1499</th>\n",
       "      <td>1500</td>\n",
       "      <td>[0.018197959288954735, -0.04125312715768814, -...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1500 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        id                                          embedding\n",
       "0        1  [0.01817476749420166, 0.0036171807441860437, 0...\n",
       "1        2  [-0.00831032544374466, -0.0027059123385697603,...\n",
       "2        3  [-0.008676226250827312, -0.02103574201464653, ...\n",
       "3        4  [-0.010519394651055336, 0.009211746975779533, ...\n",
       "4        5  [0.009460922330617905, 0.015212705358862877, 0...\n",
       "...    ...                                                ...\n",
       "1495  1496  [-0.011934620328247547, -0.02548549324274063, ...\n",
       "1496  1497  [-0.00026255170814692974, 0.012432225979864597...\n",
       "1497  1498  [0.003439840395003557, -0.009417425841093063, ...\n",
       "1498  1499  [0.013452058658003807, 0.00010316609404981136,...\n",
       "1499  1500  [0.018197959288954735, -0.04125312715768814, -...\n",
       "\n",
       "[1500 rows x 2 columns]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "train_dataset, val_dataset = load_data(data_path, dict())\n",
    "model_args = {\n",
    "    'input_dim': input_dim,\n",
    "    'output_dim': output_dim,\n",
    "    'hidden_layers': hidden_layers,\n",
    "}\n",
    "model = Translator(**model_args).to(device)\n",
    "\n",
    "train_model(model, model_save_path, train_dataset, val_dataset, batch_size, epochs, lr, temp, patience)\n",
    "\n",
    "print('Finished training. Now testing using best model...')\n",
    "\n",
    "state = torch.load(model_save_path)\n",
    "model.load_state_dict(state)\n",
    "test(val_dataset, model, device)\n",
    "\n",
    "generate_submission(model, Path(test_path), device=device)\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "databundleVersionId": 14220991,
     "sourceId": 117959,
     "sourceType": "competition"
    }
   ],
   "dockerImageVersionId": 31154,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
